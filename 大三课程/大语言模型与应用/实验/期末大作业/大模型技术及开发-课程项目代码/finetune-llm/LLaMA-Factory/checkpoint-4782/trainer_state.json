{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 4782,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003137254901960784,
      "grad_norm": 0.7053786516189575,
      "learning_rate": 4.999991368021548e-05,
      "loss": 3.5157,
      "num_input_tokens_seen": 10232,
      "step": 5,
      "train_runtime": 8.0024,
      "train_tokens_per_second": 1278.624
    },
    {
      "epoch": 0.006274509803921568,
      "grad_norm": 0.47175347805023193,
      "learning_rate": 4.999956300711246e-05,
      "loss": 3.1858,
      "num_input_tokens_seen": 20032,
      "step": 10,
      "train_runtime": 15.5934,
      "train_tokens_per_second": 1284.643
    },
    {
      "epoch": 0.009411764705882352,
      "grad_norm": 0.5638505816459656,
      "learning_rate": 4.999894258948526e-05,
      "loss": 3.0637,
      "num_input_tokens_seen": 30456,
      "step": 15,
      "train_runtime": 23.6558,
      "train_tokens_per_second": 1287.466
    },
    {
      "epoch": 0.012549019607843137,
      "grad_norm": 0.361123263835907,
      "learning_rate": 4.999805243402817e-05,
      "loss": 2.9258,
      "num_input_tokens_seen": 40664,
      "step": 20,
      "train_runtime": 31.4935,
      "train_tokens_per_second": 1291.186
    },
    {
      "epoch": 0.01568627450980392,
      "grad_norm": 0.5161364674568176,
      "learning_rate": 4.999689255034593e-05,
      "loss": 2.772,
      "num_input_tokens_seen": 50168,
      "step": 25,
      "train_runtime": 38.6273,
      "train_tokens_per_second": 1298.769
    },
    {
      "epoch": 0.018823529411764704,
      "grad_norm": 0.36827975511550903,
      "learning_rate": 4.9995462950953667e-05,
      "loss": 2.9119,
      "num_input_tokens_seen": 60288,
      "step": 30,
      "train_runtime": 46.3025,
      "train_tokens_per_second": 1302.047
    },
    {
      "epoch": 0.02196078431372549,
      "grad_norm": 0.31181779503822327,
      "learning_rate": 4.999376365127669e-05,
      "loss": 2.7764,
      "num_input_tokens_seen": 70152,
      "step": 35,
      "train_runtime": 54.2267,
      "train_tokens_per_second": 1293.681
    },
    {
      "epoch": 0.025098039215686273,
      "grad_norm": 0.29762545228004456,
      "learning_rate": 4.9991794669650406e-05,
      "loss": 2.7929,
      "num_input_tokens_seen": 80272,
      "step": 40,
      "train_runtime": 61.936,
      "train_tokens_per_second": 1296.048
    },
    {
      "epoch": 0.02823529411764706,
      "grad_norm": 0.33828005194664,
      "learning_rate": 4.9989556027320065e-05,
      "loss": 2.7475,
      "num_input_tokens_seen": 90088,
      "step": 45,
      "train_runtime": 69.7221,
      "train_tokens_per_second": 1292.102
    },
    {
      "epoch": 0.03137254901960784,
      "grad_norm": 0.3944622576236725,
      "learning_rate": 4.998704774844055e-05,
      "loss": 2.798,
      "num_input_tokens_seen": 100080,
      "step": 50,
      "train_runtime": 77.3475,
      "train_tokens_per_second": 1293.901
    },
    {
      "epoch": 0.034509803921568626,
      "grad_norm": 0.2895895838737488,
      "learning_rate": 4.998426986007611e-05,
      "loss": 2.7671,
      "num_input_tokens_seen": 109928,
      "step": 55,
      "train_runtime": 85.1298,
      "train_tokens_per_second": 1291.299
    },
    {
      "epoch": 0.03764705882352941,
      "grad_norm": 0.3162742555141449,
      "learning_rate": 4.998122239220009e-05,
      "loss": 2.7987,
      "num_input_tokens_seen": 120512,
      "step": 60,
      "train_runtime": 93.143,
      "train_tokens_per_second": 1293.838
    },
    {
      "epoch": 0.0407843137254902,
      "grad_norm": 0.42885637283325195,
      "learning_rate": 4.9977905377694554e-05,
      "loss": 2.7554,
      "num_input_tokens_seen": 130328,
      "step": 65,
      "train_runtime": 101.0074,
      "train_tokens_per_second": 1290.282
    },
    {
      "epoch": 0.04392156862745098,
      "grad_norm": 0.41133061051368713,
      "learning_rate": 4.997431885235e-05,
      "loss": 2.7779,
      "num_input_tokens_seen": 139800,
      "step": 70,
      "train_runtime": 108.3327,
      "train_tokens_per_second": 1290.469
    },
    {
      "epoch": 0.047058823529411764,
      "grad_norm": 0.43603888154029846,
      "learning_rate": 4.997046285486493e-05,
      "loss": 2.7509,
      "num_input_tokens_seen": 149552,
      "step": 75,
      "train_runtime": 115.8199,
      "train_tokens_per_second": 1291.247
    },
    {
      "epoch": 0.05019607843137255,
      "grad_norm": 0.37719863653182983,
      "learning_rate": 4.996633742684543e-05,
      "loss": 2.6913,
      "num_input_tokens_seen": 158432,
      "step": 80,
      "train_runtime": 122.6963,
      "train_tokens_per_second": 1291.254
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.46311894059181213,
      "learning_rate": 4.9961942612804744e-05,
      "loss": 2.7461,
      "num_input_tokens_seen": 168440,
      "step": 85,
      "train_runtime": 130.8218,
      "train_tokens_per_second": 1287.553
    },
    {
      "epoch": 0.05647058823529412,
      "grad_norm": 0.41264989972114563,
      "learning_rate": 4.99572784601628e-05,
      "loss": 2.7024,
      "num_input_tokens_seen": 178424,
      "step": 90,
      "train_runtime": 138.3103,
      "train_tokens_per_second": 1290.027
    },
    {
      "epoch": 0.0596078431372549,
      "grad_norm": 0.34755992889404297,
      "learning_rate": 4.995234501924564e-05,
      "loss": 2.727,
      "num_input_tokens_seen": 189136,
      "step": 95,
      "train_runtime": 146.3991,
      "train_tokens_per_second": 1291.92
    },
    {
      "epoch": 0.06274509803921569,
      "grad_norm": 0.39302435517311096,
      "learning_rate": 4.994714234328495e-05,
      "loss": 2.6372,
      "num_input_tokens_seen": 198592,
      "step": 100,
      "train_runtime": 153.8105,
      "train_tokens_per_second": 1291.147
    },
    {
      "epoch": 0.06274509803921569,
      "eval_loss": 2.7178611755371094,
      "eval_runtime": 79.1083,
      "eval_samples_per_second": 17.912,
      "eval_steps_per_second": 4.488,
      "num_input_tokens_seen": 198592,
      "step": 100
    },
    {
      "epoch": 0.06588235294117648,
      "grad_norm": 0.44956764578819275,
      "learning_rate": 4.994167048841745e-05,
      "loss": 2.8621,
      "num_input_tokens_seen": 208664,
      "step": 105,
      "train_runtime": 240.9785,
      "train_tokens_per_second": 865.903
    },
    {
      "epoch": 0.06901960784313725,
      "grad_norm": 0.39782530069351196,
      "learning_rate": 4.993592951368428e-05,
      "loss": 2.7425,
      "num_input_tokens_seen": 218944,
      "step": 110,
      "train_runtime": 248.6026,
      "train_tokens_per_second": 880.699
    },
    {
      "epoch": 0.07215686274509804,
      "grad_norm": 0.41498100757598877,
      "learning_rate": 4.992991948103038e-05,
      "loss": 2.6863,
      "num_input_tokens_seen": 229360,
      "step": 115,
      "train_runtime": 256.6145,
      "train_tokens_per_second": 893.792
    },
    {
      "epoch": 0.07529411764705882,
      "grad_norm": 0.4373573362827301,
      "learning_rate": 4.9923640455303825e-05,
      "loss": 2.7156,
      "num_input_tokens_seen": 239440,
      "step": 120,
      "train_runtime": 264.5213,
      "train_tokens_per_second": 905.182
    },
    {
      "epoch": 0.0784313725490196,
      "grad_norm": 0.41756996512413025,
      "learning_rate": 4.991709250425512e-05,
      "loss": 2.6696,
      "num_input_tokens_seen": 249312,
      "step": 125,
      "train_runtime": 272.2544,
      "train_tokens_per_second": 915.732
    },
    {
      "epoch": 0.0815686274509804,
      "grad_norm": 0.39251479506492615,
      "learning_rate": 4.9910275698536444e-05,
      "loss": 2.679,
      "num_input_tokens_seen": 259064,
      "step": 130,
      "train_runtime": 279.7828,
      "train_tokens_per_second": 925.947
    },
    {
      "epoch": 0.08470588235294117,
      "grad_norm": 0.36740830540657043,
      "learning_rate": 4.990319011170093e-05,
      "loss": 2.7737,
      "num_input_tokens_seen": 269640,
      "step": 135,
      "train_runtime": 288.0507,
      "train_tokens_per_second": 936.085
    },
    {
      "epoch": 0.08784313725490196,
      "grad_norm": 0.4052867591381073,
      "learning_rate": 4.9895835820201844e-05,
      "loss": 2.6691,
      "num_input_tokens_seen": 279496,
      "step": 140,
      "train_runtime": 295.4507,
      "train_tokens_per_second": 945.999
    },
    {
      "epoch": 0.09098039215686274,
      "grad_norm": 0.42238327860832214,
      "learning_rate": 4.988821290339177e-05,
      "loss": 2.6775,
      "num_input_tokens_seen": 289272,
      "step": 145,
      "train_runtime": 302.6144,
      "train_tokens_per_second": 955.91
    },
    {
      "epoch": 0.09411764705882353,
      "grad_norm": 0.41553300619125366,
      "learning_rate": 4.988032144352174e-05,
      "loss": 2.6155,
      "num_input_tokens_seen": 300552,
      "step": 150,
      "train_runtime": 310.8483,
      "train_tokens_per_second": 966.877
    },
    {
      "epoch": 0.09725490196078432,
      "grad_norm": 0.43640509247779846,
      "learning_rate": 4.987216152574037e-05,
      "loss": 2.7453,
      "num_input_tokens_seen": 310960,
      "step": 155,
      "train_runtime": 318.6609,
      "train_tokens_per_second": 975.833
    },
    {
      "epoch": 0.1003921568627451,
      "grad_norm": 0.47136497497558594,
      "learning_rate": 4.9863733238092923e-05,
      "loss": 2.6533,
      "num_input_tokens_seen": 320928,
      "step": 160,
      "train_runtime": 326.1463,
      "train_tokens_per_second": 984.0
    },
    {
      "epoch": 0.10352941176470588,
      "grad_norm": 0.4315975308418274,
      "learning_rate": 4.985503667152037e-05,
      "loss": 2.7047,
      "num_input_tokens_seen": 331200,
      "step": 165,
      "train_runtime": 334.0764,
      "train_tokens_per_second": 991.39
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.471259742975235,
      "learning_rate": 4.9846071919858405e-05,
      "loss": 2.7143,
      "num_input_tokens_seen": 340648,
      "step": 170,
      "train_runtime": 341.1903,
      "train_tokens_per_second": 998.411
    },
    {
      "epoch": 0.10980392156862745,
      "grad_norm": 0.42567387223243713,
      "learning_rate": 4.9836839079836417e-05,
      "loss": 2.803,
      "num_input_tokens_seen": 351376,
      "step": 175,
      "train_runtime": 349.4357,
      "train_tokens_per_second": 1005.553
    },
    {
      "epoch": 0.11294117647058824,
      "grad_norm": 0.4232335686683655,
      "learning_rate": 4.982733825107646e-05,
      "loss": 2.647,
      "num_input_tokens_seen": 360880,
      "step": 180,
      "train_runtime": 356.7855,
      "train_tokens_per_second": 1011.476
    },
    {
      "epoch": 0.11607843137254902,
      "grad_norm": 0.4474601745605469,
      "learning_rate": 4.981756953609221e-05,
      "loss": 2.6923,
      "num_input_tokens_seen": 370848,
      "step": 185,
      "train_runtime": 364.2305,
      "train_tokens_per_second": 1018.168
    },
    {
      "epoch": 0.1192156862745098,
      "grad_norm": 0.4367103576660156,
      "learning_rate": 4.980753304028779e-05,
      "loss": 2.6141,
      "num_input_tokens_seen": 380376,
      "step": 190,
      "train_runtime": 371.6392,
      "train_tokens_per_second": 1023.509
    },
    {
      "epoch": 0.1223529411764706,
      "grad_norm": 0.5607748031616211,
      "learning_rate": 4.979722887195669e-05,
      "loss": 2.6323,
      "num_input_tokens_seen": 390080,
      "step": 195,
      "train_runtime": 379.235,
      "train_tokens_per_second": 1028.597
    },
    {
      "epoch": 0.12549019607843137,
      "grad_norm": 0.512537956237793,
      "learning_rate": 4.978665714228057e-05,
      "loss": 2.6338,
      "num_input_tokens_seen": 399968,
      "step": 200,
      "train_runtime": 386.5894,
      "train_tokens_per_second": 1034.607
    },
    {
      "epoch": 0.12549019607843137,
      "eval_loss": 2.641113042831421,
      "eval_runtime": 79.0292,
      "eval_samples_per_second": 17.93,
      "eval_steps_per_second": 4.492,
      "num_input_tokens_seen": 399968,
      "step": 200
    },
    {
      "epoch": 0.12862745098039216,
      "grad_norm": 0.41931015253067017,
      "learning_rate": 4.977581796532806e-05,
      "loss": 2.7186,
      "num_input_tokens_seen": 410368,
      "step": 205,
      "train_runtime": 5785.791,
      "train_tokens_per_second": 70.927
    },
    {
      "epoch": 0.13176470588235295,
      "grad_norm": 0.48983481526374817,
      "learning_rate": 4.976471145805357e-05,
      "loss": 2.6236,
      "num_input_tokens_seen": 420480,
      "step": 210,
      "train_runtime": 5793.4307,
      "train_tokens_per_second": 72.579
    },
    {
      "epoch": 0.1349019607843137,
      "grad_norm": 0.4934830963611603,
      "learning_rate": 4.9753337740295965e-05,
      "loss": 2.7334,
      "num_input_tokens_seen": 431448,
      "step": 215,
      "train_runtime": 5801.2751,
      "train_tokens_per_second": 74.371
    },
    {
      "epoch": 0.1380392156862745,
      "grad_norm": 0.45192858576774597,
      "learning_rate": 4.9741696934777315e-05,
      "loss": 2.6816,
      "num_input_tokens_seen": 441496,
      "step": 220,
      "train_runtime": 5808.9802,
      "train_tokens_per_second": 76.002
    },
    {
      "epoch": 0.1411764705882353,
      "grad_norm": 0.5021040439605713,
      "learning_rate": 4.972978916710155e-05,
      "loss": 2.7425,
      "num_input_tokens_seen": 451800,
      "step": 225,
      "train_runtime": 5816.8724,
      "train_tokens_per_second": 77.671
    },
    {
      "epoch": 0.14431372549019608,
      "grad_norm": 0.4833097457885742,
      "learning_rate": 4.971761456575314e-05,
      "loss": 2.5514,
      "num_input_tokens_seen": 461616,
      "step": 230,
      "train_runtime": 5824.3373,
      "train_tokens_per_second": 79.256
    },
    {
      "epoch": 0.14745098039215687,
      "grad_norm": 0.5558476448059082,
      "learning_rate": 4.970517326209564e-05,
      "loss": 2.6592,
      "num_input_tokens_seen": 471624,
      "step": 235,
      "train_runtime": 5831.9948,
      "train_tokens_per_second": 80.868
    },
    {
      "epoch": 0.15058823529411763,
      "grad_norm": 0.45112717151641846,
      "learning_rate": 4.9692465390370357e-05,
      "loss": 2.6684,
      "num_input_tokens_seen": 481168,
      "step": 240,
      "train_runtime": 5839.3547,
      "train_tokens_per_second": 82.401
    },
    {
      "epoch": 0.15372549019607842,
      "grad_norm": 0.4930727183818817,
      "learning_rate": 4.967949108769483e-05,
      "loss": 2.6217,
      "num_input_tokens_seen": 490560,
      "step": 245,
      "train_runtime": 5846.8041,
      "train_tokens_per_second": 83.902
    },
    {
      "epoch": 0.1568627450980392,
      "grad_norm": 0.48997873067855835,
      "learning_rate": 4.9666250494061395e-05,
      "loss": 2.733,
      "num_input_tokens_seen": 500552,
      "step": 250,
      "train_runtime": 5854.5386,
      "train_tokens_per_second": 85.498
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.46117955446243286,
      "learning_rate": 4.9652743752335644e-05,
      "loss": 2.6415,
      "num_input_tokens_seen": 510584,
      "step": 255,
      "train_runtime": 5862.3096,
      "train_tokens_per_second": 87.096
    },
    {
      "epoch": 0.1631372549019608,
      "grad_norm": 0.4935073256492615,
      "learning_rate": 4.963897100825492e-05,
      "loss": 2.627,
      "num_input_tokens_seen": 519912,
      "step": 260,
      "train_runtime": 5869.5007,
      "train_tokens_per_second": 88.579
    },
    {
      "epoch": 0.16627450980392156,
      "grad_norm": 0.4722680449485779,
      "learning_rate": 4.962493241042672e-05,
      "loss": 2.6729,
      "num_input_tokens_seen": 530592,
      "step": 265,
      "train_runtime": 5877.7664,
      "train_tokens_per_second": 90.271
    },
    {
      "epoch": 0.16941176470588235,
      "grad_norm": 0.6258450150489807,
      "learning_rate": 4.9610628110327063e-05,
      "loss": 2.7114,
      "num_input_tokens_seen": 540592,
      "step": 270,
      "train_runtime": 5885.4442,
      "train_tokens_per_second": 91.852
    },
    {
      "epoch": 0.17254901960784313,
      "grad_norm": 0.49714764952659607,
      "learning_rate": 4.9596058262298934e-05,
      "loss": 2.596,
      "num_input_tokens_seen": 550176,
      "step": 275,
      "train_runtime": 5893.2581,
      "train_tokens_per_second": 93.357
    },
    {
      "epoch": 0.17568627450980392,
      "grad_norm": 0.5349454879760742,
      "learning_rate": 4.958122302355054e-05,
      "loss": 2.5337,
      "num_input_tokens_seen": 559600,
      "step": 280,
      "train_runtime": 5900.583,
      "train_tokens_per_second": 94.838
    },
    {
      "epoch": 0.17882352941176471,
      "grad_norm": 0.47181767225265503,
      "learning_rate": 4.956612255415366e-05,
      "loss": 2.6774,
      "num_input_tokens_seen": 569456,
      "step": 285,
      "train_runtime": 5908.4714,
      "train_tokens_per_second": 96.38
    },
    {
      "epoch": 0.18196078431372548,
      "grad_norm": 0.5097237229347229,
      "learning_rate": 4.955075701704189e-05,
      "loss": 2.6302,
      "num_input_tokens_seen": 579360,
      "step": 290,
      "train_runtime": 5916.2088,
      "train_tokens_per_second": 97.928
    },
    {
      "epoch": 0.18509803921568627,
      "grad_norm": 0.5071718692779541,
      "learning_rate": 4.953512657800892e-05,
      "loss": 2.6357,
      "num_input_tokens_seen": 589480,
      "step": 295,
      "train_runtime": 5923.7931,
      "train_tokens_per_second": 99.511
    },
    {
      "epoch": 0.18823529411764706,
      "grad_norm": 0.5392372608184814,
      "learning_rate": 4.951923140570671e-05,
      "loss": 2.6291,
      "num_input_tokens_seen": 599240,
      "step": 300,
      "train_runtime": 5931.5034,
      "train_tokens_per_second": 101.027
    },
    {
      "epoch": 0.18823529411764706,
      "eval_loss": 2.597383499145508,
      "eval_runtime": 79.05,
      "eval_samples_per_second": 17.925,
      "eval_steps_per_second": 4.491,
      "num_input_tokens_seen": 599240,
      "step": 300
    },
    {
      "epoch": 0.19137254901960785,
      "grad_norm": 0.5104608535766602,
      "learning_rate": 4.9503071671643674e-05,
      "loss": 2.6263,
      "num_input_tokens_seen": 609656,
      "step": 305,
      "train_runtime": 6019.0808,
      "train_tokens_per_second": 101.287
    },
    {
      "epoch": 0.19450980392156864,
      "grad_norm": 0.48707348108291626,
      "learning_rate": 4.948664755018286e-05,
      "loss": 2.6636,
      "num_input_tokens_seen": 620328,
      "step": 310,
      "train_runtime": 6027.3443,
      "train_tokens_per_second": 102.919
    },
    {
      "epoch": 0.1976470588235294,
      "grad_norm": 0.5236952304840088,
      "learning_rate": 4.9469959218540044e-05,
      "loss": 2.6038,
      "num_input_tokens_seen": 630136,
      "step": 315,
      "train_runtime": 6034.635,
      "train_tokens_per_second": 104.42
    },
    {
      "epoch": 0.2007843137254902,
      "grad_norm": 0.5233825445175171,
      "learning_rate": 4.94530068567818e-05,
      "loss": 2.5902,
      "num_input_tokens_seen": 640016,
      "step": 320,
      "train_runtime": 6042.1538,
      "train_tokens_per_second": 105.925
    },
    {
      "epoch": 0.20392156862745098,
      "grad_norm": 0.5460997819900513,
      "learning_rate": 4.943579064782361e-05,
      "loss": 2.5385,
      "num_input_tokens_seen": 648736,
      "step": 325,
      "train_runtime": 6049.1618,
      "train_tokens_per_second": 107.244
    },
    {
      "epoch": 0.20705882352941177,
      "grad_norm": 0.47648918628692627,
      "learning_rate": 4.941831077742785e-05,
      "loss": 2.5057,
      "num_input_tokens_seen": 658448,
      "step": 330,
      "train_runtime": 6056.5898,
      "train_tokens_per_second": 108.716
    },
    {
      "epoch": 0.21019607843137256,
      "grad_norm": 0.48275500535964966,
      "learning_rate": 4.9400567434201766e-05,
      "loss": 2.6271,
      "num_input_tokens_seen": 669168,
      "step": 335,
      "train_runtime": 6064.9201,
      "train_tokens_per_second": 110.334
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.4657118618488312,
      "learning_rate": 4.9382560809595515e-05,
      "loss": 2.621,
      "num_input_tokens_seen": 678920,
      "step": 340,
      "train_runtime": 6072.4632,
      "train_tokens_per_second": 111.803
    },
    {
      "epoch": 0.2164705882352941,
      "grad_norm": 0.46877434849739075,
      "learning_rate": 4.936429109790002e-05,
      "loss": 2.5874,
      "num_input_tokens_seen": 688640,
      "step": 345,
      "train_runtime": 6079.9727,
      "train_tokens_per_second": 113.264
    },
    {
      "epoch": 0.2196078431372549,
      "grad_norm": 0.4958241581916809,
      "learning_rate": 4.93457584962449e-05,
      "loss": 2.484,
      "num_input_tokens_seen": 698552,
      "step": 350,
      "train_runtime": 6087.4565,
      "train_tokens_per_second": 114.753
    },
    {
      "epoch": 0.2227450980392157,
      "grad_norm": 0.5668659806251526,
      "learning_rate": 4.9326963204596386e-05,
      "loss": 2.5171,
      "num_input_tokens_seen": 707992,
      "step": 355,
      "train_runtime": 6094.8963,
      "train_tokens_per_second": 116.161
    },
    {
      "epoch": 0.22588235294117648,
      "grad_norm": 0.5598688125610352,
      "learning_rate": 4.93079054257551e-05,
      "loss": 2.6353,
      "num_input_tokens_seen": 717624,
      "step": 360,
      "train_runtime": 6102.1861,
      "train_tokens_per_second": 117.601
    },
    {
      "epoch": 0.22901960784313727,
      "grad_norm": 0.4780464172363281,
      "learning_rate": 4.928858536535388e-05,
      "loss": 2.5771,
      "num_input_tokens_seen": 727784,
      "step": 365,
      "train_runtime": 6110.2399,
      "train_tokens_per_second": 119.109
    },
    {
      "epoch": 0.23215686274509803,
      "grad_norm": 0.5444279909133911,
      "learning_rate": 4.9269003231855605e-05,
      "loss": 2.6535,
      "num_input_tokens_seen": 737728,
      "step": 370,
      "train_runtime": 6117.8474,
      "train_tokens_per_second": 120.586
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 0.481660395860672,
      "learning_rate": 4.924915923655089e-05,
      "loss": 2.6687,
      "num_input_tokens_seen": 747608,
      "step": 375,
      "train_runtime": 6125.7324,
      "train_tokens_per_second": 122.044
    },
    {
      "epoch": 0.2384313725490196,
      "grad_norm": 0.5033976435661316,
      "learning_rate": 4.922905359355585e-05,
      "loss": 2.6466,
      "num_input_tokens_seen": 757392,
      "step": 380,
      "train_runtime": 6133.4113,
      "train_tokens_per_second": 123.486
    },
    {
      "epoch": 0.2415686274509804,
      "grad_norm": 0.4847785234451294,
      "learning_rate": 4.920868651980976e-05,
      "loss": 2.5742,
      "num_input_tokens_seen": 767816,
      "step": 385,
      "train_runtime": 6141.4462,
      "train_tokens_per_second": 125.022
    },
    {
      "epoch": 0.2447058823529412,
      "grad_norm": 0.5548862814903259,
      "learning_rate": 4.9188058235072706e-05,
      "loss": 2.646,
      "num_input_tokens_seen": 778040,
      "step": 390,
      "train_runtime": 6149.1053,
      "train_tokens_per_second": 126.529
    },
    {
      "epoch": 0.24784313725490195,
      "grad_norm": 0.5230933427810669,
      "learning_rate": 4.9167168961923275e-05,
      "loss": 2.601,
      "num_input_tokens_seen": 788200,
      "step": 395,
      "train_runtime": 6156.8844,
      "train_tokens_per_second": 128.019
    },
    {
      "epoch": 0.25098039215686274,
      "grad_norm": 0.5395885109901428,
      "learning_rate": 4.914601892575609e-05,
      "loss": 2.5407,
      "num_input_tokens_seen": 797480,
      "step": 400,
      "train_runtime": 6164.0738,
      "train_tokens_per_second": 129.375
    },
    {
      "epoch": 0.25098039215686274,
      "eval_loss": 2.564253568649292,
      "eval_runtime": 78.9856,
      "eval_samples_per_second": 17.94,
      "eval_steps_per_second": 4.494,
      "num_input_tokens_seen": 797480,
      "step": 400
    },
    {
      "epoch": 0.2541176470588235,
      "grad_norm": 0.5136088132858276,
      "learning_rate": 4.912460835477938e-05,
      "loss": 2.5215,
      "num_input_tokens_seen": 807200,
      "step": 405,
      "train_runtime": 6251.4226,
      "train_tokens_per_second": 129.123
    },
    {
      "epoch": 0.2572549019607843,
      "grad_norm": 0.5516197085380554,
      "learning_rate": 4.910293748001257e-05,
      "loss": 2.5448,
      "num_input_tokens_seen": 816832,
      "step": 410,
      "train_runtime": 6258.9261,
      "train_tokens_per_second": 130.507
    },
    {
      "epoch": 0.2603921568627451,
      "grad_norm": 0.5257452130317688,
      "learning_rate": 4.908100653528373e-05,
      "loss": 2.5249,
      "num_input_tokens_seen": 826984,
      "step": 415,
      "train_runtime": 6266.5121,
      "train_tokens_per_second": 131.969
    },
    {
      "epoch": 0.2635294117647059,
      "grad_norm": 0.5144187808036804,
      "learning_rate": 4.9058815757227085e-05,
      "loss": 2.6322,
      "num_input_tokens_seen": 837360,
      "step": 420,
      "train_runtime": 6274.3297,
      "train_tokens_per_second": 133.458
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.536223292350769,
      "learning_rate": 4.903636538528047e-05,
      "loss": 2.5101,
      "num_input_tokens_seen": 846528,
      "step": 425,
      "train_runtime": 6281.276,
      "train_tokens_per_second": 134.77
    },
    {
      "epoch": 0.2698039215686274,
      "grad_norm": 0.5372048616409302,
      "learning_rate": 4.90136556616827e-05,
      "loss": 2.5025,
      "num_input_tokens_seen": 856464,
      "step": 430,
      "train_runtime": 6288.7478,
      "train_tokens_per_second": 136.19
    },
    {
      "epoch": 0.27294117647058824,
      "grad_norm": 0.57784503698349,
      "learning_rate": 4.899068683147101e-05,
      "loss": 2.4754,
      "num_input_tokens_seen": 865920,
      "step": 435,
      "train_runtime": 6296.1376,
      "train_tokens_per_second": 137.532
    },
    {
      "epoch": 0.276078431372549,
      "grad_norm": 0.5348315238952637,
      "learning_rate": 4.8967459142478365e-05,
      "loss": 2.5817,
      "num_input_tokens_seen": 876056,
      "step": 440,
      "train_runtime": 6303.8787,
      "train_tokens_per_second": 138.971
    },
    {
      "epoch": 0.2792156862745098,
      "grad_norm": 0.5450997352600098,
      "learning_rate": 4.8943972845330846e-05,
      "loss": 2.5431,
      "num_input_tokens_seen": 886928,
      "step": 445,
      "train_runtime": 6312.0374,
      "train_tokens_per_second": 140.514
    },
    {
      "epoch": 0.2823529411764706,
      "grad_norm": 0.5805138945579529,
      "learning_rate": 4.8920228193444866e-05,
      "loss": 2.4341,
      "num_input_tokens_seen": 897032,
      "step": 450,
      "train_runtime": 6319.7259,
      "train_tokens_per_second": 141.942
    },
    {
      "epoch": 0.28549019607843135,
      "grad_norm": 0.5752728581428528,
      "learning_rate": 4.88962254430245e-05,
      "loss": 2.5034,
      "num_input_tokens_seen": 906464,
      "step": 455,
      "train_runtime": 6327.1291,
      "train_tokens_per_second": 143.266
    },
    {
      "epoch": 0.28862745098039216,
      "grad_norm": 0.5603885054588318,
      "learning_rate": 4.88719648530587e-05,
      "loss": 2.5268,
      "num_input_tokens_seen": 916328,
      "step": 460,
      "train_runtime": 6334.7949,
      "train_tokens_per_second": 144.65
    },
    {
      "epoch": 0.2917647058823529,
      "grad_norm": 0.5249251127243042,
      "learning_rate": 4.8847446685318496e-05,
      "loss": 2.6959,
      "num_input_tokens_seen": 926200,
      "step": 465,
      "train_runtime": 6342.5645,
      "train_tokens_per_second": 146.029
    },
    {
      "epoch": 0.29490196078431374,
      "grad_norm": 0.5488168001174927,
      "learning_rate": 4.8822671204354156e-05,
      "loss": 2.587,
      "num_input_tokens_seen": 936328,
      "step": 470,
      "train_runtime": 6350.334,
      "train_tokens_per_second": 147.445
    },
    {
      "epoch": 0.2980392156862745,
      "grad_norm": 0.525848388671875,
      "learning_rate": 4.879763867749238e-05,
      "loss": 2.4996,
      "num_input_tokens_seen": 946624,
      "step": 475,
      "train_runtime": 6357.9823,
      "train_tokens_per_second": 148.887
    },
    {
      "epoch": 0.30117647058823527,
      "grad_norm": 0.5520021915435791,
      "learning_rate": 4.877234937483337e-05,
      "loss": 2.5415,
      "num_input_tokens_seen": 956456,
      "step": 480,
      "train_runtime": 6365.4917,
      "train_tokens_per_second": 150.256
    },
    {
      "epoch": 0.3043137254901961,
      "grad_norm": 0.5563669204711914,
      "learning_rate": 4.874680356924794e-05,
      "loss": 2.4769,
      "num_input_tokens_seen": 966672,
      "step": 485,
      "train_runtime": 6373.1829,
      "train_tokens_per_second": 151.678
    },
    {
      "epoch": 0.30745098039215685,
      "grad_norm": 0.5615142583847046,
      "learning_rate": 4.872100153637452e-05,
      "loss": 2.5069,
      "num_input_tokens_seen": 975872,
      "step": 490,
      "train_runtime": 6380.3184,
      "train_tokens_per_second": 152.95
    },
    {
      "epoch": 0.31058823529411766,
      "grad_norm": 0.5673580169677734,
      "learning_rate": 4.86949435546163e-05,
      "loss": 2.512,
      "num_input_tokens_seen": 986216,
      "step": 495,
      "train_runtime": 6388.1232,
      "train_tokens_per_second": 154.383
    },
    {
      "epoch": 0.3137254901960784,
      "grad_norm": 0.4998670518398285,
      "learning_rate": 4.866862990513809e-05,
      "loss": 2.537,
      "num_input_tokens_seen": 996496,
      "step": 500,
      "train_runtime": 6395.9254,
      "train_tokens_per_second": 155.802
    },
    {
      "epoch": 0.3137254901960784,
      "eval_loss": 2.5398237705230713,
      "eval_runtime": 78.9646,
      "eval_samples_per_second": 17.945,
      "eval_steps_per_second": 4.496,
      "num_input_tokens_seen": 996496,
      "step": 500
    },
    {
      "epoch": 0.3168627450980392,
      "grad_norm": 0.5283766388893127,
      "learning_rate": 4.864206087186337e-05,
      "loss": 2.536,
      "num_input_tokens_seen": 1006200,
      "step": 505,
      "train_runtime": 6482.8357,
      "train_tokens_per_second": 155.21
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5952720046043396,
      "learning_rate": 4.86152367414712e-05,
      "loss": 2.5578,
      "num_input_tokens_seen": 1016112,
      "step": 510,
      "train_runtime": 6490.2031,
      "train_tokens_per_second": 156.561
    },
    {
      "epoch": 0.32313725490196077,
      "grad_norm": 0.58757483959198,
      "learning_rate": 4.8588157803393145e-05,
      "loss": 2.4973,
      "num_input_tokens_seen": 1025480,
      "step": 515,
      "train_runtime": 6497.213,
      "train_tokens_per_second": 157.834
    },
    {
      "epoch": 0.3262745098039216,
      "grad_norm": 0.5367328524589539,
      "learning_rate": 4.856082434981011e-05,
      "loss": 2.6248,
      "num_input_tokens_seen": 1035392,
      "step": 520,
      "train_runtime": 6504.6088,
      "train_tokens_per_second": 159.178
    },
    {
      "epoch": 0.32941176470588235,
      "grad_norm": 0.5324177145957947,
      "learning_rate": 4.853323667564922e-05,
      "loss": 2.4832,
      "num_input_tokens_seen": 1045600,
      "step": 525,
      "train_runtime": 6512.2859,
      "train_tokens_per_second": 160.558
    },
    {
      "epoch": 0.3325490196078431,
      "grad_norm": 0.6029167175292969,
      "learning_rate": 4.8505395078580654e-05,
      "loss": 2.6331,
      "num_input_tokens_seen": 1055696,
      "step": 530,
      "train_runtime": 6519.9881,
      "train_tokens_per_second": 161.917
    },
    {
      "epoch": 0.33568627450980393,
      "grad_norm": 0.5905550718307495,
      "learning_rate": 4.847729985901438e-05,
      "loss": 2.5244,
      "num_input_tokens_seen": 1065920,
      "step": 535,
      "train_runtime": 6527.7364,
      "train_tokens_per_second": 163.291
    },
    {
      "epoch": 0.3388235294117647,
      "grad_norm": 0.5590980052947998,
      "learning_rate": 4.844895132009698e-05,
      "loss": 2.6055,
      "num_input_tokens_seen": 1075440,
      "step": 540,
      "train_runtime": 6534.9962,
      "train_tokens_per_second": 164.566
    },
    {
      "epoch": 0.3419607843137255,
      "grad_norm": 0.6178556680679321,
      "learning_rate": 4.842034976770833e-05,
      "loss": 2.5016,
      "num_input_tokens_seen": 1085088,
      "step": 545,
      "train_runtime": 6542.3488,
      "train_tokens_per_second": 165.856
    },
    {
      "epoch": 0.34509803921568627,
      "grad_norm": 0.5607447624206543,
      "learning_rate": 4.8391495510458285e-05,
      "loss": 2.5079,
      "num_input_tokens_seen": 1095144,
      "step": 550,
      "train_runtime": 6549.9791,
      "train_tokens_per_second": 167.198
    },
    {
      "epoch": 0.34823529411764703,
      "grad_norm": 0.5611007809638977,
      "learning_rate": 4.836238885968343e-05,
      "loss": 2.5838,
      "num_input_tokens_seen": 1104632,
      "step": 555,
      "train_runtime": 6557.5926,
      "train_tokens_per_second": 168.451
    },
    {
      "epoch": 0.35137254901960785,
      "grad_norm": 0.5743986368179321,
      "learning_rate": 4.8333030129443624e-05,
      "loss": 2.4007,
      "num_input_tokens_seen": 1113392,
      "step": 560,
      "train_runtime": 6564.5107,
      "train_tokens_per_second": 169.608
    },
    {
      "epoch": 0.3545098039215686,
      "grad_norm": 0.5047318935394287,
      "learning_rate": 4.830341963651868e-05,
      "loss": 2.4873,
      "num_input_tokens_seen": 1123584,
      "step": 565,
      "train_runtime": 6572.5955,
      "train_tokens_per_second": 170.95
    },
    {
      "epoch": 0.35764705882352943,
      "grad_norm": 0.6053910851478577,
      "learning_rate": 4.8273557700404904e-05,
      "loss": 2.551,
      "num_input_tokens_seen": 1134120,
      "step": 570,
      "train_runtime": 6580.4432,
      "train_tokens_per_second": 172.347
    },
    {
      "epoch": 0.3607843137254902,
      "grad_norm": 0.5575987696647644,
      "learning_rate": 4.82434446433117e-05,
      "loss": 2.4852,
      "num_input_tokens_seen": 1143488,
      "step": 575,
      "train_runtime": 6587.5983,
      "train_tokens_per_second": 173.582
    },
    {
      "epoch": 0.36392156862745095,
      "grad_norm": 0.5938050150871277,
      "learning_rate": 4.821308079015802e-05,
      "loss": 2.4929,
      "num_input_tokens_seen": 1153816,
      "step": 580,
      "train_runtime": 6595.5555,
      "train_tokens_per_second": 174.938
    },
    {
      "epoch": 0.36705882352941177,
      "grad_norm": 0.5335080027580261,
      "learning_rate": 4.818246646856892e-05,
      "loss": 2.5064,
      "num_input_tokens_seen": 1164272,
      "step": 585,
      "train_runtime": 6603.4782,
      "train_tokens_per_second": 176.312
    },
    {
      "epoch": 0.37019607843137253,
      "grad_norm": 0.5616726875305176,
      "learning_rate": 4.8151602008872e-05,
      "loss": 2.5112,
      "num_input_tokens_seen": 1173544,
      "step": 590,
      "train_runtime": 6610.6655,
      "train_tokens_per_second": 177.523
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.5382565259933472,
      "learning_rate": 4.8120487744093845e-05,
      "loss": 2.5313,
      "num_input_tokens_seen": 1183000,
      "step": 595,
      "train_runtime": 6617.9416,
      "train_tokens_per_second": 178.756
    },
    {
      "epoch": 0.3764705882352941,
      "grad_norm": 0.5887882113456726,
      "learning_rate": 4.808912400995642e-05,
      "loss": 2.5495,
      "num_input_tokens_seen": 1193344,
      "step": 600,
      "train_runtime": 6625.795,
      "train_tokens_per_second": 180.106
    },
    {
      "epoch": 0.3764705882352941,
      "eval_loss": 2.5160043239593506,
      "eval_runtime": 79.0059,
      "eval_samples_per_second": 17.935,
      "eval_steps_per_second": 4.493,
      "num_input_tokens_seen": 1193344,
      "step": 600
    },
    {
      "epoch": 0.3796078431372549,
      "grad_norm": 0.5769166350364685,
      "learning_rate": 4.8057511144873454e-05,
      "loss": 2.4764,
      "num_input_tokens_seen": 1203152,
      "step": 605,
      "train_runtime": 6712.7511,
      "train_tokens_per_second": 179.234
    },
    {
      "epoch": 0.3827450980392157,
      "grad_norm": 0.5839141607284546,
      "learning_rate": 4.8025649489946825e-05,
      "loss": 2.5828,
      "num_input_tokens_seen": 1213984,
      "step": 610,
      "train_runtime": 6720.5492,
      "train_tokens_per_second": 180.638
    },
    {
      "epoch": 0.38588235294117645,
      "grad_norm": 0.6097751259803772,
      "learning_rate": 4.799353938896279e-05,
      "loss": 2.62,
      "num_input_tokens_seen": 1224264,
      "step": 615,
      "train_runtime": 6728.2704,
      "train_tokens_per_second": 181.958
    },
    {
      "epoch": 0.38901960784313727,
      "grad_norm": 0.6351765394210815,
      "learning_rate": 4.796118118838838e-05,
      "loss": 2.544,
      "num_input_tokens_seen": 1233880,
      "step": 620,
      "train_runtime": 6735.7688,
      "train_tokens_per_second": 183.183
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.5702975392341614,
      "learning_rate": 4.792857523736759e-05,
      "loss": 2.4804,
      "num_input_tokens_seen": 1243928,
      "step": 625,
      "train_runtime": 6743.5023,
      "train_tokens_per_second": 184.463
    },
    {
      "epoch": 0.3952941176470588,
      "grad_norm": 0.6154722571372986,
      "learning_rate": 4.7895721887717634e-05,
      "loss": 2.4892,
      "num_input_tokens_seen": 1253968,
      "step": 630,
      "train_runtime": 6751.0048,
      "train_tokens_per_second": 185.745
    },
    {
      "epoch": 0.3984313725490196,
      "grad_norm": 0.5615729689598083,
      "learning_rate": 4.786262149392516e-05,
      "loss": 2.608,
      "num_input_tokens_seen": 1264480,
      "step": 635,
      "train_runtime": 6758.901,
      "train_tokens_per_second": 187.084
    },
    {
      "epoch": 0.4015686274509804,
      "grad_norm": 0.5514077544212341,
      "learning_rate": 4.782927441314242e-05,
      "loss": 2.5558,
      "num_input_tokens_seen": 1274576,
      "step": 640,
      "train_runtime": 6766.6088,
      "train_tokens_per_second": 188.363
    },
    {
      "epoch": 0.4047058823529412,
      "grad_norm": 0.6199583411216736,
      "learning_rate": 4.779568100518338e-05,
      "loss": 2.5062,
      "num_input_tokens_seen": 1284920,
      "step": 645,
      "train_runtime": 6774.3604,
      "train_tokens_per_second": 189.674
    },
    {
      "epoch": 0.40784313725490196,
      "grad_norm": 0.5495561361312866,
      "learning_rate": 4.776184163251991e-05,
      "loss": 2.5705,
      "num_input_tokens_seen": 1294984,
      "step": 650,
      "train_runtime": 6781.9706,
      "train_tokens_per_second": 190.945
    },
    {
      "epoch": 0.4109803921568628,
      "grad_norm": 0.5298417210578918,
      "learning_rate": 4.77277566602778e-05,
      "loss": 2.5165,
      "num_input_tokens_seen": 1305072,
      "step": 655,
      "train_runtime": 6789.6031,
      "train_tokens_per_second": 192.216
    },
    {
      "epoch": 0.41411764705882353,
      "grad_norm": 0.5484311580657959,
      "learning_rate": 4.769342645623287e-05,
      "loss": 2.3824,
      "num_input_tokens_seen": 1314576,
      "step": 660,
      "train_runtime": 6796.8449,
      "train_tokens_per_second": 193.41
    },
    {
      "epoch": 0.4172549019607843,
      "grad_norm": 0.5728543996810913,
      "learning_rate": 4.7658851390806966e-05,
      "loss": 2.5103,
      "num_input_tokens_seen": 1325656,
      "step": 665,
      "train_runtime": 6805.1236,
      "train_tokens_per_second": 194.803
    },
    {
      "epoch": 0.4203921568627451,
      "grad_norm": 0.5782161951065063,
      "learning_rate": 4.7624031837064e-05,
      "loss": 2.5798,
      "num_input_tokens_seen": 1335968,
      "step": 670,
      "train_runtime": 6812.7282,
      "train_tokens_per_second": 196.099
    },
    {
      "epoch": 0.4235294117647059,
      "grad_norm": 0.6091198325157166,
      "learning_rate": 4.758896817070589e-05,
      "loss": 2.3908,
      "num_input_tokens_seen": 1345336,
      "step": 675,
      "train_runtime": 6820.1083,
      "train_tokens_per_second": 197.26
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.5850216150283813,
      "learning_rate": 4.755366077006854e-05,
      "loss": 2.4836,
      "num_input_tokens_seen": 1354520,
      "step": 680,
      "train_runtime": 6827.2618,
      "train_tokens_per_second": 198.399
    },
    {
      "epoch": 0.42980392156862746,
      "grad_norm": 0.6599279046058655,
      "learning_rate": 4.751811001611773e-05,
      "loss": 2.3961,
      "num_input_tokens_seen": 1363592,
      "step": 685,
      "train_runtime": 6834.0025,
      "train_tokens_per_second": 199.531
    },
    {
      "epoch": 0.4329411764705882,
      "grad_norm": 0.5370057225227356,
      "learning_rate": 4.7482316292445e-05,
      "loss": 2.4846,
      "num_input_tokens_seen": 1373848,
      "step": 690,
      "train_runtime": 6841.8122,
      "train_tokens_per_second": 200.802
    },
    {
      "epoch": 0.43607843137254904,
      "grad_norm": 0.637239396572113,
      "learning_rate": 4.744627998526355e-05,
      "loss": 2.4529,
      "num_input_tokens_seen": 1383224,
      "step": 695,
      "train_runtime": 6848.9199,
      "train_tokens_per_second": 201.962
    },
    {
      "epoch": 0.4392156862745098,
      "grad_norm": 0.652159571647644,
      "learning_rate": 4.741000148340403e-05,
      "loss": 2.5732,
      "num_input_tokens_seen": 1392880,
      "step": 700,
      "train_runtime": 6856.3958,
      "train_tokens_per_second": 203.15
    },
    {
      "epoch": 0.4392156862745098,
      "eval_loss": 2.4971046447753906,
      "eval_runtime": 79.0147,
      "eval_samples_per_second": 17.933,
      "eval_steps_per_second": 4.493,
      "num_input_tokens_seen": 1392880,
      "step": 700
    },
    {
      "epoch": 0.4423529411764706,
      "grad_norm": 0.5866276025772095,
      "learning_rate": 4.737348117831038e-05,
      "loss": 2.5511,
      "num_input_tokens_seen": 1403144,
      "step": 705,
      "train_runtime": 6943.8516,
      "train_tokens_per_second": 202.07
    },
    {
      "epoch": 0.4454901960784314,
      "grad_norm": 0.6479606032371521,
      "learning_rate": 4.733671946403557e-05,
      "loss": 2.4735,
      "num_input_tokens_seen": 1412688,
      "step": 710,
      "train_runtime": 6951.3006,
      "train_tokens_per_second": 203.226
    },
    {
      "epoch": 0.44862745098039214,
      "grad_norm": 0.662810206413269,
      "learning_rate": 4.72997167372374e-05,
      "loss": 2.5025,
      "num_input_tokens_seen": 1422448,
      "step": 715,
      "train_runtime": 6958.6176,
      "train_tokens_per_second": 204.415
    },
    {
      "epoch": 0.45176470588235296,
      "grad_norm": 0.6748553514480591,
      "learning_rate": 4.726247339717413e-05,
      "loss": 2.5285,
      "num_input_tokens_seen": 1432464,
      "step": 720,
      "train_runtime": 6966.1559,
      "train_tokens_per_second": 205.632
    },
    {
      "epoch": 0.4549019607843137,
      "grad_norm": 0.6021032333374023,
      "learning_rate": 4.7224989845700306e-05,
      "loss": 2.3935,
      "num_input_tokens_seen": 1441856,
      "step": 725,
      "train_runtime": 6973.4674,
      "train_tokens_per_second": 206.763
    },
    {
      "epoch": 0.45803921568627454,
      "grad_norm": 0.6572718620300293,
      "learning_rate": 4.7187266487262284e-05,
      "loss": 2.5518,
      "num_input_tokens_seen": 1451888,
      "step": 730,
      "train_runtime": 6981.1693,
      "train_tokens_per_second": 207.972
    },
    {
      "epoch": 0.4611764705882353,
      "grad_norm": 0.6463992595672607,
      "learning_rate": 4.7149303728893956e-05,
      "loss": 2.4856,
      "num_input_tokens_seen": 1461680,
      "step": 735,
      "train_runtime": 6988.8079,
      "train_tokens_per_second": 209.146
    },
    {
      "epoch": 0.46431372549019606,
      "grad_norm": 0.5749015808105469,
      "learning_rate": 4.711110198021233e-05,
      "loss": 2.3353,
      "num_input_tokens_seen": 1470840,
      "step": 740,
      "train_runtime": 6996.0171,
      "train_tokens_per_second": 210.24
    },
    {
      "epoch": 0.4674509803921569,
      "grad_norm": 0.6387057304382324,
      "learning_rate": 4.707266165341312e-05,
      "loss": 2.448,
      "num_input_tokens_seen": 1479880,
      "step": 745,
      "train_runtime": 7003.1228,
      "train_tokens_per_second": 211.317
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 0.6073511838912964,
      "learning_rate": 4.703398316326627e-05,
      "loss": 2.5035,
      "num_input_tokens_seen": 1489448,
      "step": 750,
      "train_runtime": 7010.4903,
      "train_tokens_per_second": 212.46
    },
    {
      "epoch": 0.47372549019607846,
      "grad_norm": 0.6541305184364319,
      "learning_rate": 4.6995066927111524e-05,
      "loss": 2.5472,
      "num_input_tokens_seen": 1499928,
      "step": 755,
      "train_runtime": 7018.2637,
      "train_tokens_per_second": 213.718
    },
    {
      "epoch": 0.4768627450980392,
      "grad_norm": 0.5419087409973145,
      "learning_rate": 4.695591336485388e-05,
      "loss": 2.4434,
      "num_input_tokens_seen": 1509528,
      "step": 760,
      "train_runtime": 7025.7298,
      "train_tokens_per_second": 214.857
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5220917463302612,
      "learning_rate": 4.6916522898959086e-05,
      "loss": 2.4268,
      "num_input_tokens_seen": 1519640,
      "step": 765,
      "train_runtime": 7033.3206,
      "train_tokens_per_second": 216.063
    },
    {
      "epoch": 0.4831372549019608,
      "grad_norm": 0.5604806542396545,
      "learning_rate": 4.687689595444907e-05,
      "loss": 2.41,
      "num_input_tokens_seen": 1529672,
      "step": 770,
      "train_runtime": 7041.0079,
      "train_tokens_per_second": 217.252
    },
    {
      "epoch": 0.48627450980392156,
      "grad_norm": 0.5829799771308899,
      "learning_rate": 4.6837032958897356e-05,
      "loss": 2.4461,
      "num_input_tokens_seen": 1539208,
      "step": 775,
      "train_runtime": 7048.4121,
      "train_tokens_per_second": 218.377
    },
    {
      "epoch": 0.4894117647058824,
      "grad_norm": 0.6496432423591614,
      "learning_rate": 4.6796934342424445e-05,
      "loss": 2.4963,
      "num_input_tokens_seen": 1548520,
      "step": 780,
      "train_runtime": 7055.5584,
      "train_tokens_per_second": 219.475
    },
    {
      "epoch": 0.49254901960784314,
      "grad_norm": 0.6338433027267456,
      "learning_rate": 4.675660053769321e-05,
      "loss": 2.3935,
      "num_input_tokens_seen": 1557792,
      "step": 785,
      "train_runtime": 7062.5989,
      "train_tokens_per_second": 220.569
    },
    {
      "epoch": 0.4956862745098039,
      "grad_norm": 0.6406744122505188,
      "learning_rate": 4.671603197990415e-05,
      "loss": 2.4852,
      "num_input_tokens_seen": 1567312,
      "step": 790,
      "train_runtime": 7070.0194,
      "train_tokens_per_second": 221.684
    },
    {
      "epoch": 0.4988235294117647,
      "grad_norm": 0.6795670390129089,
      "learning_rate": 4.66752291067908e-05,
      "loss": 2.4494,
      "num_input_tokens_seen": 1577720,
      "step": 795,
      "train_runtime": 7077.6731,
      "train_tokens_per_second": 222.915
    },
    {
      "epoch": 0.5019607843137255,
      "grad_norm": 0.6234440803527832,
      "learning_rate": 4.6634192358614884e-05,
      "loss": 2.5521,
      "num_input_tokens_seen": 1588240,
      "step": 800,
      "train_runtime": 7085.6837,
      "train_tokens_per_second": 224.148
    },
    {
      "epoch": 0.5019607843137255,
      "eval_loss": 2.479255199432373,
      "eval_runtime": 79.0404,
      "eval_samples_per_second": 17.928,
      "eval_steps_per_second": 4.491,
      "num_input_tokens_seen": 1588240,
      "step": 800
    },
    {
      "epoch": 0.5050980392156863,
      "grad_norm": 0.5974446535110474,
      "learning_rate": 4.65929221781617e-05,
      "loss": 2.5208,
      "num_input_tokens_seen": 1599064,
      "step": 805,
      "train_runtime": 7173.3567,
      "train_tokens_per_second": 222.917
    },
    {
      "epoch": 0.508235294117647,
      "grad_norm": 0.681511402130127,
      "learning_rate": 4.655141901073521e-05,
      "loss": 2.4341,
      "num_input_tokens_seen": 1609208,
      "step": 810,
      "train_runtime": 7180.9853,
      "train_tokens_per_second": 224.093
    },
    {
      "epoch": 0.5113725490196078,
      "grad_norm": 0.6587338447570801,
      "learning_rate": 4.650968330415335e-05,
      "loss": 2.4686,
      "num_input_tokens_seen": 1619072,
      "step": 815,
      "train_runtime": 7188.4917,
      "train_tokens_per_second": 225.231
    },
    {
      "epoch": 0.5145098039215686,
      "grad_norm": 0.7152983546257019,
      "learning_rate": 4.6467715508743116e-05,
      "loss": 2.4608,
      "num_input_tokens_seen": 1628536,
      "step": 820,
      "train_runtime": 7195.9772,
      "train_tokens_per_second": 226.312
    },
    {
      "epoch": 0.5176470588235295,
      "grad_norm": 0.6825945377349854,
      "learning_rate": 4.642551607733574e-05,
      "loss": 2.4701,
      "num_input_tokens_seen": 1638216,
      "step": 825,
      "train_runtime": 7203.7558,
      "train_tokens_per_second": 227.411
    },
    {
      "epoch": 0.5207843137254902,
      "grad_norm": 0.6281355619430542,
      "learning_rate": 4.6383085465261814e-05,
      "loss": 2.4438,
      "num_input_tokens_seen": 1648024,
      "step": 830,
      "train_runtime": 7211.3057,
      "train_tokens_per_second": 228.533
    },
    {
      "epoch": 0.523921568627451,
      "grad_norm": 0.706447422504425,
      "learning_rate": 4.6340424130346336e-05,
      "loss": 2.4922,
      "num_input_tokens_seen": 1657736,
      "step": 835,
      "train_runtime": 7218.8623,
      "train_tokens_per_second": 229.64
    },
    {
      "epoch": 0.5270588235294118,
      "grad_norm": 0.5869824290275574,
      "learning_rate": 4.6297532532903815e-05,
      "loss": 2.5927,
      "num_input_tokens_seen": 1667664,
      "step": 840,
      "train_runtime": 7226.4538,
      "train_tokens_per_second": 230.772
    },
    {
      "epoch": 0.5301960784313725,
      "grad_norm": 0.6340280175209045,
      "learning_rate": 4.625441113573329e-05,
      "loss": 2.553,
      "num_input_tokens_seen": 1677704,
      "step": 845,
      "train_runtime": 7234.1713,
      "train_tokens_per_second": 231.914
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.6580165028572083,
      "learning_rate": 4.6211060404113327e-05,
      "loss": 2.6443,
      "num_input_tokens_seen": 1688216,
      "step": 850,
      "train_runtime": 7242.3925,
      "train_tokens_per_second": 233.102
    },
    {
      "epoch": 0.5364705882352941,
      "grad_norm": 0.7033126950263977,
      "learning_rate": 4.6167480805796985e-05,
      "loss": 2.5751,
      "num_input_tokens_seen": 1698880,
      "step": 855,
      "train_runtime": 7250.3565,
      "train_tokens_per_second": 234.317
    },
    {
      "epoch": 0.5396078431372549,
      "grad_norm": 0.5553830862045288,
      "learning_rate": 4.6123672811006824e-05,
      "loss": 2.4761,
      "num_input_tokens_seen": 1708464,
      "step": 860,
      "train_runtime": 7257.656,
      "train_tokens_per_second": 235.402
    },
    {
      "epoch": 0.5427450980392157,
      "grad_norm": 0.5993332862854004,
      "learning_rate": 4.6079636892429756e-05,
      "loss": 2.4833,
      "num_input_tokens_seen": 1718744,
      "step": 865,
      "train_runtime": 7265.605,
      "train_tokens_per_second": 236.559
    },
    {
      "epoch": 0.5458823529411765,
      "grad_norm": 0.655128002166748,
      "learning_rate": 4.603537352521202e-05,
      "loss": 2.4715,
      "num_input_tokens_seen": 1729368,
      "step": 870,
      "train_runtime": 7273.6588,
      "train_tokens_per_second": 237.758
    },
    {
      "epoch": 0.5490196078431373,
      "grad_norm": 0.575636088848114,
      "learning_rate": 4.599088318695398e-05,
      "loss": 2.4984,
      "num_input_tokens_seen": 1739168,
      "step": 875,
      "train_runtime": 7281.0564,
      "train_tokens_per_second": 238.862
    },
    {
      "epoch": 0.552156862745098,
      "grad_norm": 0.6883127093315125,
      "learning_rate": 4.5946166357705054e-05,
      "loss": 2.5566,
      "num_input_tokens_seen": 1749440,
      "step": 880,
      "train_runtime": 7289.0055,
      "train_tokens_per_second": 240.011
    },
    {
      "epoch": 0.5552941176470588,
      "grad_norm": 0.6318145990371704,
      "learning_rate": 4.5901223519958456e-05,
      "loss": 2.5188,
      "num_input_tokens_seen": 1759304,
      "step": 885,
      "train_runtime": 7296.5616,
      "train_tokens_per_second": 241.114
    },
    {
      "epoch": 0.5584313725490196,
      "grad_norm": 0.674229621887207,
      "learning_rate": 4.585605515864605e-05,
      "loss": 2.3565,
      "num_input_tokens_seen": 1768608,
      "step": 890,
      "train_runtime": 7304.0894,
      "train_tokens_per_second": 242.139
    },
    {
      "epoch": 0.5615686274509804,
      "grad_norm": 0.6091311573982239,
      "learning_rate": 4.5810661761133064e-05,
      "loss": 2.5024,
      "num_input_tokens_seen": 1779320,
      "step": 895,
      "train_runtime": 7312.1354,
      "train_tokens_per_second": 243.338
    },
    {
      "epoch": 0.5647058823529412,
      "grad_norm": 0.6582733392715454,
      "learning_rate": 4.5765043817212885e-05,
      "loss": 2.4986,
      "num_input_tokens_seen": 1789608,
      "step": 900,
      "train_runtime": 7319.9936,
      "train_tokens_per_second": 244.482
    },
    {
      "epoch": 0.5647058823529412,
      "eval_loss": 2.462778091430664,
      "eval_runtime": 79.0146,
      "eval_samples_per_second": 17.933,
      "eval_steps_per_second": 4.493,
      "num_input_tokens_seen": 1789608,
      "step": 900
    },
    {
      "epoch": 0.567843137254902,
      "grad_norm": 0.6093223094940186,
      "learning_rate": 4.5719201819101735e-05,
      "loss": 2.4929,
      "num_input_tokens_seen": 1799624,
      "step": 905,
      "train_runtime": 7406.9525,
      "train_tokens_per_second": 242.964
    },
    {
      "epoch": 0.5709803921568627,
      "grad_norm": 0.5735735893249512,
      "learning_rate": 4.567313626143339e-05,
      "loss": 2.472,
      "num_input_tokens_seen": 1810304,
      "step": 910,
      "train_runtime": 7414.9627,
      "train_tokens_per_second": 244.142
    },
    {
      "epoch": 0.5741176470588235,
      "grad_norm": 0.5480644106864929,
      "learning_rate": 4.56268476412538e-05,
      "loss": 2.4244,
      "num_input_tokens_seen": 1821144,
      "step": 915,
      "train_runtime": 7423.0677,
      "train_tokens_per_second": 245.336
    },
    {
      "epoch": 0.5772549019607843,
      "grad_norm": 0.6132708787918091,
      "learning_rate": 4.558033645801578e-05,
      "loss": 2.42,
      "num_input_tokens_seen": 1830576,
      "step": 920,
      "train_runtime": 7430.3745,
      "train_tokens_per_second": 246.364
    },
    {
      "epoch": 0.5803921568627451,
      "grad_norm": 0.6452284455299377,
      "learning_rate": 4.5533603213573586e-05,
      "loss": 2.4082,
      "num_input_tokens_seen": 1840664,
      "step": 925,
      "train_runtime": 7438.1525,
      "train_tokens_per_second": 247.463
    },
    {
      "epoch": 0.5835294117647059,
      "grad_norm": 0.6715510487556458,
      "learning_rate": 4.548664841217749e-05,
      "loss": 2.4786,
      "num_input_tokens_seen": 1850544,
      "step": 930,
      "train_runtime": 7445.6427,
      "train_tokens_per_second": 248.541
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.6119397878646851,
      "learning_rate": 4.543947256046837e-05,
      "loss": 2.4401,
      "num_input_tokens_seen": 1861024,
      "step": 935,
      "train_runtime": 7453.9743,
      "train_tokens_per_second": 249.669
    },
    {
      "epoch": 0.5898039215686275,
      "grad_norm": 0.6563675403594971,
      "learning_rate": 4.539207616747224e-05,
      "loss": 2.4838,
      "num_input_tokens_seen": 1871304,
      "step": 940,
      "train_runtime": 7461.7944,
      "train_tokens_per_second": 250.785
    },
    {
      "epoch": 0.5929411764705882,
      "grad_norm": 0.6587172746658325,
      "learning_rate": 4.5344459744594735e-05,
      "loss": 2.4668,
      "num_input_tokens_seen": 1881448,
      "step": 945,
      "train_runtime": 7469.4723,
      "train_tokens_per_second": 251.885
    },
    {
      "epoch": 0.596078431372549,
      "grad_norm": 0.5797609686851501,
      "learning_rate": 4.529662380561561e-05,
      "loss": 2.5091,
      "num_input_tokens_seen": 1891344,
      "step": 950,
      "train_runtime": 7477.2884,
      "train_tokens_per_second": 252.945
    },
    {
      "epoch": 0.5992156862745098,
      "grad_norm": 0.6030340194702148,
      "learning_rate": 4.5248568866683195e-05,
      "loss": 2.3375,
      "num_input_tokens_seen": 1900952,
      "step": 955,
      "train_runtime": 7484.8881,
      "train_tokens_per_second": 253.972
    },
    {
      "epoch": 0.6023529411764705,
      "grad_norm": 0.645625114440918,
      "learning_rate": 4.52002954463088e-05,
      "loss": 2.5557,
      "num_input_tokens_seen": 1911264,
      "step": 960,
      "train_runtime": 7492.8991,
      "train_tokens_per_second": 255.077
    },
    {
      "epoch": 0.6054901960784314,
      "grad_norm": 0.6685253381729126,
      "learning_rate": 4.515180406536119e-05,
      "loss": 2.4203,
      "num_input_tokens_seen": 1920624,
      "step": 965,
      "train_runtime": 7500.1059,
      "train_tokens_per_second": 256.08
    },
    {
      "epoch": 0.6086274509803922,
      "grad_norm": 0.6083003282546997,
      "learning_rate": 4.510309524706088e-05,
      "loss": 2.4863,
      "num_input_tokens_seen": 1931248,
      "step": 970,
      "train_runtime": 7508.1868,
      "train_tokens_per_second": 257.219
    },
    {
      "epoch": 0.611764705882353,
      "grad_norm": 0.6414815187454224,
      "learning_rate": 4.505416951697452e-05,
      "loss": 2.3987,
      "num_input_tokens_seen": 1941576,
      "step": 975,
      "train_runtime": 7515.972,
      "train_tokens_per_second": 258.327
    },
    {
      "epoch": 0.6149019607843137,
      "grad_norm": 0.5947257280349731,
      "learning_rate": 4.500502740300927e-05,
      "loss": 2.4027,
      "num_input_tokens_seen": 1951192,
      "step": 980,
      "train_runtime": 7523.3624,
      "train_tokens_per_second": 259.351
    },
    {
      "epoch": 0.6180392156862745,
      "grad_norm": 0.6804273724555969,
      "learning_rate": 4.495566943540703e-05,
      "loss": 2.5062,
      "num_input_tokens_seen": 1961880,
      "step": 985,
      "train_runtime": 7531.6209,
      "train_tokens_per_second": 260.486
    },
    {
      "epoch": 0.6211764705882353,
      "grad_norm": 0.6725308299064636,
      "learning_rate": 4.490609614673878e-05,
      "loss": 2.5348,
      "num_input_tokens_seen": 1971640,
      "step": 990,
      "train_runtime": 7539.0846,
      "train_tokens_per_second": 261.522
    },
    {
      "epoch": 0.624313725490196,
      "grad_norm": 0.5909632444381714,
      "learning_rate": 4.485630807189879e-05,
      "loss": 2.4153,
      "num_input_tokens_seen": 1981992,
      "step": 995,
      "train_runtime": 7547.036,
      "train_tokens_per_second": 262.619
    },
    {
      "epoch": 0.6274509803921569,
      "grad_norm": 0.7483217716217041,
      "learning_rate": 4.4806305748098874e-05,
      "loss": 2.4463,
      "num_input_tokens_seen": 1991776,
      "step": 1000,
      "train_runtime": 7554.6137,
      "train_tokens_per_second": 263.65
    },
    {
      "epoch": 0.6274509803921569,
      "eval_loss": 2.4470691680908203,
      "eval_runtime": 78.9647,
      "eval_samples_per_second": 17.945,
      "eval_steps_per_second": 4.496,
      "num_input_tokens_seen": 1991776,
      "step": 1000
    },
    {
      "epoch": 0.6305882352941177,
      "grad_norm": 0.6916738748550415,
      "learning_rate": 4.475608971486259e-05,
      "loss": 2.4772,
      "num_input_tokens_seen": 2001992,
      "step": 1005,
      "train_runtime": 7641.5912,
      "train_tokens_per_second": 261.986
    },
    {
      "epoch": 0.6337254901960784,
      "grad_norm": 0.6197510361671448,
      "learning_rate": 4.47056605140194e-05,
      "loss": 2.4154,
      "num_input_tokens_seen": 2011944,
      "step": 1010,
      "train_runtime": 7649.1216,
      "train_tokens_per_second": 263.029
    },
    {
      "epoch": 0.6368627450980392,
      "grad_norm": 0.650084376335144,
      "learning_rate": 4.465501868969885e-05,
      "loss": 2.3648,
      "num_input_tokens_seen": 2021504,
      "step": 1015,
      "train_runtime": 7656.3684,
      "train_tokens_per_second": 264.029
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6017749309539795,
      "learning_rate": 4.4604164788324684e-05,
      "loss": 2.5707,
      "num_input_tokens_seen": 2032248,
      "step": 1020,
      "train_runtime": 7664.3992,
      "train_tokens_per_second": 265.154
    },
    {
      "epoch": 0.6431372549019608,
      "grad_norm": 0.6532626748085022,
      "learning_rate": 4.4553099358608945e-05,
      "loss": 2.4123,
      "num_input_tokens_seen": 2042384,
      "step": 1025,
      "train_runtime": 7671.9692,
      "train_tokens_per_second": 266.214
    },
    {
      "epoch": 0.6462745098039215,
      "grad_norm": 0.6344058513641357,
      "learning_rate": 4.4501822951546074e-05,
      "loss": 2.4832,
      "num_input_tokens_seen": 2052936,
      "step": 1030,
      "train_runtime": 7680.017,
      "train_tokens_per_second": 267.309
    },
    {
      "epoch": 0.6494117647058824,
      "grad_norm": 0.6882011890411377,
      "learning_rate": 4.445033612040694e-05,
      "loss": 2.4698,
      "num_input_tokens_seen": 2062864,
      "step": 1035,
      "train_runtime": 7687.4778,
      "train_tokens_per_second": 268.341
    },
    {
      "epoch": 0.6525490196078432,
      "grad_norm": 0.6837179660797119,
      "learning_rate": 4.439863942073289e-05,
      "loss": 2.4158,
      "num_input_tokens_seen": 2072032,
      "step": 1040,
      "train_runtime": 7694.6734,
      "train_tokens_per_second": 269.281
    },
    {
      "epoch": 0.6556862745098039,
      "grad_norm": 0.8275521397590637,
      "learning_rate": 4.434673341032973e-05,
      "loss": 2.4118,
      "num_input_tokens_seen": 2081904,
      "step": 1045,
      "train_runtime": 7702.3189,
      "train_tokens_per_second": 270.296
    },
    {
      "epoch": 0.6588235294117647,
      "grad_norm": 0.6314124464988708,
      "learning_rate": 4.4294618649261735e-05,
      "loss": 2.5419,
      "num_input_tokens_seen": 2092280,
      "step": 1050,
      "train_runtime": 7710.188,
      "train_tokens_per_second": 271.366
    },
    {
      "epoch": 0.6619607843137255,
      "grad_norm": 0.7258930206298828,
      "learning_rate": 4.4242295699845605e-05,
      "loss": 2.4698,
      "num_input_tokens_seen": 2101912,
      "step": 1055,
      "train_runtime": 7717.5901,
      "train_tokens_per_second": 272.353
    },
    {
      "epoch": 0.6650980392156862,
      "grad_norm": 0.7132779955863953,
      "learning_rate": 4.418976512664435e-05,
      "loss": 2.4496,
      "num_input_tokens_seen": 2111824,
      "step": 1060,
      "train_runtime": 7725.0504,
      "train_tokens_per_second": 273.373
    },
    {
      "epoch": 0.668235294117647,
      "grad_norm": 0.6447386145591736,
      "learning_rate": 4.413702749646127e-05,
      "loss": 2.4786,
      "num_input_tokens_seen": 2122128,
      "step": 1065,
      "train_runtime": 7733.299,
      "train_tokens_per_second": 274.414
    },
    {
      "epoch": 0.6713725490196079,
      "grad_norm": 0.6281453967094421,
      "learning_rate": 4.4084083378333785e-05,
      "loss": 2.5615,
      "num_input_tokens_seen": 2132736,
      "step": 1070,
      "train_runtime": 7741.4064,
      "train_tokens_per_second": 275.497
    },
    {
      "epoch": 0.6745098039215687,
      "grad_norm": 0.5588974952697754,
      "learning_rate": 4.4030933343527326e-05,
      "loss": 2.4652,
      "num_input_tokens_seen": 2143344,
      "step": 1075,
      "train_runtime": 7749.4133,
      "train_tokens_per_second": 276.581
    },
    {
      "epoch": 0.6776470588235294,
      "grad_norm": 0.6315450668334961,
      "learning_rate": 4.397757796552915e-05,
      "loss": 2.4064,
      "num_input_tokens_seen": 2154112,
      "step": 1080,
      "train_runtime": 7757.74,
      "train_tokens_per_second": 277.673
    },
    {
      "epoch": 0.6807843137254902,
      "grad_norm": 0.6617061495780945,
      "learning_rate": 4.392401782004215e-05,
      "loss": 2.5112,
      "num_input_tokens_seen": 2164160,
      "step": 1085,
      "train_runtime": 7765.5678,
      "train_tokens_per_second": 278.687
    },
    {
      "epoch": 0.683921568627451,
      "grad_norm": 0.6360288858413696,
      "learning_rate": 4.3870253484978686e-05,
      "loss": 2.6003,
      "num_input_tokens_seen": 2174792,
      "step": 1090,
      "train_runtime": 7773.6289,
      "train_tokens_per_second": 279.765
    },
    {
      "epoch": 0.6870588235294117,
      "grad_norm": 0.6300710439682007,
      "learning_rate": 4.381628554045428e-05,
      "loss": 2.5944,
      "num_input_tokens_seen": 2184960,
      "step": 1095,
      "train_runtime": 7781.4726,
      "train_tokens_per_second": 280.79
    },
    {
      "epoch": 0.6901960784313725,
      "grad_norm": 0.6383811235427856,
      "learning_rate": 4.3762114568781415e-05,
      "loss": 2.5072,
      "num_input_tokens_seen": 2195000,
      "step": 1100,
      "train_runtime": 7789.3169,
      "train_tokens_per_second": 281.796
    },
    {
      "epoch": 0.6901960784313725,
      "eval_loss": 2.4354240894317627,
      "eval_runtime": 78.9555,
      "eval_samples_per_second": 17.947,
      "eval_steps_per_second": 4.496,
      "num_input_tokens_seen": 2195000,
      "step": 1100
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.7823399901390076,
      "learning_rate": 4.3707741154463235e-05,
      "loss": 2.4988,
      "num_input_tokens_seen": 2204576,
      "step": 1105,
      "train_runtime": 7875.9084,
      "train_tokens_per_second": 279.914
    },
    {
      "epoch": 0.6964705882352941,
      "grad_norm": 0.653779923915863,
      "learning_rate": 4.365316588418722e-05,
      "loss": 2.4023,
      "num_input_tokens_seen": 2214656,
      "step": 1110,
      "train_runtime": 7883.6112,
      "train_tokens_per_second": 280.919
    },
    {
      "epoch": 0.6996078431372549,
      "grad_norm": 0.6545277237892151,
      "learning_rate": 4.359838934681887e-05,
      "loss": 2.4962,
      "num_input_tokens_seen": 2224936,
      "step": 1115,
      "train_runtime": 7891.297,
      "train_tokens_per_second": 281.948
    },
    {
      "epoch": 0.7027450980392157,
      "grad_norm": 0.5985286235809326,
      "learning_rate": 4.354341213339537e-05,
      "loss": 2.5225,
      "num_input_tokens_seen": 2235072,
      "step": 1120,
      "train_runtime": 7898.8845,
      "train_tokens_per_second": 282.96
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 0.6744406223297119,
      "learning_rate": 4.3488234837119166e-05,
      "loss": 2.4692,
      "num_input_tokens_seen": 2244864,
      "step": 1125,
      "train_runtime": 7906.4291,
      "train_tokens_per_second": 283.929
    },
    {
      "epoch": 0.7090196078431372,
      "grad_norm": 0.6509506106376648,
      "learning_rate": 4.3432858053351624e-05,
      "loss": 2.4843,
      "num_input_tokens_seen": 2255336,
      "step": 1130,
      "train_runtime": 7914.508,
      "train_tokens_per_second": 284.962
    },
    {
      "epoch": 0.712156862745098,
      "grad_norm": 0.6990675926208496,
      "learning_rate": 4.337728237960654e-05,
      "loss": 2.3527,
      "num_input_tokens_seen": 2264968,
      "step": 1135,
      "train_runtime": 7922.0353,
      "train_tokens_per_second": 285.907
    },
    {
      "epoch": 0.7152941176470589,
      "grad_norm": 0.6116471886634827,
      "learning_rate": 4.332150841554374e-05,
      "loss": 2.3667,
      "num_input_tokens_seen": 2275240,
      "step": 1140,
      "train_runtime": 7929.8984,
      "train_tokens_per_second": 286.919
    },
    {
      "epoch": 0.7184313725490196,
      "grad_norm": 0.6334346532821655,
      "learning_rate": 4.326553676296262e-05,
      "loss": 2.3619,
      "num_input_tokens_seen": 2284648,
      "step": 1145,
      "train_runtime": 7937.0666,
      "train_tokens_per_second": 287.845
    },
    {
      "epoch": 0.7215686274509804,
      "grad_norm": 0.7318094968795776,
      "learning_rate": 4.3209368025795595e-05,
      "loss": 2.4307,
      "num_input_tokens_seen": 2293936,
      "step": 1150,
      "train_runtime": 7944.2555,
      "train_tokens_per_second": 288.754
    },
    {
      "epoch": 0.7247058823529412,
      "grad_norm": 0.6169258952140808,
      "learning_rate": 4.315300281010162e-05,
      "loss": 2.4862,
      "num_input_tokens_seen": 2304392,
      "step": 1155,
      "train_runtime": 7952.1267,
      "train_tokens_per_second": 289.783
    },
    {
      "epoch": 0.7278431372549019,
      "grad_norm": 0.6254990100860596,
      "learning_rate": 4.309644172405967e-05,
      "loss": 2.4093,
      "num_input_tokens_seen": 2314728,
      "step": 1160,
      "train_runtime": 7960.0735,
      "train_tokens_per_second": 290.792
    },
    {
      "epoch": 0.7309803921568627,
      "grad_norm": 0.6753774285316467,
      "learning_rate": 4.303968537796215e-05,
      "loss": 2.3653,
      "num_input_tokens_seen": 2324952,
      "step": 1165,
      "train_runtime": 7968.0079,
      "train_tokens_per_second": 291.786
    },
    {
      "epoch": 0.7341176470588235,
      "grad_norm": 0.7300695180892944,
      "learning_rate": 4.298273438420829e-05,
      "loss": 2.4602,
      "num_input_tokens_seen": 2334696,
      "step": 1170,
      "train_runtime": 7975.5583,
      "train_tokens_per_second": 292.731
    },
    {
      "epoch": 0.7372549019607844,
      "grad_norm": 0.5986980199813843,
      "learning_rate": 4.292558935729758e-05,
      "loss": 2.4067,
      "num_input_tokens_seen": 2344920,
      "step": 1175,
      "train_runtime": 7983.243,
      "train_tokens_per_second": 293.73
    },
    {
      "epoch": 0.7403921568627451,
      "grad_norm": 0.6895025372505188,
      "learning_rate": 4.2868250913823136e-05,
      "loss": 2.4682,
      "num_input_tokens_seen": 2354792,
      "step": 1180,
      "train_runtime": 7991.0049,
      "train_tokens_per_second": 294.68
    },
    {
      "epoch": 0.7435294117647059,
      "grad_norm": 0.695805013179779,
      "learning_rate": 4.281071967246501e-05,
      "loss": 2.4036,
      "num_input_tokens_seen": 2364480,
      "step": 1185,
      "train_runtime": 7998.5266,
      "train_tokens_per_second": 295.614
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.7573379874229431,
      "learning_rate": 4.2752996253983545e-05,
      "loss": 2.3858,
      "num_input_tokens_seen": 2374800,
      "step": 1190,
      "train_runtime": 8006.3619,
      "train_tokens_per_second": 296.614
    },
    {
      "epoch": 0.7498039215686274,
      "grad_norm": 0.6659537553787231,
      "learning_rate": 4.269508128121268e-05,
      "loss": 2.3583,
      "num_input_tokens_seen": 2384400,
      "step": 1195,
      "train_runtime": 8013.8147,
      "train_tokens_per_second": 297.536
    },
    {
      "epoch": 0.7529411764705882,
      "grad_norm": 0.621234655380249,
      "learning_rate": 4.263697537905319e-05,
      "loss": 2.5234,
      "num_input_tokens_seen": 2395216,
      "step": 1200,
      "train_runtime": 8021.9603,
      "train_tokens_per_second": 298.582
    },
    {
      "epoch": 0.7529411764705882,
      "eval_loss": 2.4230573177337646,
      "eval_runtime": 78.9401,
      "eval_samples_per_second": 17.95,
      "eval_steps_per_second": 4.497,
      "num_input_tokens_seen": 2395216,
      "step": 1200
    },
    {
      "epoch": 0.756078431372549,
      "grad_norm": 0.6493569016456604,
      "learning_rate": 4.257867917446601e-05,
      "loss": 2.4292,
      "num_input_tokens_seen": 2405528,
      "step": 1205,
      "train_runtime": 8109.1238,
      "train_tokens_per_second": 296.645
    },
    {
      "epoch": 0.7592156862745097,
      "grad_norm": 0.7065591812133789,
      "learning_rate": 4.25201932964654e-05,
      "loss": 2.4701,
      "num_input_tokens_seen": 2415624,
      "step": 1210,
      "train_runtime": 8116.7774,
      "train_tokens_per_second": 297.609
    },
    {
      "epoch": 0.7623529411764706,
      "grad_norm": 0.739273726940155,
      "learning_rate": 4.2461518376112216e-05,
      "loss": 2.4263,
      "num_input_tokens_seen": 2425072,
      "step": 1215,
      "train_runtime": 8123.9476,
      "train_tokens_per_second": 298.509
    },
    {
      "epoch": 0.7654901960784314,
      "grad_norm": 0.6367782950401306,
      "learning_rate": 4.240265504650706e-05,
      "loss": 2.377,
      "num_input_tokens_seen": 2434608,
      "step": 1220,
      "train_runtime": 8131.5859,
      "train_tokens_per_second": 299.401
    },
    {
      "epoch": 0.7686274509803922,
      "grad_norm": 0.6979654431343079,
      "learning_rate": 4.234360394278345e-05,
      "loss": 2.4547,
      "num_input_tokens_seen": 2444728,
      "step": 1225,
      "train_runtime": 8139.3272,
      "train_tokens_per_second": 300.36
    },
    {
      "epoch": 0.7717647058823529,
      "grad_norm": 0.6667248606681824,
      "learning_rate": 4.2284365702101025e-05,
      "loss": 2.3482,
      "num_input_tokens_seen": 2454784,
      "step": 1230,
      "train_runtime": 8146.616,
      "train_tokens_per_second": 301.326
    },
    {
      "epoch": 0.7749019607843137,
      "grad_norm": 0.7264310121536255,
      "learning_rate": 4.2224940963638585e-05,
      "loss": 2.411,
      "num_input_tokens_seen": 2463824,
      "step": 1235,
      "train_runtime": 8153.898,
      "train_tokens_per_second": 302.165
    },
    {
      "epoch": 0.7780392156862745,
      "grad_norm": 0.6829324960708618,
      "learning_rate": 4.216533036858725e-05,
      "loss": 2.4713,
      "num_input_tokens_seen": 2474712,
      "step": 1240,
      "train_runtime": 8161.9943,
      "train_tokens_per_second": 303.199
    },
    {
      "epoch": 0.7811764705882352,
      "grad_norm": 0.6941818594932556,
      "learning_rate": 4.210553456014354e-05,
      "loss": 2.397,
      "num_input_tokens_seen": 2485264,
      "step": 1245,
      "train_runtime": 8169.8528,
      "train_tokens_per_second": 304.199
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.6672576665878296,
      "learning_rate": 4.204555418350239e-05,
      "loss": 2.3161,
      "num_input_tokens_seen": 2494728,
      "step": 1250,
      "train_runtime": 8177.261,
      "train_tokens_per_second": 305.081
    },
    {
      "epoch": 0.7874509803921569,
      "grad_norm": 0.7074472308158875,
      "learning_rate": 4.198538988585025e-05,
      "loss": 2.4542,
      "num_input_tokens_seen": 2504176,
      "step": 1255,
      "train_runtime": 8184.6434,
      "train_tokens_per_second": 305.96
    },
    {
      "epoch": 0.7905882352941176,
      "grad_norm": 0.7887606024742126,
      "learning_rate": 4.192504231635804e-05,
      "loss": 2.4484,
      "num_input_tokens_seen": 2514504,
      "step": 1260,
      "train_runtime": 8192.4797,
      "train_tokens_per_second": 306.928
    },
    {
      "epoch": 0.7937254901960784,
      "grad_norm": 0.6638487577438354,
      "learning_rate": 4.1864512126174236e-05,
      "loss": 2.3533,
      "num_input_tokens_seen": 2524432,
      "step": 1265,
      "train_runtime": 8200.0671,
      "train_tokens_per_second": 307.855
    },
    {
      "epoch": 0.7968627450980392,
      "grad_norm": 0.6826321482658386,
      "learning_rate": 4.1803799968417734e-05,
      "loss": 2.4561,
      "num_input_tokens_seen": 2534608,
      "step": 1270,
      "train_runtime": 8207.7464,
      "train_tokens_per_second": 308.807
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.618096113204956,
      "learning_rate": 4.1742906498170854e-05,
      "loss": 2.4669,
      "num_input_tokens_seen": 2544184,
      "step": 1275,
      "train_runtime": 8215.2544,
      "train_tokens_per_second": 309.69
    },
    {
      "epoch": 0.8031372549019608,
      "grad_norm": 0.6501224637031555,
      "learning_rate": 4.1681832372472295e-05,
      "loss": 2.3887,
      "num_input_tokens_seen": 2553976,
      "step": 1280,
      "train_runtime": 8222.6962,
      "train_tokens_per_second": 310.601
    },
    {
      "epoch": 0.8062745098039216,
      "grad_norm": 0.6930689215660095,
      "learning_rate": 4.162057825031002e-05,
      "loss": 2.4103,
      "num_input_tokens_seen": 2563536,
      "step": 1285,
      "train_runtime": 8230.129,
      "train_tokens_per_second": 311.482
    },
    {
      "epoch": 0.8094117647058824,
      "grad_norm": 0.7432404160499573,
      "learning_rate": 4.1559144792614144e-05,
      "loss": 2.3947,
      "num_input_tokens_seen": 2573192,
      "step": 1290,
      "train_runtime": 8237.7212,
      "train_tokens_per_second": 312.367
    },
    {
      "epoch": 0.8125490196078431,
      "grad_norm": 0.6968070268630981,
      "learning_rate": 4.14975326622498e-05,
      "loss": 2.4308,
      "num_input_tokens_seen": 2583096,
      "step": 1295,
      "train_runtime": 8245.4455,
      "train_tokens_per_second": 313.275
    },
    {
      "epoch": 0.8156862745098039,
      "grad_norm": 0.6521438956260681,
      "learning_rate": 4.1435742524009996e-05,
      "loss": 2.3678,
      "num_input_tokens_seen": 2593552,
      "step": 1300,
      "train_runtime": 8253.4998,
      "train_tokens_per_second": 314.237
    },
    {
      "epoch": 0.8156862745098039,
      "eval_loss": 2.4126415252685547,
      "eval_runtime": 78.9487,
      "eval_samples_per_second": 17.948,
      "eval_steps_per_second": 4.497,
      "num_input_tokens_seen": 2593552,
      "step": 1300
    },
    {
      "epoch": 0.8188235294117647,
      "grad_norm": 0.6608258485794067,
      "learning_rate": 4.137377504460845e-05,
      "loss": 2.3871,
      "num_input_tokens_seen": 2602648,
      "step": 1305,
      "train_runtime": 8339.6543,
      "train_tokens_per_second": 312.081
    },
    {
      "epoch": 0.8219607843137255,
      "grad_norm": 0.7620266675949097,
      "learning_rate": 4.131163089267239e-05,
      "loss": 2.5159,
      "num_input_tokens_seen": 2612088,
      "step": 1310,
      "train_runtime": 8346.7637,
      "train_tokens_per_second": 312.946
    },
    {
      "epoch": 0.8250980392156863,
      "grad_norm": 0.8874356746673584,
      "learning_rate": 4.124931073873531e-05,
      "loss": 2.4189,
      "num_input_tokens_seen": 2621792,
      "step": 1315,
      "train_runtime": 8354.1889,
      "train_tokens_per_second": 313.83
    },
    {
      "epoch": 0.8282352941176471,
      "grad_norm": 0.7118515968322754,
      "learning_rate": 4.1186815255229775e-05,
      "loss": 2.4747,
      "num_input_tokens_seen": 2631744,
      "step": 1320,
      "train_runtime": 8362.0051,
      "train_tokens_per_second": 314.726
    },
    {
      "epoch": 0.8313725490196079,
      "grad_norm": 0.726553738117218,
      "learning_rate": 4.112414511648016e-05,
      "loss": 2.3454,
      "num_input_tokens_seen": 2640984,
      "step": 1325,
      "train_runtime": 8369.06,
      "train_tokens_per_second": 315.565
    },
    {
      "epoch": 0.8345098039215686,
      "grad_norm": 0.7776907682418823,
      "learning_rate": 4.1061300998695355e-05,
      "loss": 2.3457,
      "num_input_tokens_seen": 2650880,
      "step": 1330,
      "train_runtime": 8376.6796,
      "train_tokens_per_second": 316.46
    },
    {
      "epoch": 0.8376470588235294,
      "grad_norm": 0.5980848670005798,
      "learning_rate": 4.099828357996146e-05,
      "loss": 2.4403,
      "num_input_tokens_seen": 2660944,
      "step": 1335,
      "train_runtime": 8384.4389,
      "train_tokens_per_second": 317.367
    },
    {
      "epoch": 0.8407843137254902,
      "grad_norm": 0.6201786994934082,
      "learning_rate": 4.093509354023451e-05,
      "loss": 2.4548,
      "num_input_tokens_seen": 2671880,
      "step": 1340,
      "train_runtime": 8392.7215,
      "train_tokens_per_second": 318.357
    },
    {
      "epoch": 0.8439215686274509,
      "grad_norm": 0.662483274936676,
      "learning_rate": 4.087173156133314e-05,
      "loss": 2.3357,
      "num_input_tokens_seen": 2681720,
      "step": 1345,
      "train_runtime": 8400.2778,
      "train_tokens_per_second": 319.242
    },
    {
      "epoch": 0.8470588235294118,
      "grad_norm": 0.7081847786903381,
      "learning_rate": 4.0808198326931144e-05,
      "loss": 2.3371,
      "num_input_tokens_seen": 2691416,
      "step": 1350,
      "train_runtime": 8407.6786,
      "train_tokens_per_second": 320.114
    },
    {
      "epoch": 0.8501960784313726,
      "grad_norm": 0.7080933451652527,
      "learning_rate": 4.07444945225502e-05,
      "loss": 2.3983,
      "num_input_tokens_seen": 2701648,
      "step": 1355,
      "train_runtime": 8415.4034,
      "train_tokens_per_second": 321.036
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.7135518789291382,
      "learning_rate": 4.0680620835552425e-05,
      "loss": 2.3624,
      "num_input_tokens_seen": 2711192,
      "step": 1360,
      "train_runtime": 8422.5242,
      "train_tokens_per_second": 321.898
    },
    {
      "epoch": 0.8564705882352941,
      "grad_norm": 0.6274308562278748,
      "learning_rate": 4.061657795513294e-05,
      "loss": 2.3325,
      "num_input_tokens_seen": 2721400,
      "step": 1365,
      "train_runtime": 8430.1589,
      "train_tokens_per_second": 322.817
    },
    {
      "epoch": 0.8596078431372549,
      "grad_norm": 0.6930301785469055,
      "learning_rate": 4.05523665723125e-05,
      "loss": 2.4104,
      "num_input_tokens_seen": 2731984,
      "step": 1370,
      "train_runtime": 8437.8222,
      "train_tokens_per_second": 323.778
    },
    {
      "epoch": 0.8627450980392157,
      "grad_norm": 0.8192833662033081,
      "learning_rate": 4.048798737992994e-05,
      "loss": 2.4857,
      "num_input_tokens_seen": 2742584,
      "step": 1375,
      "train_runtime": 8445.8308,
      "train_tokens_per_second": 324.726
    },
    {
      "epoch": 0.8658823529411764,
      "grad_norm": 0.7105642557144165,
      "learning_rate": 4.042344107263482e-05,
      "loss": 2.4531,
      "num_input_tokens_seen": 2752768,
      "step": 1380,
      "train_runtime": 8453.5316,
      "train_tokens_per_second": 325.635
    },
    {
      "epoch": 0.8690196078431373,
      "grad_norm": 0.6541239619255066,
      "learning_rate": 4.0358728346879806e-05,
      "loss": 2.3874,
      "num_input_tokens_seen": 2762792,
      "step": 1385,
      "train_runtime": 8461.3397,
      "train_tokens_per_second": 326.519
    },
    {
      "epoch": 0.8721568627450981,
      "grad_norm": 0.6944730281829834,
      "learning_rate": 4.029384990091326e-05,
      "loss": 2.4115,
      "num_input_tokens_seen": 2772784,
      "step": 1390,
      "train_runtime": 8468.9133,
      "train_tokens_per_second": 327.407
    },
    {
      "epoch": 0.8752941176470588,
      "grad_norm": 0.7628680467605591,
      "learning_rate": 4.0228806434771624e-05,
      "loss": 2.4355,
      "num_input_tokens_seen": 2782512,
      "step": 1395,
      "train_runtime": 8476.1865,
      "train_tokens_per_second": 328.274
    },
    {
      "epoch": 0.8784313725490196,
      "grad_norm": 0.7012823224067688,
      "learning_rate": 4.016359865027193e-05,
      "loss": 2.3165,
      "num_input_tokens_seen": 2793000,
      "step": 1400,
      "train_runtime": 8484.0994,
      "train_tokens_per_second": 329.204
    },
    {
      "epoch": 0.8784313725490196,
      "eval_loss": 2.402927875518799,
      "eval_runtime": 78.954,
      "eval_samples_per_second": 17.947,
      "eval_steps_per_second": 4.496,
      "num_input_tokens_seen": 2793000,
      "step": 1400
    },
    {
      "epoch": 0.8815686274509804,
      "grad_norm": 0.7491496205329895,
      "learning_rate": 4.009822725100418e-05,
      "loss": 2.4189,
      "num_input_tokens_seen": 2803912,
      "step": 1405,
      "train_runtime": 8571.3006,
      "train_tokens_per_second": 327.128
    },
    {
      "epoch": 0.8847058823529412,
      "grad_norm": 0.6834533214569092,
      "learning_rate": 4.003269294232379e-05,
      "loss": 2.4682,
      "num_input_tokens_seen": 2814816,
      "step": 1410,
      "train_runtime": 8579.435,
      "train_tokens_per_second": 328.089
    },
    {
      "epoch": 0.8878431372549019,
      "grad_norm": 0.7612832188606262,
      "learning_rate": 3.9966996431343954e-05,
      "loss": 2.3385,
      "num_input_tokens_seen": 2824096,
      "step": 1415,
      "train_runtime": 8586.459,
      "train_tokens_per_second": 328.901
    },
    {
      "epoch": 0.8909803921568628,
      "grad_norm": 0.7118933200836182,
      "learning_rate": 3.990113842692803e-05,
      "loss": 2.4463,
      "num_input_tokens_seen": 2834568,
      "step": 1420,
      "train_runtime": 8594.5533,
      "train_tokens_per_second": 329.81
    },
    {
      "epoch": 0.8941176470588236,
      "grad_norm": 0.7047643661499023,
      "learning_rate": 3.983511963968187e-05,
      "loss": 2.4064,
      "num_input_tokens_seen": 2844736,
      "step": 1425,
      "train_runtime": 8602.3751,
      "train_tokens_per_second": 330.692
    },
    {
      "epoch": 0.8972549019607843,
      "grad_norm": 0.659199595451355,
      "learning_rate": 3.97689407819462e-05,
      "loss": 2.372,
      "num_input_tokens_seen": 2855120,
      "step": 1430,
      "train_runtime": 8610.378,
      "train_tokens_per_second": 331.591
    },
    {
      "epoch": 0.9003921568627451,
      "grad_norm": 0.7706926465034485,
      "learning_rate": 3.970260256778885e-05,
      "loss": 2.4327,
      "num_input_tokens_seen": 2864584,
      "step": 1435,
      "train_runtime": 8617.7714,
      "train_tokens_per_second": 332.404
    },
    {
      "epoch": 0.9035294117647059,
      "grad_norm": 0.6687380075454712,
      "learning_rate": 3.9636105712997165e-05,
      "loss": 2.3672,
      "num_input_tokens_seen": 2874408,
      "step": 1440,
      "train_runtime": 8625.5018,
      "train_tokens_per_second": 333.245
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.7006394267082214,
      "learning_rate": 3.956945093507016e-05,
      "loss": 2.4609,
      "num_input_tokens_seen": 2884168,
      "step": 1445,
      "train_runtime": 8633.3708,
      "train_tokens_per_second": 334.072
    },
    {
      "epoch": 0.9098039215686274,
      "grad_norm": 0.6032112836837769,
      "learning_rate": 3.9502638953210886e-05,
      "loss": 2.4931,
      "num_input_tokens_seen": 2894280,
      "step": 1450,
      "train_runtime": 8640.908,
      "train_tokens_per_second": 334.951
    },
    {
      "epoch": 0.9129411764705883,
      "grad_norm": 0.6445319652557373,
      "learning_rate": 3.943567048831858e-05,
      "loss": 2.4157,
      "num_input_tokens_seen": 2904592,
      "step": 1455,
      "train_runtime": 8648.7699,
      "train_tokens_per_second": 335.839
    },
    {
      "epoch": 0.9160784313725491,
      "grad_norm": 0.7637354731559753,
      "learning_rate": 3.9368546262980935e-05,
      "loss": 2.3562,
      "num_input_tokens_seen": 2914664,
      "step": 1460,
      "train_runtime": 8656.162,
      "train_tokens_per_second": 336.716
    },
    {
      "epoch": 0.9192156862745098,
      "grad_norm": 0.7208041548728943,
      "learning_rate": 3.93012670014663e-05,
      "loss": 2.3438,
      "num_input_tokens_seen": 2924672,
      "step": 1465,
      "train_runtime": 8663.8829,
      "train_tokens_per_second": 337.571
    },
    {
      "epoch": 0.9223529411764706,
      "grad_norm": 0.8103705644607544,
      "learning_rate": 3.9233833429715875e-05,
      "loss": 2.4748,
      "num_input_tokens_seen": 2934080,
      "step": 1470,
      "train_runtime": 8671.3601,
      "train_tokens_per_second": 338.364
    },
    {
      "epoch": 0.9254901960784314,
      "grad_norm": 0.6908378601074219,
      "learning_rate": 3.9166246275335836e-05,
      "loss": 2.4364,
      "num_input_tokens_seen": 2943944,
      "step": 1475,
      "train_runtime": 8678.8312,
      "train_tokens_per_second": 339.21
    },
    {
      "epoch": 0.9286274509803921,
      "grad_norm": 0.7248737215995789,
      "learning_rate": 3.909850626758952e-05,
      "loss": 2.3546,
      "num_input_tokens_seen": 2953376,
      "step": 1480,
      "train_runtime": 8686.2372,
      "train_tokens_per_second": 340.006
    },
    {
      "epoch": 0.9317647058823529,
      "grad_norm": 0.6407846212387085,
      "learning_rate": 3.9030614137389554e-05,
      "loss": 2.4272,
      "num_input_tokens_seen": 2964256,
      "step": 1485,
      "train_runtime": 8694.2442,
      "train_tokens_per_second": 340.945
    },
    {
      "epoch": 0.9349019607843138,
      "grad_norm": 0.731975257396698,
      "learning_rate": 3.896257061728996e-05,
      "loss": 2.4683,
      "num_input_tokens_seen": 2974944,
      "step": 1490,
      "train_runtime": 8702.4774,
      "train_tokens_per_second": 341.85
    },
    {
      "epoch": 0.9380392156862745,
      "grad_norm": 0.6849587559700012,
      "learning_rate": 3.889437644147824e-05,
      "loss": 2.5038,
      "num_input_tokens_seen": 2984928,
      "step": 1495,
      "train_runtime": 8710.303,
      "train_tokens_per_second": 342.689
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 0.7013918161392212,
      "learning_rate": 3.8826032345767494e-05,
      "loss": 2.4313,
      "num_input_tokens_seen": 2994368,
      "step": 1500,
      "train_runtime": 8717.8515,
      "train_tokens_per_second": 343.475
    },
    {
      "epoch": 0.9411764705882353,
      "eval_loss": 2.391223430633545,
      "eval_runtime": 78.9821,
      "eval_samples_per_second": 17.941,
      "eval_steps_per_second": 4.495,
      "num_input_tokens_seen": 2994368,
      "step": 1500
    },
    {
      "epoch": 0.9443137254901961,
      "grad_norm": 0.7187613844871521,
      "learning_rate": 3.8757539067588414e-05,
      "loss": 2.427,
      "num_input_tokens_seen": 3004272,
      "step": 1505,
      "train_runtime": 8804.8379,
      "train_tokens_per_second": 341.207
    },
    {
      "epoch": 0.9474509803921569,
      "grad_norm": 0.729029655456543,
      "learning_rate": 3.8688897345981395e-05,
      "loss": 2.4067,
      "num_input_tokens_seen": 3014672,
      "step": 1510,
      "train_runtime": 8812.6736,
      "train_tokens_per_second": 342.084
    },
    {
      "epoch": 0.9505882352941176,
      "grad_norm": 0.7515145540237427,
      "learning_rate": 3.8620107921588535e-05,
      "loss": 2.3746,
      "num_input_tokens_seen": 3024256,
      "step": 1515,
      "train_runtime": 8819.9605,
      "train_tokens_per_second": 342.888
    },
    {
      "epoch": 0.9537254901960784,
      "grad_norm": 0.7969908714294434,
      "learning_rate": 3.8551171536645617e-05,
      "loss": 2.3588,
      "num_input_tokens_seen": 3033928,
      "step": 1520,
      "train_runtime": 8827.2357,
      "train_tokens_per_second": 343.701
    },
    {
      "epoch": 0.9568627450980393,
      "grad_norm": 0.6785094738006592,
      "learning_rate": 3.848208893497414e-05,
      "loss": 2.5018,
      "num_input_tokens_seen": 3043912,
      "step": 1525,
      "train_runtime": 8835.0925,
      "train_tokens_per_second": 344.525
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.756790041923523,
      "learning_rate": 3.8412860861973284e-05,
      "loss": 2.4237,
      "num_input_tokens_seen": 3053512,
      "step": 1530,
      "train_runtime": 8842.4676,
      "train_tokens_per_second": 345.324
    },
    {
      "epoch": 0.9631372549019608,
      "grad_norm": 0.6977978348731995,
      "learning_rate": 3.834348806461183e-05,
      "loss": 2.3958,
      "num_input_tokens_seen": 3064008,
      "step": 1535,
      "train_runtime": 8850.6283,
      "train_tokens_per_second": 346.191
    },
    {
      "epoch": 0.9662745098039216,
      "grad_norm": 0.7809386253356934,
      "learning_rate": 3.827397129142017e-05,
      "loss": 2.3547,
      "num_input_tokens_seen": 3074336,
      "step": 1540,
      "train_runtime": 8858.6576,
      "train_tokens_per_second": 347.043
    },
    {
      "epoch": 0.9694117647058823,
      "grad_norm": 0.7311163544654846,
      "learning_rate": 3.820431129248216e-05,
      "loss": 2.3921,
      "num_input_tokens_seen": 3084240,
      "step": 1545,
      "train_runtime": 8866.1618,
      "train_tokens_per_second": 347.866
    },
    {
      "epoch": 0.9725490196078431,
      "grad_norm": 0.6752628087997437,
      "learning_rate": 3.813450881942708e-05,
      "loss": 2.3242,
      "num_input_tokens_seen": 3093936,
      "step": 1550,
      "train_runtime": 8873.4797,
      "train_tokens_per_second": 348.672
    },
    {
      "epoch": 0.9756862745098039,
      "grad_norm": 0.7802899479866028,
      "learning_rate": 3.806456462542147e-05,
      "loss": 2.3157,
      "num_input_tokens_seen": 3103368,
      "step": 1555,
      "train_runtime": 8880.5231,
      "train_tokens_per_second": 349.458
    },
    {
      "epoch": 0.9788235294117648,
      "grad_norm": 0.7704379558563232,
      "learning_rate": 3.799447946516108e-05,
      "loss": 2.3152,
      "num_input_tokens_seen": 3113328,
      "step": 1560,
      "train_runtime": 8888.3876,
      "train_tokens_per_second": 350.269
    },
    {
      "epoch": 0.9819607843137255,
      "grad_norm": 0.8186370730400085,
      "learning_rate": 3.792425409486264e-05,
      "loss": 2.3608,
      "num_input_tokens_seen": 3123480,
      "step": 1565,
      "train_runtime": 8896.2912,
      "train_tokens_per_second": 351.099
    },
    {
      "epoch": 0.9850980392156863,
      "grad_norm": 0.6766547560691833,
      "learning_rate": 3.785388927225577e-05,
      "loss": 2.3929,
      "num_input_tokens_seen": 3133240,
      "step": 1570,
      "train_runtime": 8903.9375,
      "train_tokens_per_second": 351.894
    },
    {
      "epoch": 0.9882352941176471,
      "grad_norm": 0.7452688217163086,
      "learning_rate": 3.7783385756574755e-05,
      "loss": 2.3585,
      "num_input_tokens_seen": 3143296,
      "step": 1575,
      "train_runtime": 8911.8877,
      "train_tokens_per_second": 352.708
    },
    {
      "epoch": 0.9913725490196078,
      "grad_norm": 0.7429950833320618,
      "learning_rate": 3.7712744308550395e-05,
      "loss": 2.3499,
      "num_input_tokens_seen": 3153480,
      "step": 1580,
      "train_runtime": 8919.7084,
      "train_tokens_per_second": 353.541
    },
    {
      "epoch": 0.9945098039215686,
      "grad_norm": 0.8363685011863708,
      "learning_rate": 3.764196569040176e-05,
      "loss": 2.3903,
      "num_input_tokens_seen": 3163184,
      "step": 1585,
      "train_runtime": 8927.4983,
      "train_tokens_per_second": 354.319
    },
    {
      "epoch": 0.9976470588235294,
      "grad_norm": 0.7051501870155334,
      "learning_rate": 3.757105066582797e-05,
      "loss": 2.4068,
      "num_input_tokens_seen": 3173632,
      "step": 1590,
      "train_runtime": 8935.2974,
      "train_tokens_per_second": 355.179
    },
    {
      "epoch": 1.000627450980392,
      "grad_norm": 0.7332232594490051,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 2.2705,
      "num_input_tokens_seen": 3183064,
      "step": 1595,
      "train_runtime": 8942.4477,
      "train_tokens_per_second": 355.95
    },
    {
      "epoch": 1.003764705882353,
      "grad_norm": 0.7677835822105408,
      "learning_rate": 3.7428814459552374e-05,
      "loss": 2.2504,
      "num_input_tokens_seen": 3192952,
      "step": 1600,
      "train_runtime": 8950.174,
      "train_tokens_per_second": 356.747
    },
    {
      "epoch": 1.003764705882353,
      "eval_loss": 2.3835246562957764,
      "eval_runtime": 79.0249,
      "eval_samples_per_second": 17.931,
      "eval_steps_per_second": 4.492,
      "num_input_tokens_seen": 3192952,
      "step": 1600
    },
    {
      "epoch": 1.0069019607843137,
      "grad_norm": 0.7641481161117554,
      "learning_rate": 3.73574948125749e-05,
      "loss": 2.2139,
      "num_input_tokens_seen": 3203616,
      "step": 1605,
      "train_runtime": 9037.8065,
      "train_tokens_per_second": 354.468
    },
    {
      "epoch": 1.0100392156862745,
      "grad_norm": 0.8636948466300964,
      "learning_rate": 3.7286041828604404e-05,
      "loss": 2.1853,
      "num_input_tokens_seen": 3213416,
      "step": 1610,
      "train_runtime": 9045.2169,
      "train_tokens_per_second": 355.261
    },
    {
      "epoch": 1.0131764705882353,
      "grad_norm": 0.7129502892494202,
      "learning_rate": 3.7214456278616405e-05,
      "loss": 2.1651,
      "num_input_tokens_seen": 3223336,
      "step": 1615,
      "train_runtime": 9052.9402,
      "train_tokens_per_second": 356.054
    },
    {
      "epoch": 1.0163137254901962,
      "grad_norm": 0.8964852690696716,
      "learning_rate": 3.7142738935016804e-05,
      "loss": 2.2194,
      "num_input_tokens_seen": 3233560,
      "step": 1620,
      "train_runtime": 9061.0902,
      "train_tokens_per_second": 356.862
    },
    {
      "epoch": 1.0194509803921568,
      "grad_norm": 0.7557547092437744,
      "learning_rate": 3.707089057163358e-05,
      "loss": 2.199,
      "num_input_tokens_seen": 3243424,
      "step": 1625,
      "train_runtime": 9068.7352,
      "train_tokens_per_second": 357.649
    },
    {
      "epoch": 1.0225882352941176,
      "grad_norm": 0.6621900200843811,
      "learning_rate": 3.699891196370835e-05,
      "loss": 2.2385,
      "num_input_tokens_seen": 3253904,
      "step": 1630,
      "train_runtime": 9076.8283,
      "train_tokens_per_second": 358.485
    },
    {
      "epoch": 1.0257254901960784,
      "grad_norm": 0.7864047288894653,
      "learning_rate": 3.6926803887888126e-05,
      "loss": 2.2282,
      "num_input_tokens_seen": 3263544,
      "step": 1635,
      "train_runtime": 9084.6675,
      "train_tokens_per_second": 359.236
    },
    {
      "epoch": 1.0288627450980392,
      "grad_norm": 0.7070903182029724,
      "learning_rate": 3.685456712221687e-05,
      "loss": 2.1815,
      "num_input_tokens_seen": 3274144,
      "step": 1640,
      "train_runtime": 9092.67,
      "train_tokens_per_second": 360.086
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.8536216020584106,
      "learning_rate": 3.678220244612704e-05,
      "loss": 2.1873,
      "num_input_tokens_seen": 3283456,
      "step": 1645,
      "train_runtime": 9099.9719,
      "train_tokens_per_second": 360.82
    },
    {
      "epoch": 1.0351372549019608,
      "grad_norm": 0.7619454264640808,
      "learning_rate": 3.6709710640431324e-05,
      "loss": 2.1626,
      "num_input_tokens_seen": 3293320,
      "step": 1650,
      "train_runtime": 9107.6284,
      "train_tokens_per_second": 361.6
    },
    {
      "epoch": 1.0382745098039217,
      "grad_norm": 0.7188210487365723,
      "learning_rate": 3.6637092487314094e-05,
      "loss": 2.1941,
      "num_input_tokens_seen": 3304072,
      "step": 1655,
      "train_runtime": 9115.5294,
      "train_tokens_per_second": 362.466
    },
    {
      "epoch": 1.0414117647058823,
      "grad_norm": 0.7476827502250671,
      "learning_rate": 3.656434877032301e-05,
      "loss": 2.204,
      "num_input_tokens_seen": 3314472,
      "step": 1660,
      "train_runtime": 9123.3691,
      "train_tokens_per_second": 363.295
    },
    {
      "epoch": 1.044549019607843,
      "grad_norm": 0.7273176312446594,
      "learning_rate": 3.6491480274360565e-05,
      "loss": 2.1594,
      "num_input_tokens_seen": 3324296,
      "step": 1665,
      "train_runtime": 9131.175,
      "train_tokens_per_second": 364.06
    },
    {
      "epoch": 1.047686274509804,
      "grad_norm": 0.774019181728363,
      "learning_rate": 3.64184877856756e-05,
      "loss": 2.1141,
      "num_input_tokens_seen": 3334048,
      "step": 1670,
      "train_runtime": 9138.7993,
      "train_tokens_per_second": 364.823
    },
    {
      "epoch": 1.0508235294117647,
      "grad_norm": 0.8313727974891663,
      "learning_rate": 3.634537209185487e-05,
      "loss": 2.1402,
      "num_input_tokens_seen": 3343152,
      "step": 1675,
      "train_runtime": 9145.8648,
      "train_tokens_per_second": 365.537
    },
    {
      "epoch": 1.0539607843137255,
      "grad_norm": 0.8928428888320923,
      "learning_rate": 3.6272133981814475e-05,
      "loss": 2.3033,
      "num_input_tokens_seen": 3352888,
      "step": 1680,
      "train_runtime": 9153.5457,
      "train_tokens_per_second": 366.294
    },
    {
      "epoch": 1.0570980392156863,
      "grad_norm": 0.7974850535392761,
      "learning_rate": 3.619877424579139e-05,
      "loss": 2.207,
      "num_input_tokens_seen": 3362656,
      "step": 1685,
      "train_runtime": 9161.3297,
      "train_tokens_per_second": 367.049
    },
    {
      "epoch": 1.0602352941176472,
      "grad_norm": 0.8008760809898376,
      "learning_rate": 3.612529367533495e-05,
      "loss": 2.1052,
      "num_input_tokens_seen": 3372648,
      "step": 1690,
      "train_runtime": 9169.1093,
      "train_tokens_per_second": 367.827
    },
    {
      "epoch": 1.0633725490196078,
      "grad_norm": 0.8201208114624023,
      "learning_rate": 3.605169306329825e-05,
      "loss": 2.1892,
      "num_input_tokens_seen": 3382520,
      "step": 1695,
      "train_runtime": 9176.598,
      "train_tokens_per_second": 368.603
    },
    {
      "epoch": 1.0665098039215686,
      "grad_norm": 0.8092001080513,
      "learning_rate": 3.5977973203829676e-05,
      "loss": 2.1119,
      "num_input_tokens_seen": 3392464,
      "step": 1700,
      "train_runtime": 9184.4298,
      "train_tokens_per_second": 369.371
    },
    {
      "epoch": 1.0665098039215686,
      "eval_loss": 2.388739824295044,
      "eval_runtime": 79.0504,
      "eval_samples_per_second": 17.925,
      "eval_steps_per_second": 4.491,
      "num_input_tokens_seen": 3392464,
      "step": 1700
    },
    {
      "epoch": 1.0696470588235294,
      "grad_norm": 0.7646613121032715,
      "learning_rate": 3.590413489236427e-05,
      "loss": 2.2193,
      "num_input_tokens_seen": 3402808,
      "step": 1705,
      "train_runtime": 9271.745,
      "train_tokens_per_second": 367.008
    },
    {
      "epoch": 1.0727843137254902,
      "grad_norm": 0.7542991042137146,
      "learning_rate": 3.583017892561514e-05,
      "loss": 2.2619,
      "num_input_tokens_seen": 3413264,
      "step": 1710,
      "train_runtime": 9279.973,
      "train_tokens_per_second": 367.81
    },
    {
      "epoch": 1.075921568627451,
      "grad_norm": 0.8502288460731506,
      "learning_rate": 3.5756106101564933e-05,
      "loss": 2.1546,
      "num_input_tokens_seen": 3422784,
      "step": 1715,
      "train_runtime": 9287.1583,
      "train_tokens_per_second": 368.55
    },
    {
      "epoch": 1.0790588235294118,
      "grad_norm": 0.8810560703277588,
      "learning_rate": 3.568191721945718e-05,
      "loss": 2.0931,
      "num_input_tokens_seen": 3432296,
      "step": 1720,
      "train_runtime": 9294.2916,
      "train_tokens_per_second": 369.291
    },
    {
      "epoch": 1.0821960784313727,
      "grad_norm": 0.7790762782096863,
      "learning_rate": 3.560761307978764e-05,
      "loss": 2.2788,
      "num_input_tokens_seen": 3442344,
      "step": 1725,
      "train_runtime": 9301.9849,
      "train_tokens_per_second": 370.066
    },
    {
      "epoch": 1.0853333333333333,
      "grad_norm": 0.8290956020355225,
      "learning_rate": 3.5533194484295734e-05,
      "loss": 2.2059,
      "num_input_tokens_seen": 3452096,
      "step": 1730,
      "train_runtime": 9309.4809,
      "train_tokens_per_second": 370.815
    },
    {
      "epoch": 1.088470588235294,
      "grad_norm": 0.8385836482048035,
      "learning_rate": 3.5458662235955836e-05,
      "loss": 2.1848,
      "num_input_tokens_seen": 3461872,
      "step": 1735,
      "train_runtime": 9316.8597,
      "train_tokens_per_second": 371.571
    },
    {
      "epoch": 1.091607843137255,
      "grad_norm": 0.8171011209487915,
      "learning_rate": 3.5384017138968635e-05,
      "loss": 2.1063,
      "num_input_tokens_seen": 3472184,
      "step": 1740,
      "train_runtime": 9324.5919,
      "train_tokens_per_second": 372.368
    },
    {
      "epoch": 1.0947450980392157,
      "grad_norm": 0.8151000142097473,
      "learning_rate": 3.5309259998752464e-05,
      "loss": 2.1338,
      "num_input_tokens_seen": 3481568,
      "step": 1745,
      "train_runtime": 9331.9682,
      "train_tokens_per_second": 373.08
    },
    {
      "epoch": 1.0978823529411765,
      "grad_norm": 0.8463728427886963,
      "learning_rate": 3.523439162193459e-05,
      "loss": 2.1622,
      "num_input_tokens_seen": 3491160,
      "step": 1750,
      "train_runtime": 9339.4109,
      "train_tokens_per_second": 373.809
    },
    {
      "epoch": 1.1010196078431373,
      "grad_norm": 0.72647625207901,
      "learning_rate": 3.515941281634251e-05,
      "loss": 2.0592,
      "num_input_tokens_seen": 3500848,
      "step": 1755,
      "train_runtime": 9346.8226,
      "train_tokens_per_second": 374.55
    },
    {
      "epoch": 1.104156862745098,
      "grad_norm": 0.7744167447090149,
      "learning_rate": 3.5084324390995265e-05,
      "loss": 2.1459,
      "num_input_tokens_seen": 3511160,
      "step": 1760,
      "train_runtime": 9354.6597,
      "train_tokens_per_second": 375.338
    },
    {
      "epoch": 1.1072941176470588,
      "grad_norm": 0.8042063117027283,
      "learning_rate": 3.5009127156094685e-05,
      "loss": 2.3059,
      "num_input_tokens_seen": 3521440,
      "step": 1765,
      "train_runtime": 9362.6379,
      "train_tokens_per_second": 376.116
    },
    {
      "epoch": 1.1104313725490196,
      "grad_norm": 0.7290316224098206,
      "learning_rate": 3.493382192301663e-05,
      "loss": 2.1701,
      "num_input_tokens_seen": 3531824,
      "step": 1770,
      "train_runtime": 9370.8627,
      "train_tokens_per_second": 376.894
    },
    {
      "epoch": 1.1135686274509804,
      "grad_norm": 0.7506400346755981,
      "learning_rate": 3.485840950430229e-05,
      "loss": 2.1432,
      "num_input_tokens_seen": 3541648,
      "step": 1775,
      "train_runtime": 9378.4015,
      "train_tokens_per_second": 377.639
    },
    {
      "epoch": 1.1167058823529412,
      "grad_norm": 0.7654314637184143,
      "learning_rate": 3.4782890713649356e-05,
      "loss": 2.1732,
      "num_input_tokens_seen": 3551544,
      "step": 1780,
      "train_runtime": 9385.704,
      "train_tokens_per_second": 378.399
    },
    {
      "epoch": 1.119843137254902,
      "grad_norm": 0.8333360552787781,
      "learning_rate": 3.4707266365903304e-05,
      "loss": 2.3685,
      "num_input_tokens_seen": 3561528,
      "step": 1785,
      "train_runtime": 9393.3663,
      "train_tokens_per_second": 379.154
    },
    {
      "epoch": 1.1229803921568626,
      "grad_norm": 0.7831788659095764,
      "learning_rate": 3.463153727704851e-05,
      "loss": 2.2263,
      "num_input_tokens_seen": 3572024,
      "step": 1790,
      "train_runtime": 9401.1926,
      "train_tokens_per_second": 379.954
    },
    {
      "epoch": 1.1261176470588234,
      "grad_norm": 0.7488706111907959,
      "learning_rate": 3.455570426419956e-05,
      "loss": 2.1913,
      "num_input_tokens_seen": 3582384,
      "step": 1795,
      "train_runtime": 9409.1526,
      "train_tokens_per_second": 380.734
    },
    {
      "epoch": 1.1292549019607843,
      "grad_norm": 0.8524177670478821,
      "learning_rate": 3.4479768145592354e-05,
      "loss": 2.1511,
      "num_input_tokens_seen": 3592632,
      "step": 1800,
      "train_runtime": 9416.7876,
      "train_tokens_per_second": 381.514
    },
    {
      "epoch": 1.1292549019607843,
      "eval_loss": 2.3840901851654053,
      "eval_runtime": 78.9816,
      "eval_samples_per_second": 17.941,
      "eval_steps_per_second": 4.495,
      "num_input_tokens_seen": 3592632,
      "step": 1800
    },
    {
      "epoch": 1.132392156862745,
      "grad_norm": 0.8254775404930115,
      "learning_rate": 3.4403729740575295e-05,
      "loss": 2.0935,
      "num_input_tokens_seen": 3602320,
      "step": 1805,
      "train_runtime": 9503.657,
      "train_tokens_per_second": 379.046
    },
    {
      "epoch": 1.135529411764706,
      "grad_norm": 0.8516232371330261,
      "learning_rate": 3.432758986960047e-05,
      "loss": 2.2252,
      "num_input_tokens_seen": 3612104,
      "step": 1810,
      "train_runtime": 9510.9799,
      "train_tokens_per_second": 379.783
    },
    {
      "epoch": 1.1386666666666667,
      "grad_norm": 0.8680551648139954,
      "learning_rate": 3.4251349354214754e-05,
      "loss": 2.211,
      "num_input_tokens_seen": 3622280,
      "step": 1815,
      "train_runtime": 9518.8758,
      "train_tokens_per_second": 380.537
    },
    {
      "epoch": 1.1418039215686275,
      "grad_norm": 0.8412907123565674,
      "learning_rate": 3.4175009017051006e-05,
      "loss": 2.21,
      "num_input_tokens_seen": 3632496,
      "step": 1820,
      "train_runtime": 9526.6053,
      "train_tokens_per_second": 381.3
    },
    {
      "epoch": 1.1449411764705881,
      "grad_norm": 0.7765125632286072,
      "learning_rate": 3.409856968181913e-05,
      "loss": 2.2176,
      "num_input_tokens_seen": 3642552,
      "step": 1825,
      "train_runtime": 9534.5146,
      "train_tokens_per_second": 382.039
    },
    {
      "epoch": 1.148078431372549,
      "grad_norm": 0.8879425525665283,
      "learning_rate": 3.402203217329724e-05,
      "loss": 2.1884,
      "num_input_tokens_seen": 3652168,
      "step": 1830,
      "train_runtime": 9541.7168,
      "train_tokens_per_second": 382.758
    },
    {
      "epoch": 1.1512156862745098,
      "grad_norm": 0.7855513095855713,
      "learning_rate": 3.39453973173227e-05,
      "loss": 2.1933,
      "num_input_tokens_seen": 3661808,
      "step": 1835,
      "train_runtime": 9549.0405,
      "train_tokens_per_second": 383.474
    },
    {
      "epoch": 1.1543529411764706,
      "grad_norm": 0.7774498462677002,
      "learning_rate": 3.386866594078329e-05,
      "loss": 2.1872,
      "num_input_tokens_seen": 3671680,
      "step": 1840,
      "train_runtime": 9556.4852,
      "train_tokens_per_second": 384.208
    },
    {
      "epoch": 1.1574901960784314,
      "grad_norm": 0.7970754504203796,
      "learning_rate": 3.379183887160824e-05,
      "loss": 2.1994,
      "num_input_tokens_seen": 3682192,
      "step": 1845,
      "train_runtime": 9564.4161,
      "train_tokens_per_second": 384.989
    },
    {
      "epoch": 1.1606274509803922,
      "grad_norm": 0.792814314365387,
      "learning_rate": 3.3714916938759265e-05,
      "loss": 2.145,
      "num_input_tokens_seen": 3691888,
      "step": 1850,
      "train_runtime": 9571.9708,
      "train_tokens_per_second": 385.698
    },
    {
      "epoch": 1.163764705882353,
      "grad_norm": 0.8700534701347351,
      "learning_rate": 3.363790097222169e-05,
      "loss": 2.2055,
      "num_input_tokens_seen": 3702592,
      "step": 1855,
      "train_runtime": 9580.081,
      "train_tokens_per_second": 386.489
    },
    {
      "epoch": 1.1669019607843136,
      "grad_norm": 0.8410173654556274,
      "learning_rate": 3.3560791802995455e-05,
      "loss": 2.1474,
      "num_input_tokens_seen": 3712648,
      "step": 1860,
      "train_runtime": 9587.7897,
      "train_tokens_per_second": 387.227
    },
    {
      "epoch": 1.1700392156862744,
      "grad_norm": 0.7706979513168335,
      "learning_rate": 3.348359026308615e-05,
      "loss": 2.1929,
      "num_input_tokens_seen": 3722376,
      "step": 1865,
      "train_runtime": 9595.2283,
      "train_tokens_per_second": 387.94
    },
    {
      "epoch": 1.1731764705882353,
      "grad_norm": 0.7962079644203186,
      "learning_rate": 3.340629718549603e-05,
      "loss": 2.2101,
      "num_input_tokens_seen": 3731680,
      "step": 1870,
      "train_runtime": 9602.7853,
      "train_tokens_per_second": 388.604
    },
    {
      "epoch": 1.176313725490196,
      "grad_norm": 0.8330979943275452,
      "learning_rate": 3.3328913404215053e-05,
      "loss": 2.2656,
      "num_input_tokens_seen": 3741208,
      "step": 1875,
      "train_runtime": 9610.0647,
      "train_tokens_per_second": 389.301
    },
    {
      "epoch": 1.179450980392157,
      "grad_norm": 0.800014078617096,
      "learning_rate": 3.3251439754211883e-05,
      "loss": 2.1017,
      "num_input_tokens_seen": 3751384,
      "step": 1880,
      "train_runtime": 9617.8497,
      "train_tokens_per_second": 390.044
    },
    {
      "epoch": 1.1825882352941177,
      "grad_norm": 0.8395191431045532,
      "learning_rate": 3.317387707142483e-05,
      "loss": 2.1174,
      "num_input_tokens_seen": 3760880,
      "step": 1885,
      "train_runtime": 9625.0449,
      "train_tokens_per_second": 390.739
    },
    {
      "epoch": 1.1857254901960785,
      "grad_norm": 0.8044039011001587,
      "learning_rate": 3.309622619275287e-05,
      "loss": 2.2344,
      "num_input_tokens_seen": 3771424,
      "step": 1890,
      "train_runtime": 9633.3348,
      "train_tokens_per_second": 391.497
    },
    {
      "epoch": 1.1888627450980391,
      "grad_norm": 0.8556532263755798,
      "learning_rate": 3.301848795604665e-05,
      "loss": 2.1726,
      "num_input_tokens_seen": 3781512,
      "step": 1895,
      "train_runtime": 9640.7148,
      "train_tokens_per_second": 392.244
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.8223779201507568,
      "learning_rate": 3.294066320009936e-05,
      "loss": 2.1515,
      "num_input_tokens_seen": 3791432,
      "step": 1900,
      "train_runtime": 9648.4653,
      "train_tokens_per_second": 392.957
    },
    {
      "epoch": 1.192,
      "eval_loss": 2.376253604888916,
      "eval_runtime": 79.0167,
      "eval_samples_per_second": 17.933,
      "eval_steps_per_second": 4.493,
      "num_input_tokens_seen": 3791432,
      "step": 1900
    },
    {
      "epoch": 1.1951372549019608,
      "grad_norm": 0.8393867611885071,
      "learning_rate": 3.286275276463775e-05,
      "loss": 2.2658,
      "num_input_tokens_seen": 3801200,
      "step": 1905,
      "train_runtime": 9735.3912,
      "train_tokens_per_second": 390.452
    },
    {
      "epoch": 1.1982745098039216,
      "grad_norm": 0.7393761873245239,
      "learning_rate": 3.278475749031305e-05,
      "loss": 2.203,
      "num_input_tokens_seen": 3811536,
      "step": 1910,
      "train_runtime": 9742.9705,
      "train_tokens_per_second": 391.209
    },
    {
      "epoch": 1.2014117647058824,
      "grad_norm": 0.7628511786460876,
      "learning_rate": 3.27066782186919e-05,
      "loss": 2.2331,
      "num_input_tokens_seen": 3822256,
      "step": 1915,
      "train_runtime": 9750.9793,
      "train_tokens_per_second": 391.987
    },
    {
      "epoch": 1.2045490196078432,
      "grad_norm": 0.9189062118530273,
      "learning_rate": 3.262851579224726e-05,
      "loss": 2.2673,
      "num_input_tokens_seen": 3832200,
      "step": 1920,
      "train_runtime": 9758.448,
      "train_tokens_per_second": 392.706
    },
    {
      "epoch": 1.207686274509804,
      "grad_norm": 0.816655695438385,
      "learning_rate": 3.2550271054349333e-05,
      "loss": 2.1051,
      "num_input_tokens_seen": 3842160,
      "step": 1925,
      "train_runtime": 9766.0396,
      "train_tokens_per_second": 393.42
    },
    {
      "epoch": 1.2108235294117646,
      "grad_norm": 0.7476188540458679,
      "learning_rate": 3.247194484925647e-05,
      "loss": 2.1377,
      "num_input_tokens_seen": 3851472,
      "step": 1930,
      "train_runtime": 9773.2946,
      "train_tokens_per_second": 394.081
    },
    {
      "epoch": 1.2139607843137254,
      "grad_norm": 0.8395829796791077,
      "learning_rate": 3.2393538022106027e-05,
      "loss": 2.2065,
      "num_input_tokens_seen": 3861856,
      "step": 1935,
      "train_runtime": 9781.1888,
      "train_tokens_per_second": 394.825
    },
    {
      "epoch": 1.2170980392156863,
      "grad_norm": 0.8252895474433899,
      "learning_rate": 3.23150514189053e-05,
      "loss": 2.2089,
      "num_input_tokens_seen": 3871264,
      "step": 1940,
      "train_runtime": 9788.4363,
      "train_tokens_per_second": 395.494
    },
    {
      "epoch": 1.220235294117647,
      "grad_norm": 0.8496764302253723,
      "learning_rate": 3.223648588652232e-05,
      "loss": 2.2255,
      "num_input_tokens_seen": 3881056,
      "step": 1945,
      "train_runtime": 9795.9972,
      "train_tokens_per_second": 396.188
    },
    {
      "epoch": 1.223372549019608,
      "grad_norm": 0.8069896101951599,
      "learning_rate": 3.215784227267682e-05,
      "loss": 2.1187,
      "num_input_tokens_seen": 3891112,
      "step": 1950,
      "train_runtime": 9803.9042,
      "train_tokens_per_second": 396.894
    },
    {
      "epoch": 1.2265098039215687,
      "grad_norm": 0.8304464817047119,
      "learning_rate": 3.207912142593099e-05,
      "loss": 2.1572,
      "num_input_tokens_seen": 3900896,
      "step": 1955,
      "train_runtime": 9811.4324,
      "train_tokens_per_second": 397.587
    },
    {
      "epoch": 1.2296470588235293,
      "grad_norm": 0.8425151109695435,
      "learning_rate": 3.200032419568038e-05,
      "loss": 2.1615,
      "num_input_tokens_seen": 3911048,
      "step": 1960,
      "train_runtime": 9819.1524,
      "train_tokens_per_second": 398.308
    },
    {
      "epoch": 1.2327843137254901,
      "grad_norm": 0.8725998401641846,
      "learning_rate": 3.1921451432144685e-05,
      "loss": 2.1303,
      "num_input_tokens_seen": 3920048,
      "step": 1965,
      "train_runtime": 9826.0643,
      "train_tokens_per_second": 398.944
    },
    {
      "epoch": 1.235921568627451,
      "grad_norm": 0.7750372886657715,
      "learning_rate": 3.1842503986358646e-05,
      "loss": 2.2659,
      "num_input_tokens_seen": 3930472,
      "step": 1970,
      "train_runtime": 9833.9022,
      "train_tokens_per_second": 399.686
    },
    {
      "epoch": 1.2390588235294118,
      "grad_norm": 0.7389498353004456,
      "learning_rate": 3.176348271016278e-05,
      "loss": 2.2081,
      "num_input_tokens_seen": 3940792,
      "step": 1975,
      "train_runtime": 9841.9754,
      "train_tokens_per_second": 400.407
    },
    {
      "epoch": 1.2421960784313726,
      "grad_norm": 0.8488362431526184,
      "learning_rate": 3.168438845619428e-05,
      "loss": 2.2643,
      "num_input_tokens_seen": 3950992,
      "step": 1980,
      "train_runtime": 9849.7116,
      "train_tokens_per_second": 401.128
    },
    {
      "epoch": 1.2453333333333334,
      "grad_norm": 0.7381928563117981,
      "learning_rate": 3.1605222077877714e-05,
      "loss": 2.2064,
      "num_input_tokens_seen": 3961160,
      "step": 1985,
      "train_runtime": 9857.4806,
      "train_tokens_per_second": 401.843
    },
    {
      "epoch": 1.248470588235294,
      "grad_norm": 0.8536397218704224,
      "learning_rate": 3.152598442941591e-05,
      "loss": 2.1451,
      "num_input_tokens_seen": 3971120,
      "step": 1990,
      "train_runtime": 9865.2222,
      "train_tokens_per_second": 402.537
    },
    {
      "epoch": 1.251607843137255,
      "grad_norm": 0.7978442311286926,
      "learning_rate": 3.1446676365780674e-05,
      "loss": 2.2179,
      "num_input_tokens_seen": 3980960,
      "step": 1995,
      "train_runtime": 9872.837,
      "train_tokens_per_second": 403.224
    },
    {
      "epoch": 1.2547450980392156,
      "grad_norm": 0.8910380005836487,
      "learning_rate": 3.136729874270361e-05,
      "loss": 2.2078,
      "num_input_tokens_seen": 3991040,
      "step": 2000,
      "train_runtime": 9880.2886,
      "train_tokens_per_second": 403.94
    },
    {
      "epoch": 1.2547450980392156,
      "eval_loss": 2.3724124431610107,
      "eval_runtime": 79.0191,
      "eval_samples_per_second": 17.932,
      "eval_steps_per_second": 4.493,
      "num_input_tokens_seen": 3991040,
      "step": 2000
    },
    {
      "epoch": 1.2578823529411765,
      "grad_norm": 0.8353274464607239,
      "learning_rate": 3.1287852416666855e-05,
      "loss": 2.1545,
      "num_input_tokens_seen": 4001168,
      "step": 2005,
      "train_runtime": 9967.2662,
      "train_tokens_per_second": 401.431
    },
    {
      "epoch": 1.2610196078431373,
      "grad_norm": 0.74331134557724,
      "learning_rate": 3.120833824489383e-05,
      "loss": 2.2007,
      "num_input_tokens_seen": 4012208,
      "step": 2010,
      "train_runtime": 9975.4481,
      "train_tokens_per_second": 402.208
    },
    {
      "epoch": 1.264156862745098,
      "grad_norm": 0.8695365786552429,
      "learning_rate": 3.112875708534006e-05,
      "loss": 2.2096,
      "num_input_tokens_seen": 4021896,
      "step": 2015,
      "train_runtime": 9982.8359,
      "train_tokens_per_second": 402.881
    },
    {
      "epoch": 1.267294117647059,
      "grad_norm": 0.8129284977912903,
      "learning_rate": 3.104910979668381e-05,
      "loss": 2.1654,
      "num_input_tokens_seen": 4031672,
      "step": 2020,
      "train_runtime": 9990.4751,
      "train_tokens_per_second": 403.552
    },
    {
      "epoch": 1.2704313725490195,
      "grad_norm": 0.822498083114624,
      "learning_rate": 3.096939723831692e-05,
      "loss": 2.2303,
      "num_input_tokens_seen": 4041944,
      "step": 2025,
      "train_runtime": 9998.3323,
      "train_tokens_per_second": 404.262
    },
    {
      "epoch": 1.2735686274509803,
      "grad_norm": 0.8578911423683167,
      "learning_rate": 3.088962027033545e-05,
      "loss": 2.2855,
      "num_input_tokens_seen": 4052352,
      "step": 2030,
      "train_runtime": 10006.5045,
      "train_tokens_per_second": 404.972
    },
    {
      "epoch": 1.2767058823529411,
      "grad_norm": 0.8315767049789429,
      "learning_rate": 3.080977975353048e-05,
      "loss": 2.1012,
      "num_input_tokens_seen": 4062360,
      "step": 2035,
      "train_runtime": 10014.2337,
      "train_tokens_per_second": 405.659
    },
    {
      "epoch": 1.279843137254902,
      "grad_norm": 0.7670605778694153,
      "learning_rate": 3.072987654937873e-05,
      "loss": 2.1607,
      "num_input_tokens_seen": 4072208,
      "step": 2040,
      "train_runtime": 10021.4855,
      "train_tokens_per_second": 406.348
    },
    {
      "epoch": 1.2829803921568628,
      "grad_norm": 0.8531294465065002,
      "learning_rate": 3.064991152003337e-05,
      "loss": 2.3174,
      "num_input_tokens_seen": 4082520,
      "step": 2045,
      "train_runtime": 10029.2421,
      "train_tokens_per_second": 407.062
    },
    {
      "epoch": 1.2861176470588236,
      "grad_norm": 0.8194733262062073,
      "learning_rate": 3.056988552831461e-05,
      "loss": 2.1713,
      "num_input_tokens_seen": 4092688,
      "step": 2050,
      "train_runtime": 10036.9173,
      "train_tokens_per_second": 407.763
    },
    {
      "epoch": 1.2892549019607844,
      "grad_norm": 0.873910129070282,
      "learning_rate": 3.0489799437700472e-05,
      "loss": 2.227,
      "num_input_tokens_seen": 4102288,
      "step": 2055,
      "train_runtime": 10044.3749,
      "train_tokens_per_second": 408.416
    },
    {
      "epoch": 1.292392156862745,
      "grad_norm": 0.8694836497306824,
      "learning_rate": 3.040965411231744e-05,
      "loss": 2.2381,
      "num_input_tokens_seen": 4112336,
      "step": 2060,
      "train_runtime": 10052.0431,
      "train_tokens_per_second": 409.104
    },
    {
      "epoch": 1.2955294117647058,
      "grad_norm": 0.8342404961585999,
      "learning_rate": 3.0329450416931143e-05,
      "loss": 2.1892,
      "num_input_tokens_seen": 4122296,
      "step": 2065,
      "train_runtime": 10059.9094,
      "train_tokens_per_second": 409.775
    },
    {
      "epoch": 1.2986666666666666,
      "grad_norm": 0.7798029184341431,
      "learning_rate": 3.0249189216937008e-05,
      "loss": 2.2167,
      "num_input_tokens_seen": 4133048,
      "step": 2070,
      "train_runtime": 10068.1392,
      "train_tokens_per_second": 410.508
    },
    {
      "epoch": 1.3018039215686275,
      "grad_norm": 0.8937613368034363,
      "learning_rate": 3.016887137835093e-05,
      "loss": 2.2452,
      "num_input_tokens_seen": 4143576,
      "step": 2075,
      "train_runtime": 10076.5138,
      "train_tokens_per_second": 411.211
    },
    {
      "epoch": 1.3049411764705883,
      "grad_norm": 0.7946799993515015,
      "learning_rate": 3.0088497767799968e-05,
      "loss": 2.1258,
      "num_input_tokens_seen": 4153152,
      "step": 2080,
      "train_runtime": 10083.8291,
      "train_tokens_per_second": 411.863
    },
    {
      "epoch": 1.308078431372549,
      "grad_norm": 0.8940634727478027,
      "learning_rate": 3.0008069252512905e-05,
      "loss": 2.2234,
      "num_input_tokens_seen": 4163264,
      "step": 2085,
      "train_runtime": 10091.5364,
      "train_tokens_per_second": 412.55
    },
    {
      "epoch": 1.31121568627451,
      "grad_norm": 0.9551220536231995,
      "learning_rate": 2.9927586700311e-05,
      "loss": 2.1699,
      "num_input_tokens_seen": 4172920,
      "step": 2090,
      "train_runtime": 10099.1273,
      "train_tokens_per_second": 413.196
    },
    {
      "epoch": 1.3143529411764705,
      "grad_norm": 0.8251965641975403,
      "learning_rate": 2.9847050979598517e-05,
      "loss": 2.3088,
      "num_input_tokens_seen": 4183384,
      "step": 2095,
      "train_runtime": 10107.0093,
      "train_tokens_per_second": 413.909
    },
    {
      "epoch": 1.3174901960784313,
      "grad_norm": 0.8030139803886414,
      "learning_rate": 2.9766462959353463e-05,
      "loss": 2.1472,
      "num_input_tokens_seen": 4193712,
      "step": 2100,
      "train_runtime": 10115.0351,
      "train_tokens_per_second": 414.602
    },
    {
      "epoch": 1.3174901960784313,
      "eval_loss": 2.3644943237304688,
      "eval_runtime": 79.0261,
      "eval_samples_per_second": 17.931,
      "eval_steps_per_second": 4.492,
      "num_input_tokens_seen": 4193712,
      "step": 2100
    },
    {
      "epoch": 1.3206274509803921,
      "grad_norm": 0.8879997134208679,
      "learning_rate": 2.9685823509118093e-05,
      "loss": 2.2429,
      "num_input_tokens_seen": 4203048,
      "step": 2105,
      "train_runtime": 10201.6011,
      "train_tokens_per_second": 411.999
    },
    {
      "epoch": 1.323764705882353,
      "grad_norm": 0.8737501502037048,
      "learning_rate": 2.9605133498989646e-05,
      "loss": 2.2663,
      "num_input_tokens_seen": 4212768,
      "step": 2110,
      "train_runtime": 10209.1409,
      "train_tokens_per_second": 412.647
    },
    {
      "epoch": 1.3269019607843138,
      "grad_norm": 0.9006035327911377,
      "learning_rate": 2.952439379961086e-05,
      "loss": 2.3161,
      "num_input_tokens_seen": 4223024,
      "step": 2115,
      "train_runtime": 10217.0242,
      "train_tokens_per_second": 413.332
    },
    {
      "epoch": 1.3300392156862746,
      "grad_norm": 0.8784193396568298,
      "learning_rate": 2.9443605282160648e-05,
      "loss": 2.1738,
      "num_input_tokens_seen": 4232824,
      "step": 2120,
      "train_runtime": 10224.2399,
      "train_tokens_per_second": 413.999
    },
    {
      "epoch": 1.3331764705882354,
      "grad_norm": 0.8839720487594604,
      "learning_rate": 2.9362768818344638e-05,
      "loss": 2.3072,
      "num_input_tokens_seen": 4242672,
      "step": 2125,
      "train_runtime": 10231.85,
      "train_tokens_per_second": 414.653
    },
    {
      "epoch": 1.336313725490196,
      "grad_norm": 0.803675651550293,
      "learning_rate": 2.928188528038583e-05,
      "loss": 2.1446,
      "num_input_tokens_seen": 4252864,
      "step": 2130,
      "train_runtime": 10239.6792,
      "train_tokens_per_second": 415.332
    },
    {
      "epoch": 1.3394509803921568,
      "grad_norm": 0.7936355471611023,
      "learning_rate": 2.920095554101513e-05,
      "loss": 2.1977,
      "num_input_tokens_seen": 4262936,
      "step": 2135,
      "train_runtime": 10247.1401,
      "train_tokens_per_second": 416.012
    },
    {
      "epoch": 1.3425882352941176,
      "grad_norm": 0.8551798462867737,
      "learning_rate": 2.9119980473461965e-05,
      "loss": 2.2792,
      "num_input_tokens_seen": 4273056,
      "step": 2140,
      "train_runtime": 10254.8256,
      "train_tokens_per_second": 416.687
    },
    {
      "epoch": 1.3457254901960785,
      "grad_norm": 0.9549434185028076,
      "learning_rate": 2.9038960951444854e-05,
      "loss": 2.1715,
      "num_input_tokens_seen": 4283152,
      "step": 2145,
      "train_runtime": 10262.6104,
      "train_tokens_per_second": 417.355
    },
    {
      "epoch": 1.3488627450980393,
      "grad_norm": 0.8929479718208313,
      "learning_rate": 2.8957897849161962e-05,
      "loss": 2.1921,
      "num_input_tokens_seen": 4293408,
      "step": 2150,
      "train_runtime": 10270.5525,
      "train_tokens_per_second": 418.031
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.8206591606140137,
      "learning_rate": 2.8876792041281715e-05,
      "loss": 2.2172,
      "num_input_tokens_seen": 4303232,
      "step": 2155,
      "train_runtime": 10278.075,
      "train_tokens_per_second": 418.681
    },
    {
      "epoch": 1.355137254901961,
      "grad_norm": 0.9329007863998413,
      "learning_rate": 2.8795644402933298e-05,
      "loss": 2.1612,
      "num_input_tokens_seen": 4312576,
      "step": 2160,
      "train_runtime": 10285.4119,
      "train_tokens_per_second": 419.291
    },
    {
      "epoch": 1.3582745098039215,
      "grad_norm": 0.9082239866256714,
      "learning_rate": 2.8714455809697268e-05,
      "loss": 2.1459,
      "num_input_tokens_seen": 4322720,
      "step": 2165,
      "train_runtime": 10293.2575,
      "train_tokens_per_second": 419.956
    },
    {
      "epoch": 1.3614117647058823,
      "grad_norm": 0.9709713459014893,
      "learning_rate": 2.8633227137596063e-05,
      "loss": 2.2487,
      "num_input_tokens_seen": 4332776,
      "step": 2170,
      "train_runtime": 10300.9312,
      "train_tokens_per_second": 420.62
    },
    {
      "epoch": 1.3645490196078431,
      "grad_norm": 0.8286260962486267,
      "learning_rate": 2.8551959263084603e-05,
      "loss": 2.2784,
      "num_input_tokens_seen": 4343264,
      "step": 2175,
      "train_runtime": 10309.2181,
      "train_tokens_per_second": 421.299
    },
    {
      "epoch": 1.367686274509804,
      "grad_norm": 0.8343477845191956,
      "learning_rate": 2.847065306304076e-05,
      "loss": 2.1856,
      "num_input_tokens_seen": 4352984,
      "step": 2180,
      "train_runtime": 10316.7303,
      "train_tokens_per_second": 421.934
    },
    {
      "epoch": 1.3708235294117648,
      "grad_norm": 0.832737147808075,
      "learning_rate": 2.8389309414755972e-05,
      "loss": 2.2225,
      "num_input_tokens_seen": 4363016,
      "step": 2185,
      "train_runtime": 10324.0937,
      "train_tokens_per_second": 422.605
    },
    {
      "epoch": 1.3739607843137254,
      "grad_norm": 0.9168224930763245,
      "learning_rate": 2.8307929195925724e-05,
      "loss": 2.1361,
      "num_input_tokens_seen": 4373016,
      "step": 2190,
      "train_runtime": 10331.9796,
      "train_tokens_per_second": 423.251
    },
    {
      "epoch": 1.3770980392156864,
      "grad_norm": 0.8738197684288025,
      "learning_rate": 2.822651328464011e-05,
      "loss": 2.2374,
      "num_input_tokens_seen": 4383312,
      "step": 2195,
      "train_runtime": 10339.7382,
      "train_tokens_per_second": 423.929
    },
    {
      "epoch": 1.380235294117647,
      "grad_norm": 0.8858362436294556,
      "learning_rate": 2.814506255937432e-05,
      "loss": 2.22,
      "num_input_tokens_seen": 4392944,
      "step": 2200,
      "train_runtime": 10347.2511,
      "train_tokens_per_second": 424.552
    },
    {
      "epoch": 1.380235294117647,
      "eval_loss": 2.3550777435302734,
      "eval_runtime": 78.9416,
      "eval_samples_per_second": 17.95,
      "eval_steps_per_second": 4.497,
      "num_input_tokens_seen": 4392944,
      "step": 2200
    },
    {
      "epoch": 1.3833725490196078,
      "grad_norm": 0.8427743315696716,
      "learning_rate": 2.806357789897921e-05,
      "loss": 2.1577,
      "num_input_tokens_seen": 4403064,
      "step": 2205,
      "train_runtime": 10434.1681,
      "train_tokens_per_second": 421.985
    },
    {
      "epoch": 1.3865098039215686,
      "grad_norm": 0.871910572052002,
      "learning_rate": 2.7982060182671794e-05,
      "loss": 2.1421,
      "num_input_tokens_seen": 4413256,
      "step": 2210,
      "train_runtime": 10441.8357,
      "train_tokens_per_second": 422.651
    },
    {
      "epoch": 1.3896470588235295,
      "grad_norm": 0.8829131722450256,
      "learning_rate": 2.7900510290025727e-05,
      "loss": 2.1836,
      "num_input_tokens_seen": 4423520,
      "step": 2215,
      "train_runtime": 10449.5691,
      "train_tokens_per_second": 423.321
    },
    {
      "epoch": 1.3927843137254903,
      "grad_norm": 0.9024247527122498,
      "learning_rate": 2.78189291009619e-05,
      "loss": 2.1799,
      "num_input_tokens_seen": 4433792,
      "step": 2220,
      "train_runtime": 10457.5073,
      "train_tokens_per_second": 423.982
    },
    {
      "epoch": 1.3959215686274509,
      "grad_norm": 0.7284942865371704,
      "learning_rate": 2.773731749573884e-05,
      "loss": 2.2136,
      "num_input_tokens_seen": 4444736,
      "step": 2225,
      "train_runtime": 10465.7636,
      "train_tokens_per_second": 424.693
    },
    {
      "epoch": 1.3990588235294117,
      "grad_norm": 0.8843998312950134,
      "learning_rate": 2.765567635494329e-05,
      "loss": 2.1334,
      "num_input_tokens_seen": 4454584,
      "step": 2230,
      "train_runtime": 10473.349,
      "train_tokens_per_second": 425.326
    },
    {
      "epoch": 1.4021960784313725,
      "grad_norm": 0.8580219149589539,
      "learning_rate": 2.757400655948067e-05,
      "loss": 2.1356,
      "num_input_tokens_seen": 4464024,
      "step": 2235,
      "train_runtime": 10480.5842,
      "train_tokens_per_second": 425.933
    },
    {
      "epoch": 1.4053333333333333,
      "grad_norm": 0.8573769927024841,
      "learning_rate": 2.7492308990565607e-05,
      "loss": 2.2183,
      "num_input_tokens_seen": 4474512,
      "step": 2240,
      "train_runtime": 10488.8113,
      "train_tokens_per_second": 426.599
    },
    {
      "epoch": 1.4084705882352941,
      "grad_norm": 0.7801220417022705,
      "learning_rate": 2.7410584529712353e-05,
      "loss": 2.3106,
      "num_input_tokens_seen": 4484456,
      "step": 2245,
      "train_runtime": 10496.2368,
      "train_tokens_per_second": 427.244
    },
    {
      "epoch": 1.411607843137255,
      "grad_norm": 0.8478468656539917,
      "learning_rate": 2.732883405872538e-05,
      "loss": 2.1069,
      "num_input_tokens_seen": 4494280,
      "step": 2250,
      "train_runtime": 10503.8728,
      "train_tokens_per_second": 427.869
    },
    {
      "epoch": 1.4147450980392158,
      "grad_norm": 0.8434497117996216,
      "learning_rate": 2.7247058459689772e-05,
      "loss": 2.2593,
      "num_input_tokens_seen": 4504400,
      "step": 2255,
      "train_runtime": 10511.7126,
      "train_tokens_per_second": 428.512
    },
    {
      "epoch": 1.4178823529411764,
      "grad_norm": 0.9438812136650085,
      "learning_rate": 2.7165258614961753e-05,
      "loss": 2.1786,
      "num_input_tokens_seen": 4514128,
      "step": 2260,
      "train_runtime": 10519.0826,
      "train_tokens_per_second": 429.137
    },
    {
      "epoch": 1.4210196078431372,
      "grad_norm": 0.7757895588874817,
      "learning_rate": 2.7083435407159157e-05,
      "loss": 2.1325,
      "num_input_tokens_seen": 4524184,
      "step": 2265,
      "train_runtime": 10526.8414,
      "train_tokens_per_second": 429.776
    },
    {
      "epoch": 1.424156862745098,
      "grad_norm": 0.9270001649856567,
      "learning_rate": 2.700158971915192e-05,
      "loss": 2.2267,
      "num_input_tokens_seen": 4534432,
      "step": 2270,
      "train_runtime": 10534.6761,
      "train_tokens_per_second": 430.429
    },
    {
      "epoch": 1.4272941176470588,
      "grad_norm": 0.9601079225540161,
      "learning_rate": 2.6919722434052512e-05,
      "loss": 2.131,
      "num_input_tokens_seen": 4543864,
      "step": 2275,
      "train_runtime": 10541.809,
      "train_tokens_per_second": 431.033
    },
    {
      "epoch": 1.4304313725490196,
      "grad_norm": 0.9079379439353943,
      "learning_rate": 2.683783443520645e-05,
      "loss": 2.1691,
      "num_input_tokens_seen": 4553880,
      "step": 2280,
      "train_runtime": 10549.3139,
      "train_tokens_per_second": 431.675
    },
    {
      "epoch": 1.4335686274509805,
      "grad_norm": 0.8504190444946289,
      "learning_rate": 2.6755926606182758e-05,
      "loss": 2.1636,
      "num_input_tokens_seen": 4563928,
      "step": 2285,
      "train_runtime": 10557.1466,
      "train_tokens_per_second": 432.307
    },
    {
      "epoch": 1.4367058823529413,
      "grad_norm": 0.8344516754150391,
      "learning_rate": 2.6673999830764405e-05,
      "loss": 2.146,
      "num_input_tokens_seen": 4574432,
      "step": 2290,
      "train_runtime": 10565.1988,
      "train_tokens_per_second": 432.972
    },
    {
      "epoch": 1.4398431372549019,
      "grad_norm": 0.8193700313568115,
      "learning_rate": 2.659205499293882e-05,
      "loss": 2.2303,
      "num_input_tokens_seen": 4584408,
      "step": 2295,
      "train_runtime": 10572.8399,
      "train_tokens_per_second": 433.602
    },
    {
      "epoch": 1.4429803921568627,
      "grad_norm": 0.8498283624649048,
      "learning_rate": 2.6510092976888303e-05,
      "loss": 2.1871,
      "num_input_tokens_seen": 4594560,
      "step": 2300,
      "train_runtime": 10580.4944,
      "train_tokens_per_second": 434.248
    },
    {
      "epoch": 1.4429803921568627,
      "eval_loss": 2.3504765033721924,
      "eval_runtime": 78.9709,
      "eval_samples_per_second": 17.943,
      "eval_steps_per_second": 4.495,
      "num_input_tokens_seen": 4594560,
      "step": 2300
    },
    {
      "epoch": 1.4461176470588235,
      "grad_norm": 0.9331158995628357,
      "learning_rate": 2.642811466698051e-05,
      "loss": 2.2268,
      "num_input_tokens_seen": 4604432,
      "step": 2305,
      "train_runtime": 10667.431,
      "train_tokens_per_second": 431.635
    },
    {
      "epoch": 1.4492549019607843,
      "grad_norm": 0.9317331910133362,
      "learning_rate": 2.6346120947758907e-05,
      "loss": 2.1527,
      "num_input_tokens_seen": 4614064,
      "step": 2310,
      "train_runtime": 10675.0337,
      "train_tokens_per_second": 432.229
    },
    {
      "epoch": 1.4523921568627451,
      "grad_norm": 0.839919924736023,
      "learning_rate": 2.6264112703933247e-05,
      "loss": 2.0625,
      "num_input_tokens_seen": 4623800,
      "step": 2315,
      "train_runtime": 10682.4429,
      "train_tokens_per_second": 432.841
    },
    {
      "epoch": 1.455529411764706,
      "grad_norm": 0.9386906027793884,
      "learning_rate": 2.618209082036997e-05,
      "loss": 2.1843,
      "num_input_tokens_seen": 4633768,
      "step": 2320,
      "train_runtime": 10690.1337,
      "train_tokens_per_second": 433.462
    },
    {
      "epoch": 1.4586666666666668,
      "grad_norm": 0.9494760632514954,
      "learning_rate": 2.610005618208271e-05,
      "loss": 2.1758,
      "num_input_tokens_seen": 4644088,
      "step": 2325,
      "train_runtime": 10698.0491,
      "train_tokens_per_second": 434.106
    },
    {
      "epoch": 1.4618039215686274,
      "grad_norm": 0.8555777072906494,
      "learning_rate": 2.601800967422271e-05,
      "loss": 2.1885,
      "num_input_tokens_seen": 4653680,
      "step": 2330,
      "train_runtime": 10705.7756,
      "train_tokens_per_second": 434.689
    },
    {
      "epoch": 1.4649411764705882,
      "grad_norm": 0.9055178761482239,
      "learning_rate": 2.593595218206931e-05,
      "loss": 2.0457,
      "num_input_tokens_seen": 4663280,
      "step": 2335,
      "train_runtime": 10713.2784,
      "train_tokens_per_second": 435.28
    },
    {
      "epoch": 1.468078431372549,
      "grad_norm": 0.8952035903930664,
      "learning_rate": 2.5853884591020345e-05,
      "loss": 2.2421,
      "num_input_tokens_seen": 4673424,
      "step": 2340,
      "train_runtime": 10720.7053,
      "train_tokens_per_second": 435.925
    },
    {
      "epoch": 1.4712156862745098,
      "grad_norm": 0.9685643911361694,
      "learning_rate": 2.577180778658262e-05,
      "loss": 2.1509,
      "num_input_tokens_seen": 4682792,
      "step": 2345,
      "train_runtime": 10727.8205,
      "train_tokens_per_second": 436.509
    },
    {
      "epoch": 1.4743529411764706,
      "grad_norm": 0.8891441822052002,
      "learning_rate": 2.5689722654362357e-05,
      "loss": 2.1874,
      "num_input_tokens_seen": 4692720,
      "step": 2350,
      "train_runtime": 10735.3085,
      "train_tokens_per_second": 437.129
    },
    {
      "epoch": 1.4774901960784312,
      "grad_norm": 0.8975565433502197,
      "learning_rate": 2.5607630080055646e-05,
      "loss": 2.2339,
      "num_input_tokens_seen": 4701952,
      "step": 2355,
      "train_runtime": 10742.2413,
      "train_tokens_per_second": 437.707
    },
    {
      "epoch": 1.4806274509803923,
      "grad_norm": 0.934127151966095,
      "learning_rate": 2.5525530949438858e-05,
      "loss": 2.1587,
      "num_input_tokens_seen": 4711272,
      "step": 2360,
      "train_runtime": 10749.4749,
      "train_tokens_per_second": 438.279
    },
    {
      "epoch": 1.4837647058823529,
      "grad_norm": 0.8855400681495667,
      "learning_rate": 2.5443426148359117e-05,
      "loss": 2.192,
      "num_input_tokens_seen": 4720848,
      "step": 2365,
      "train_runtime": 10756.9891,
      "train_tokens_per_second": 438.863
    },
    {
      "epoch": 1.4869019607843137,
      "grad_norm": 0.8893212080001831,
      "learning_rate": 2.5361316562724723e-05,
      "loss": 2.2366,
      "num_input_tokens_seen": 4730912,
      "step": 2370,
      "train_runtime": 10764.5363,
      "train_tokens_per_second": 439.491
    },
    {
      "epoch": 1.4900392156862745,
      "grad_norm": 0.9266489744186401,
      "learning_rate": 2.5279203078495612e-05,
      "loss": 2.1483,
      "num_input_tokens_seen": 4741144,
      "step": 2375,
      "train_runtime": 10772.24,
      "train_tokens_per_second": 440.126
    },
    {
      "epoch": 1.4931764705882353,
      "grad_norm": 0.8381653428077698,
      "learning_rate": 2.519708658167379e-05,
      "loss": 2.1429,
      "num_input_tokens_seen": 4751080,
      "step": 2380,
      "train_runtime": 10779.7844,
      "train_tokens_per_second": 440.74
    },
    {
      "epoch": 1.4963137254901961,
      "grad_norm": 0.8947359919548035,
      "learning_rate": 2.5114967958293733e-05,
      "loss": 2.2642,
      "num_input_tokens_seen": 4760816,
      "step": 2385,
      "train_runtime": 10787.3203,
      "train_tokens_per_second": 441.334
    },
    {
      "epoch": 1.4994509803921567,
      "grad_norm": 0.9009884595870972,
      "learning_rate": 2.5032848094412915e-05,
      "loss": 2.2174,
      "num_input_tokens_seen": 4771168,
      "step": 2390,
      "train_runtime": 10795.3678,
      "train_tokens_per_second": 441.964
    },
    {
      "epoch": 1.5025882352941178,
      "grad_norm": 0.9271688461303711,
      "learning_rate": 2.4950727876102154e-05,
      "loss": 2.1523,
      "num_input_tokens_seen": 4781328,
      "step": 2395,
      "train_runtime": 10803.1589,
      "train_tokens_per_second": 442.586
    },
    {
      "epoch": 1.5057254901960784,
      "grad_norm": 0.8358123898506165,
      "learning_rate": 2.4868608189436106e-05,
      "loss": 2.1217,
      "num_input_tokens_seen": 4791544,
      "step": 2400,
      "train_runtime": 10811.334,
      "train_tokens_per_second": 443.196
    },
    {
      "epoch": 1.5057254901960784,
      "eval_loss": 2.3447911739349365,
      "eval_runtime": 78.9395,
      "eval_samples_per_second": 17.95,
      "eval_steps_per_second": 4.497,
      "num_input_tokens_seen": 4791544,
      "step": 2400
    },
    {
      "epoch": 1.5088627450980392,
      "grad_norm": 0.8214766383171082,
      "learning_rate": 2.47864899204837e-05,
      "loss": 2.1067,
      "num_input_tokens_seen": 4801832,
      "step": 2405,
      "train_runtime": 10898.4733,
      "train_tokens_per_second": 440.597
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.8323304057121277,
      "learning_rate": 2.4704373955298557e-05,
      "loss": 2.1897,
      "num_input_tokens_seen": 4812200,
      "step": 2410,
      "train_runtime": 10906.3996,
      "train_tokens_per_second": 441.227
    },
    {
      "epoch": 1.5151372549019608,
      "grad_norm": 0.8367763757705688,
      "learning_rate": 2.4622261179909435e-05,
      "loss": 2.1799,
      "num_input_tokens_seen": 4822464,
      "step": 2415,
      "train_runtime": 10914.0458,
      "train_tokens_per_second": 441.859
    },
    {
      "epoch": 1.5182745098039216,
      "grad_norm": 0.8459058403968811,
      "learning_rate": 2.4540152480310695e-05,
      "loss": 2.1813,
      "num_input_tokens_seen": 4832952,
      "step": 2420,
      "train_runtime": 10921.8202,
      "train_tokens_per_second": 442.504
    },
    {
      "epoch": 1.5214117647058822,
      "grad_norm": 0.9788263440132141,
      "learning_rate": 2.4458048742452706e-05,
      "loss": 2.1482,
      "num_input_tokens_seen": 4843344,
      "step": 2425,
      "train_runtime": 10929.7773,
      "train_tokens_per_second": 443.133
    },
    {
      "epoch": 1.5245490196078433,
      "grad_norm": 0.8385351300239563,
      "learning_rate": 2.437595085223228e-05,
      "loss": 2.1201,
      "num_input_tokens_seen": 4853832,
      "step": 2430,
      "train_runtime": 10937.9706,
      "train_tokens_per_second": 443.76
    },
    {
      "epoch": 1.5276862745098039,
      "grad_norm": 0.8868191838264465,
      "learning_rate": 2.4293859695483187e-05,
      "loss": 2.1634,
      "num_input_tokens_seen": 4862992,
      "step": 2435,
      "train_runtime": 10944.7982,
      "train_tokens_per_second": 444.32
    },
    {
      "epoch": 1.5308235294117647,
      "grad_norm": 0.887245774269104,
      "learning_rate": 2.421177615796649e-05,
      "loss": 2.1798,
      "num_input_tokens_seen": 4872608,
      "step": 2440,
      "train_runtime": 10952.2139,
      "train_tokens_per_second": 444.897
    },
    {
      "epoch": 1.5339607843137255,
      "grad_norm": 0.8621636629104614,
      "learning_rate": 2.4129701125361056e-05,
      "loss": 2.1039,
      "num_input_tokens_seen": 4882360,
      "step": 2445,
      "train_runtime": 10959.629,
      "train_tokens_per_second": 445.486
    },
    {
      "epoch": 1.5370980392156863,
      "grad_norm": 0.8238694667816162,
      "learning_rate": 2.4047635483254007e-05,
      "loss": 2.1991,
      "num_input_tokens_seen": 4892392,
      "step": 2450,
      "train_runtime": 10967.1671,
      "train_tokens_per_second": 446.094
    },
    {
      "epoch": 1.5402352941176471,
      "grad_norm": 0.8713784217834473,
      "learning_rate": 2.3965580117131116e-05,
      "loss": 2.2715,
      "num_input_tokens_seen": 4902936,
      "step": 2455,
      "train_runtime": 10975.1389,
      "train_tokens_per_second": 446.731
    },
    {
      "epoch": 1.5433725490196077,
      "grad_norm": 0.9657586216926575,
      "learning_rate": 2.3883535912367277e-05,
      "loss": 2.1401,
      "num_input_tokens_seen": 4912528,
      "step": 2460,
      "train_runtime": 10982.6129,
      "train_tokens_per_second": 447.3
    },
    {
      "epoch": 1.5465098039215688,
      "grad_norm": 0.9915129542350769,
      "learning_rate": 2.3801503754216985e-05,
      "loss": 2.22,
      "num_input_tokens_seen": 4922072,
      "step": 2465,
      "train_runtime": 10989.8029,
      "train_tokens_per_second": 447.876
    },
    {
      "epoch": 1.5496470588235294,
      "grad_norm": 0.8878453969955444,
      "learning_rate": 2.3719484527804717e-05,
      "loss": 2.1814,
      "num_input_tokens_seen": 4931512,
      "step": 2470,
      "train_runtime": 10997.1717,
      "train_tokens_per_second": 448.435
    },
    {
      "epoch": 1.5527843137254902,
      "grad_norm": 0.8115075826644897,
      "learning_rate": 2.3637479118115422e-05,
      "loss": 2.1766,
      "num_input_tokens_seen": 4941544,
      "step": 2475,
      "train_runtime": 11004.88,
      "train_tokens_per_second": 449.032
    },
    {
      "epoch": 1.555921568627451,
      "grad_norm": 0.9168897867202759,
      "learning_rate": 2.3555488409984992e-05,
      "loss": 2.25,
      "num_input_tokens_seen": 4951152,
      "step": 2480,
      "train_runtime": 11012.2426,
      "train_tokens_per_second": 449.604
    },
    {
      "epoch": 1.5590588235294116,
      "grad_norm": 0.8804802298545837,
      "learning_rate": 2.3473513288090664e-05,
      "loss": 2.1215,
      "num_input_tokens_seen": 4961248,
      "step": 2485,
      "train_runtime": 11020.0502,
      "train_tokens_per_second": 450.202
    },
    {
      "epoch": 1.5621960784313726,
      "grad_norm": 0.9121412634849548,
      "learning_rate": 2.339155463694151e-05,
      "loss": 2.1219,
      "num_input_tokens_seen": 4970648,
      "step": 2490,
      "train_runtime": 11027.2305,
      "train_tokens_per_second": 450.761
    },
    {
      "epoch": 1.5653333333333332,
      "grad_norm": 0.9128673672676086,
      "learning_rate": 2.3309613340868884e-05,
      "loss": 2.2758,
      "num_input_tokens_seen": 4980864,
      "step": 2495,
      "train_runtime": 11034.7596,
      "train_tokens_per_second": 451.379
    },
    {
      "epoch": 1.5684705882352943,
      "grad_norm": 0.9638357758522034,
      "learning_rate": 2.3227690284016883e-05,
      "loss": 2.2569,
      "num_input_tokens_seen": 4990752,
      "step": 2500,
      "train_runtime": 11042.2891,
      "train_tokens_per_second": 451.967
    },
    {
      "epoch": 1.5684705882352943,
      "eval_loss": 2.339707851409912,
      "eval_runtime": 78.9455,
      "eval_samples_per_second": 17.949,
      "eval_steps_per_second": 4.497,
      "num_input_tokens_seen": 4990752,
      "step": 2500
    },
    {
      "epoch": 1.5716078431372549,
      "grad_norm": 0.8393397927284241,
      "learning_rate": 2.3145786350332776e-05,
      "loss": 2.1841,
      "num_input_tokens_seen": 4999984,
      "step": 2505,
      "train_runtime": 11128.6609,
      "train_tokens_per_second": 449.289
    },
    {
      "epoch": 1.5747450980392157,
      "grad_norm": 0.9641789793968201,
      "learning_rate": 2.3063902423557545e-05,
      "loss": 2.0974,
      "num_input_tokens_seen": 5009728,
      "step": 2510,
      "train_runtime": 11136.2585,
      "train_tokens_per_second": 449.857
    },
    {
      "epoch": 1.5778823529411765,
      "grad_norm": 0.8685287833213806,
      "learning_rate": 2.2982039387216254e-05,
      "loss": 2.1514,
      "num_input_tokens_seen": 5020112,
      "step": 2515,
      "train_runtime": 11144.3151,
      "train_tokens_per_second": 450.464
    },
    {
      "epoch": 1.581019607843137,
      "grad_norm": 0.9253703951835632,
      "learning_rate": 2.2900198124608564e-05,
      "loss": 2.1677,
      "num_input_tokens_seen": 5030448,
      "step": 2520,
      "train_runtime": 11152.338,
      "train_tokens_per_second": 451.067
    },
    {
      "epoch": 1.5841568627450981,
      "grad_norm": 0.8799592852592468,
      "learning_rate": 2.2818379518799224e-05,
      "loss": 2.2965,
      "num_input_tokens_seen": 5040840,
      "step": 2525,
      "train_runtime": 11160.2633,
      "train_tokens_per_second": 451.678
    },
    {
      "epoch": 1.5872941176470587,
      "grad_norm": 0.9316130876541138,
      "learning_rate": 2.2736584452608496e-05,
      "loss": 2.2159,
      "num_input_tokens_seen": 5050448,
      "step": 2530,
      "train_runtime": 11167.7737,
      "train_tokens_per_second": 452.234
    },
    {
      "epoch": 1.5904313725490196,
      "grad_norm": 0.8546066880226135,
      "learning_rate": 2.265481380860265e-05,
      "loss": 2.1113,
      "num_input_tokens_seen": 5060560,
      "step": 2535,
      "train_runtime": 11175.4158,
      "train_tokens_per_second": 452.83
    },
    {
      "epoch": 1.5935686274509804,
      "grad_norm": 0.8291714191436768,
      "learning_rate": 2.2573068469084456e-05,
      "loss": 2.1731,
      "num_input_tokens_seen": 5070592,
      "step": 2540,
      "train_runtime": 11182.9355,
      "train_tokens_per_second": 453.422
    },
    {
      "epoch": 1.5967058823529412,
      "grad_norm": 0.882797122001648,
      "learning_rate": 2.2491349316083643e-05,
      "loss": 2.1316,
      "num_input_tokens_seen": 5080880,
      "step": 2545,
      "train_runtime": 11190.6021,
      "train_tokens_per_second": 454.031
    },
    {
      "epoch": 1.599843137254902,
      "grad_norm": 0.8853169083595276,
      "learning_rate": 2.240965723134737e-05,
      "loss": 2.1079,
      "num_input_tokens_seen": 5091056,
      "step": 2550,
      "train_runtime": 11198.3976,
      "train_tokens_per_second": 454.624
    },
    {
      "epoch": 1.6029803921568626,
      "grad_norm": 0.8941015601158142,
      "learning_rate": 2.2327993096330754e-05,
      "loss": 2.1174,
      "num_input_tokens_seen": 5100736,
      "step": 2555,
      "train_runtime": 11205.884,
      "train_tokens_per_second": 455.184
    },
    {
      "epoch": 1.6061176470588236,
      "grad_norm": 0.8647210597991943,
      "learning_rate": 2.224635779218733e-05,
      "loss": 2.0115,
      "num_input_tokens_seen": 5110648,
      "step": 2560,
      "train_runtime": 11213.6791,
      "train_tokens_per_second": 455.751
    },
    {
      "epoch": 1.6092549019607842,
      "grad_norm": 0.9339298009872437,
      "learning_rate": 2.2164752199759538e-05,
      "loss": 2.0938,
      "num_input_tokens_seen": 5120632,
      "step": 2565,
      "train_runtime": 11221.5652,
      "train_tokens_per_second": 456.321
    },
    {
      "epoch": 1.612392156862745,
      "grad_norm": 0.9122444987297058,
      "learning_rate": 2.208317719956925e-05,
      "loss": 2.1062,
      "num_input_tokens_seen": 5131040,
      "step": 2570,
      "train_runtime": 11229.6188,
      "train_tokens_per_second": 456.92
    },
    {
      "epoch": 1.6155294117647059,
      "grad_norm": 0.8606505393981934,
      "learning_rate": 2.200163367180823e-05,
      "loss": 2.1859,
      "num_input_tokens_seen": 5140960,
      "step": 2575,
      "train_runtime": 11237.2996,
      "train_tokens_per_second": 457.491
    },
    {
      "epoch": 1.6186666666666667,
      "grad_norm": 0.851082980632782,
      "learning_rate": 2.1920122496328643e-05,
      "loss": 2.0632,
      "num_input_tokens_seen": 5151056,
      "step": 2580,
      "train_runtime": 11244.9787,
      "train_tokens_per_second": 458.076
    },
    {
      "epoch": 1.6218039215686275,
      "grad_norm": 0.838333785533905,
      "learning_rate": 2.1838644552633627e-05,
      "loss": 2.1272,
      "num_input_tokens_seen": 5161240,
      "step": 2585,
      "train_runtime": 11252.7301,
      "train_tokens_per_second": 458.666
    },
    {
      "epoch": 1.6249411764705881,
      "grad_norm": 0.8446274995803833,
      "learning_rate": 2.175720071986769e-05,
      "loss": 2.1139,
      "num_input_tokens_seen": 5170816,
      "step": 2590,
      "train_runtime": 11260.1447,
      "train_tokens_per_second": 459.214
    },
    {
      "epoch": 1.6280784313725492,
      "grad_norm": 0.910968542098999,
      "learning_rate": 2.1675791876807313e-05,
      "loss": 2.0947,
      "num_input_tokens_seen": 5180320,
      "step": 2595,
      "train_runtime": 11267.5144,
      "train_tokens_per_second": 459.757
    },
    {
      "epoch": 1.6312156862745097,
      "grad_norm": 0.8648654222488403,
      "learning_rate": 2.1594418901851443e-05,
      "loss": 2.1027,
      "num_input_tokens_seen": 5190680,
      "step": 2600,
      "train_runtime": 11275.372,
      "train_tokens_per_second": 460.356
    },
    {
      "epoch": 1.6312156862745097,
      "eval_loss": 2.3360462188720703,
      "eval_runtime": 78.9776,
      "eval_samples_per_second": 17.942,
      "eval_steps_per_second": 4.495,
      "num_input_tokens_seen": 5190680,
      "step": 2600
    },
    {
      "epoch": 1.6343529411764706,
      "grad_norm": 0.9204450249671936,
      "learning_rate": 2.1513082673011997e-05,
      "loss": 2.2295,
      "num_input_tokens_seen": 5201288,
      "step": 2605,
      "train_runtime": 11362.7055,
      "train_tokens_per_second": 457.751
    },
    {
      "epoch": 1.6374901960784314,
      "grad_norm": 0.9060807824134827,
      "learning_rate": 2.1431784067904415e-05,
      "loss": 2.1307,
      "num_input_tokens_seen": 5210560,
      "step": 2610,
      "train_runtime": 11369.813,
      "train_tokens_per_second": 458.28
    },
    {
      "epoch": 1.6406274509803922,
      "grad_norm": 0.880782961845398,
      "learning_rate": 2.135052396373817e-05,
      "loss": 2.1246,
      "num_input_tokens_seen": 5220376,
      "step": 2615,
      "train_runtime": 11377.6617,
      "train_tokens_per_second": 458.827
    },
    {
      "epoch": 1.643764705882353,
      "grad_norm": 0.94362473487854,
      "learning_rate": 2.126930323730731e-05,
      "loss": 2.2183,
      "num_input_tokens_seen": 5230056,
      "step": 2620,
      "train_runtime": 11384.8988,
      "train_tokens_per_second": 459.385
    },
    {
      "epoch": 1.6469019607843136,
      "grad_norm": 0.8782905340194702,
      "learning_rate": 2.118812276498101e-05,
      "loss": 2.1171,
      "num_input_tokens_seen": 5239592,
      "step": 2625,
      "train_runtime": 11392.3132,
      "train_tokens_per_second": 459.923
    },
    {
      "epoch": 1.6500392156862747,
      "grad_norm": 0.8499267101287842,
      "learning_rate": 2.1106983422694096e-05,
      "loss": 2.2001,
      "num_input_tokens_seen": 5248912,
      "step": 2630,
      "train_runtime": 11399.7483,
      "train_tokens_per_second": 460.441
    },
    {
      "epoch": 1.6531764705882352,
      "grad_norm": 0.8504784107208252,
      "learning_rate": 2.102588608593758e-05,
      "loss": 2.2294,
      "num_input_tokens_seen": 5259008,
      "step": 2635,
      "train_runtime": 11407.3964,
      "train_tokens_per_second": 461.017
    },
    {
      "epoch": 1.656313725490196,
      "grad_norm": 0.8689867258071899,
      "learning_rate": 2.0944831629749296e-05,
      "loss": 2.1254,
      "num_input_tokens_seen": 5269264,
      "step": 2640,
      "train_runtime": 11414.9859,
      "train_tokens_per_second": 461.609
    },
    {
      "epoch": 1.6594509803921569,
      "grad_norm": 0.8730990290641785,
      "learning_rate": 2.0863820928704335e-05,
      "loss": 2.2246,
      "num_input_tokens_seen": 5279704,
      "step": 2645,
      "train_runtime": 11422.8408,
      "train_tokens_per_second": 462.206
    },
    {
      "epoch": 1.6625882352941177,
      "grad_norm": 0.9925044775009155,
      "learning_rate": 2.0782854856905694e-05,
      "loss": 2.198,
      "num_input_tokens_seen": 5289480,
      "step": 2650,
      "train_runtime": 11430.2091,
      "train_tokens_per_second": 462.763
    },
    {
      "epoch": 1.6657254901960785,
      "grad_norm": 0.9037479758262634,
      "learning_rate": 2.0701934287974833e-05,
      "loss": 2.1722,
      "num_input_tokens_seen": 5299976,
      "step": 2655,
      "train_runtime": 11438.1032,
      "train_tokens_per_second": 463.361
    },
    {
      "epoch": 1.6688627450980391,
      "grad_norm": 0.8398779630661011,
      "learning_rate": 2.0621060095042235e-05,
      "loss": 2.2121,
      "num_input_tokens_seen": 5309504,
      "step": 2660,
      "train_runtime": 11445.2998,
      "train_tokens_per_second": 463.903
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.8987144827842712,
      "learning_rate": 2.054023315073796e-05,
      "loss": 2.2343,
      "num_input_tokens_seen": 5319864,
      "step": 2665,
      "train_runtime": 11453.0105,
      "train_tokens_per_second": 464.495
    },
    {
      "epoch": 1.6751372549019607,
      "grad_norm": 0.871640682220459,
      "learning_rate": 2.0459454327182302e-05,
      "loss": 2.1951,
      "num_input_tokens_seen": 5330640,
      "step": 2670,
      "train_runtime": 11461.4835,
      "train_tokens_per_second": 465.092
    },
    {
      "epoch": 1.6782745098039216,
      "grad_norm": 0.9482843279838562,
      "learning_rate": 2.0378724495976294e-05,
      "loss": 2.1389,
      "num_input_tokens_seen": 5340352,
      "step": 2675,
      "train_runtime": 11468.8795,
      "train_tokens_per_second": 465.639
    },
    {
      "epoch": 1.6814117647058824,
      "grad_norm": 1.0305505990982056,
      "learning_rate": 2.0298044528192363e-05,
      "loss": 2.1758,
      "num_input_tokens_seen": 5350240,
      "step": 2680,
      "train_runtime": 11476.4048,
      "train_tokens_per_second": 466.195
    },
    {
      "epoch": 1.684549019607843,
      "grad_norm": 0.9092760682106018,
      "learning_rate": 2.0217415294364903e-05,
      "loss": 2.2034,
      "num_input_tokens_seen": 5359560,
      "step": 2685,
      "train_runtime": 11483.5621,
      "train_tokens_per_second": 466.716
    },
    {
      "epoch": 1.687686274509804,
      "grad_norm": 0.8272384405136108,
      "learning_rate": 2.0136837664480902e-05,
      "loss": 2.2467,
      "num_input_tokens_seen": 5369880,
      "step": 2690,
      "train_runtime": 11491.3442,
      "train_tokens_per_second": 467.298
    },
    {
      "epoch": 1.6908235294117646,
      "grad_norm": 0.9425166249275208,
      "learning_rate": 2.005631250797052e-05,
      "loss": 2.1905,
      "num_input_tokens_seen": 5380144,
      "step": 2695,
      "train_runtime": 11498.9907,
      "train_tokens_per_second": 467.88
    },
    {
      "epoch": 1.6939607843137257,
      "grad_norm": 0.9587878584861755,
      "learning_rate": 1.9975840693697763e-05,
      "loss": 2.1235,
      "num_input_tokens_seen": 5389656,
      "step": 2700,
      "train_runtime": 11506.5247,
      "train_tokens_per_second": 468.4
    },
    {
      "epoch": 1.6939607843137257,
      "eval_loss": 2.329637050628662,
      "eval_runtime": 78.973,
      "eval_samples_per_second": 17.943,
      "eval_steps_per_second": 4.495,
      "num_input_tokens_seen": 5389656,
      "step": 2700
    },
    {
      "epoch": 1.6970980392156862,
      "grad_norm": 0.886067807674408,
      "learning_rate": 1.9895423089951056e-05,
      "loss": 2.2485,
      "num_input_tokens_seen": 5399568,
      "step": 2705,
      "train_runtime": 11593.3717,
      "train_tokens_per_second": 465.746
    },
    {
      "epoch": 1.700235294117647,
      "grad_norm": 0.951359212398529,
      "learning_rate": 1.9815060564433872e-05,
      "loss": 2.261,
      "num_input_tokens_seen": 5409768,
      "step": 2710,
      "train_runtime": 11601.128,
      "train_tokens_per_second": 466.314
    },
    {
      "epoch": 1.7033725490196079,
      "grad_norm": 0.9009987115859985,
      "learning_rate": 1.973475398425545e-05,
      "loss": 2.1775,
      "num_input_tokens_seen": 5419416,
      "step": 2715,
      "train_runtime": 11608.613,
      "train_tokens_per_second": 466.844
    },
    {
      "epoch": 1.7065098039215685,
      "grad_norm": 0.9010618329048157,
      "learning_rate": 1.965450421592133e-05,
      "loss": 2.0562,
      "num_input_tokens_seen": 5428816,
      "step": 2720,
      "train_runtime": 11615.8056,
      "train_tokens_per_second": 467.365
    },
    {
      "epoch": 1.7096470588235295,
      "grad_norm": 0.8368756175041199,
      "learning_rate": 1.9574312125324064e-05,
      "loss": 2.2145,
      "num_input_tokens_seen": 5439168,
      "step": 2725,
      "train_runtime": 11623.6615,
      "train_tokens_per_second": 467.939
    },
    {
      "epoch": 1.7127843137254901,
      "grad_norm": 0.868548572063446,
      "learning_rate": 1.9494178577733886e-05,
      "loss": 2.1927,
      "num_input_tokens_seen": 5449784,
      "step": 2730,
      "train_runtime": 11631.8059,
      "train_tokens_per_second": 468.524
    },
    {
      "epoch": 1.715921568627451,
      "grad_norm": 0.9727489948272705,
      "learning_rate": 1.9414104437789326e-05,
      "loss": 2.1454,
      "num_input_tokens_seen": 5459728,
      "step": 2735,
      "train_runtime": 11639.5822,
      "train_tokens_per_second": 469.066
    },
    {
      "epoch": 1.7190588235294118,
      "grad_norm": 0.9254045486450195,
      "learning_rate": 1.9334090569487916e-05,
      "loss": 2.1542,
      "num_input_tokens_seen": 5469480,
      "step": 2740,
      "train_runtime": 11647.205,
      "train_tokens_per_second": 469.596
    },
    {
      "epoch": 1.7221960784313726,
      "grad_norm": 0.8579983711242676,
      "learning_rate": 1.9254137836176865e-05,
      "loss": 2.0994,
      "num_input_tokens_seen": 5478936,
      "step": 2745,
      "train_runtime": 11654.4757,
      "train_tokens_per_second": 470.114
    },
    {
      "epoch": 1.7253333333333334,
      "grad_norm": 0.9428701996803284,
      "learning_rate": 1.9174247100543745e-05,
      "loss": 2.1802,
      "num_input_tokens_seen": 5489232,
      "step": 2750,
      "train_runtime": 11662.3292,
      "train_tokens_per_second": 470.681
    },
    {
      "epoch": 1.728470588235294,
      "grad_norm": 0.842880129814148,
      "learning_rate": 1.9094419224607134e-05,
      "loss": 2.149,
      "num_input_tokens_seen": 5499376,
      "step": 2755,
      "train_runtime": 11670.0074,
      "train_tokens_per_second": 471.24
    },
    {
      "epoch": 1.731607843137255,
      "grad_norm": 0.9495248794555664,
      "learning_rate": 1.9014655069707403e-05,
      "loss": 2.0967,
      "num_input_tokens_seen": 5509264,
      "step": 2760,
      "train_runtime": 11677.9531,
      "train_tokens_per_second": 471.766
    },
    {
      "epoch": 1.7347450980392156,
      "grad_norm": 0.8686875700950623,
      "learning_rate": 1.8934955496497352e-05,
      "loss": 2.2268,
      "num_input_tokens_seen": 5519832,
      "step": 2765,
      "train_runtime": 11685.9841,
      "train_tokens_per_second": 472.346
    },
    {
      "epoch": 1.7378823529411764,
      "grad_norm": 0.8998350501060486,
      "learning_rate": 1.885532136493295e-05,
      "loss": 2.1281,
      "num_input_tokens_seen": 5529360,
      "step": 2770,
      "train_runtime": 11693.3712,
      "train_tokens_per_second": 472.863
    },
    {
      "epoch": 1.7410196078431373,
      "grad_norm": 0.8705402612686157,
      "learning_rate": 1.8775753534264062e-05,
      "loss": 2.0697,
      "num_input_tokens_seen": 5538856,
      "step": 2775,
      "train_runtime": 11700.6474,
      "train_tokens_per_second": 473.38
    },
    {
      "epoch": 1.744156862745098,
      "grad_norm": 0.9790387153625488,
      "learning_rate": 1.869625286302516e-05,
      "loss": 2.2461,
      "num_input_tokens_seen": 5548640,
      "step": 2780,
      "train_runtime": 11708.295,
      "train_tokens_per_second": 473.907
    },
    {
      "epoch": 1.7472941176470589,
      "grad_norm": 0.9640617370605469,
      "learning_rate": 1.8616820209026043e-05,
      "loss": 2.1586,
      "num_input_tokens_seen": 5558968,
      "step": 2785,
      "train_runtime": 11716.1333,
      "train_tokens_per_second": 474.471
    },
    {
      "epoch": 1.7504313725490195,
      "grad_norm": 0.9271041750907898,
      "learning_rate": 1.853745642934266e-05,
      "loss": 2.2306,
      "num_input_tokens_seen": 5569424,
      "step": 2790,
      "train_runtime": 11724.1229,
      "train_tokens_per_second": 475.04
    },
    {
      "epoch": 1.7535686274509805,
      "grad_norm": 1.0102901458740234,
      "learning_rate": 1.845816238030777e-05,
      "loss": 2.1697,
      "num_input_tokens_seen": 5578752,
      "step": 2795,
      "train_runtime": 11731.4477,
      "train_tokens_per_second": 475.538
    },
    {
      "epoch": 1.7567058823529411,
      "grad_norm": 0.9253309369087219,
      "learning_rate": 1.8378938917501737e-05,
      "loss": 2.2793,
      "num_input_tokens_seen": 5589208,
      "step": 2800,
      "train_runtime": 11739.6212,
      "train_tokens_per_second": 476.098
    },
    {
      "epoch": 1.7567058823529411,
      "eval_loss": 2.32595157623291,
      "eval_runtime": 78.944,
      "eval_samples_per_second": 17.949,
      "eval_steps_per_second": 4.497,
      "num_input_tokens_seen": 5589208,
      "step": 2800
    },
    {
      "epoch": 1.759843137254902,
      "grad_norm": 0.9360722303390503,
      "learning_rate": 1.829978689574333e-05,
      "loss": 2.0972,
      "num_input_tokens_seen": 5598672,
      "step": 2805,
      "train_runtime": 11826.221,
      "train_tokens_per_second": 473.412
    },
    {
      "epoch": 1.7629803921568628,
      "grad_norm": 0.9157439470291138,
      "learning_rate": 1.8220707169080454e-05,
      "loss": 2.2298,
      "num_input_tokens_seen": 5609240,
      "step": 2810,
      "train_runtime": 11833.9384,
      "train_tokens_per_second": 473.996
    },
    {
      "epoch": 1.7661176470588236,
      "grad_norm": 0.9020656943321228,
      "learning_rate": 1.814170059078094e-05,
      "loss": 2.1455,
      "num_input_tokens_seen": 5619200,
      "step": 2815,
      "train_runtime": 11841.5361,
      "train_tokens_per_second": 474.533
    },
    {
      "epoch": 1.7692549019607844,
      "grad_norm": 0.9632139801979065,
      "learning_rate": 1.806276801332338e-05,
      "loss": 2.2008,
      "num_input_tokens_seen": 5629408,
      "step": 2820,
      "train_runtime": 11849.1736,
      "train_tokens_per_second": 475.089
    },
    {
      "epoch": 1.772392156862745,
      "grad_norm": 1.0564993619918823,
      "learning_rate": 1.798391028838787e-05,
      "loss": 2.1308,
      "num_input_tokens_seen": 5638752,
      "step": 2825,
      "train_runtime": 11856.3821,
      "train_tokens_per_second": 475.588
    },
    {
      "epoch": 1.775529411764706,
      "grad_norm": 1.0077996253967285,
      "learning_rate": 1.7905128266846877e-05,
      "loss": 2.139,
      "num_input_tokens_seen": 5648712,
      "step": 2830,
      "train_runtime": 11864.0919,
      "train_tokens_per_second": 476.118
    },
    {
      "epoch": 1.7786666666666666,
      "grad_norm": 1.0958051681518555,
      "learning_rate": 1.782642279875601e-05,
      "loss": 2.0946,
      "num_input_tokens_seen": 5657712,
      "step": 2835,
      "train_runtime": 11871.1187,
      "train_tokens_per_second": 476.595
    },
    {
      "epoch": 1.7818039215686274,
      "grad_norm": 0.8764427304267883,
      "learning_rate": 1.774779473334486e-05,
      "loss": 2.1285,
      "num_input_tokens_seen": 5667952,
      "step": 2840,
      "train_runtime": 11878.8723,
      "train_tokens_per_second": 477.146
    },
    {
      "epoch": 1.7849411764705883,
      "grad_norm": 0.8447704911231995,
      "learning_rate": 1.766924491900789e-05,
      "loss": 2.2941,
      "num_input_tokens_seen": 5678464,
      "step": 2845,
      "train_runtime": 11886.7484,
      "train_tokens_per_second": 477.714
    },
    {
      "epoch": 1.788078431372549,
      "grad_norm": 1.006645679473877,
      "learning_rate": 1.7590774203295178e-05,
      "loss": 2.1551,
      "num_input_tokens_seen": 5688216,
      "step": 2850,
      "train_runtime": 11894.6705,
      "train_tokens_per_second": 478.216
    },
    {
      "epoch": 1.7912156862745099,
      "grad_norm": 0.9186574816703796,
      "learning_rate": 1.7512383432903373e-05,
      "loss": 2.1117,
      "num_input_tokens_seen": 5698064,
      "step": 2855,
      "train_runtime": 11902.2648,
      "train_tokens_per_second": 478.738
    },
    {
      "epoch": 1.7943529411764705,
      "grad_norm": 0.8462941646575928,
      "learning_rate": 1.7434073453666505e-05,
      "loss": 2.2773,
      "num_input_tokens_seen": 5707792,
      "step": 2860,
      "train_runtime": 11909.8975,
      "train_tokens_per_second": 479.248
    },
    {
      "epoch": 1.7974901960784315,
      "grad_norm": 0.8854940533638,
      "learning_rate": 1.735584511054686e-05,
      "loss": 2.0669,
      "num_input_tokens_seen": 5717560,
      "step": 2865,
      "train_runtime": 11917.4168,
      "train_tokens_per_second": 479.765
    },
    {
      "epoch": 1.8006274509803921,
      "grad_norm": 0.9439228177070618,
      "learning_rate": 1.7277699247625877e-05,
      "loss": 2.1634,
      "num_input_tokens_seen": 5727800,
      "step": 2870,
      "train_runtime": 11924.9286,
      "train_tokens_per_second": 480.322
    },
    {
      "epoch": 1.803764705882353,
      "grad_norm": 0.8465468883514404,
      "learning_rate": 1.7199636708095057e-05,
      "loss": 2.1445,
      "num_input_tokens_seen": 5738264,
      "step": 2875,
      "train_runtime": 11932.9505,
      "train_tokens_per_second": 480.876
    },
    {
      "epoch": 1.8069019607843138,
      "grad_norm": 0.9213857650756836,
      "learning_rate": 1.7121658334246808e-05,
      "loss": 2.0902,
      "num_input_tokens_seen": 5748000,
      "step": 2880,
      "train_runtime": 11940.2897,
      "train_tokens_per_second": 481.395
    },
    {
      "epoch": 1.8100392156862743,
      "grad_norm": 0.9472652077674866,
      "learning_rate": 1.7043764967465416e-05,
      "loss": 2.1328,
      "num_input_tokens_seen": 5758184,
      "step": 2885,
      "train_runtime": 11948.2131,
      "train_tokens_per_second": 481.928
    },
    {
      "epoch": 1.8131764705882354,
      "grad_norm": 0.8763210773468018,
      "learning_rate": 1.696595744821794e-05,
      "loss": 2.1129,
      "num_input_tokens_seen": 5768016,
      "step": 2890,
      "train_runtime": 11955.6352,
      "train_tokens_per_second": 482.452
    },
    {
      "epoch": 1.816313725490196,
      "grad_norm": 0.8956505060195923,
      "learning_rate": 1.688823661604515e-05,
      "loss": 2.1166,
      "num_input_tokens_seen": 5778112,
      "step": 2895,
      "train_runtime": 11963.5446,
      "train_tokens_per_second": 482.977
    },
    {
      "epoch": 1.819450980392157,
      "grad_norm": 0.9296989440917969,
      "learning_rate": 1.681060330955245e-05,
      "loss": 2.1768,
      "num_input_tokens_seen": 5788408,
      "step": 2900,
      "train_runtime": 11971.2108,
      "train_tokens_per_second": 483.527
    },
    {
      "epoch": 1.819450980392157,
      "eval_loss": 2.322798252105713,
      "eval_runtime": 78.9267,
      "eval_samples_per_second": 17.953,
      "eval_steps_per_second": 4.498,
      "num_input_tokens_seen": 5788408,
      "step": 2900
    },
    {
      "epoch": 1.8225882352941176,
      "grad_norm": 0.8188639879226685,
      "learning_rate": 1.6733058366400858e-05,
      "loss": 2.1253,
      "num_input_tokens_seen": 5798776,
      "step": 2905,
      "train_runtime": 12058.4902,
      "train_tokens_per_second": 480.887
    },
    {
      "epoch": 1.8257254901960784,
      "grad_norm": 0.9455382227897644,
      "learning_rate": 1.6655602623297962e-05,
      "loss": 2.1747,
      "num_input_tokens_seen": 5809016,
      "step": 2910,
      "train_runtime": 12066.4406,
      "train_tokens_per_second": 481.419
    },
    {
      "epoch": 1.8288627450980393,
      "grad_norm": 1.029945969581604,
      "learning_rate": 1.657823691598885e-05,
      "loss": 2.2164,
      "num_input_tokens_seen": 5819360,
      "step": 2915,
      "train_runtime": 12074.2315,
      "train_tokens_per_second": 481.965
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.9219268560409546,
      "learning_rate": 1.6500962079247182e-05,
      "loss": 2.1698,
      "num_input_tokens_seen": 5829752,
      "step": 2920,
      "train_runtime": 12082.2484,
      "train_tokens_per_second": 482.506
    },
    {
      "epoch": 1.835137254901961,
      "grad_norm": 0.8231993913650513,
      "learning_rate": 1.642377894686607e-05,
      "loss": 2.1629,
      "num_input_tokens_seen": 5840144,
      "step": 2925,
      "train_runtime": 12090.1058,
      "train_tokens_per_second": 483.052
    },
    {
      "epoch": 1.8382745098039215,
      "grad_norm": 0.8490417003631592,
      "learning_rate": 1.6346688351649168e-05,
      "loss": 2.1806,
      "num_input_tokens_seen": 5850640,
      "step": 2930,
      "train_runtime": 12098.4084,
      "train_tokens_per_second": 483.588
    },
    {
      "epoch": 1.8414117647058823,
      "grad_norm": 0.9233232140541077,
      "learning_rate": 1.626969112540166e-05,
      "loss": 2.1556,
      "num_input_tokens_seen": 5860400,
      "step": 2935,
      "train_runtime": 12106.048,
      "train_tokens_per_second": 484.089
    },
    {
      "epoch": 1.8445490196078431,
      "grad_norm": 1.036001205444336,
      "learning_rate": 1.619278809892127e-05,
      "loss": 2.2003,
      "num_input_tokens_seen": 5870592,
      "step": 2940,
      "train_runtime": 12113.9961,
      "train_tokens_per_second": 484.612
    },
    {
      "epoch": 1.847686274509804,
      "grad_norm": 0.925438642501831,
      "learning_rate": 1.6115980101989314e-05,
      "loss": 2.0515,
      "num_input_tokens_seen": 5880424,
      "step": 2945,
      "train_runtime": 12121.5475,
      "train_tokens_per_second": 485.122
    },
    {
      "epoch": 1.8508235294117648,
      "grad_norm": 0.9233812689781189,
      "learning_rate": 1.6039267963361742e-05,
      "loss": 2.1382,
      "num_input_tokens_seen": 5890368,
      "step": 2950,
      "train_runtime": 12129.3611,
      "train_tokens_per_second": 485.629
    },
    {
      "epoch": 1.8539607843137254,
      "grad_norm": 0.9259898066520691,
      "learning_rate": 1.5962652510760207e-05,
      "loss": 2.2511,
      "num_input_tokens_seen": 5900736,
      "step": 2955,
      "train_runtime": 12137.2114,
      "train_tokens_per_second": 486.169
    },
    {
      "epoch": 1.8570980392156864,
      "grad_norm": 0.9363442063331604,
      "learning_rate": 1.5886134570863086e-05,
      "loss": 2.1757,
      "num_input_tokens_seen": 5910624,
      "step": 2960,
      "train_runtime": 12144.7675,
      "train_tokens_per_second": 486.681
    },
    {
      "epoch": 1.860235294117647,
      "grad_norm": 0.8754936456680298,
      "learning_rate": 1.5809714969296644e-05,
      "loss": 2.1346,
      "num_input_tokens_seen": 5920320,
      "step": 2965,
      "train_runtime": 12152.3447,
      "train_tokens_per_second": 487.175
    },
    {
      "epoch": 1.8633725490196078,
      "grad_norm": 0.8021448850631714,
      "learning_rate": 1.5733394530626047e-05,
      "loss": 2.1366,
      "num_input_tokens_seen": 5930848,
      "step": 2970,
      "train_runtime": 12160.0958,
      "train_tokens_per_second": 487.73
    },
    {
      "epoch": 1.8665098039215686,
      "grad_norm": 0.8596580028533936,
      "learning_rate": 1.5657174078346504e-05,
      "loss": 2.1731,
      "num_input_tokens_seen": 5940816,
      "step": 2975,
      "train_runtime": 12167.6458,
      "train_tokens_per_second": 488.247
    },
    {
      "epoch": 1.8696470588235294,
      "grad_norm": 0.9375355243682861,
      "learning_rate": 1.5581054434874386e-05,
      "loss": 2.1353,
      "num_input_tokens_seen": 5950536,
      "step": 2980,
      "train_runtime": 12175.0822,
      "train_tokens_per_second": 488.747
    },
    {
      "epoch": 1.8727843137254903,
      "grad_norm": 0.8688495755195618,
      "learning_rate": 1.5505036421538333e-05,
      "loss": 2.0029,
      "num_input_tokens_seen": 5960760,
      "step": 2985,
      "train_runtime": 12182.8617,
      "train_tokens_per_second": 489.274
    },
    {
      "epoch": 1.8759215686274509,
      "grad_norm": 0.9701483249664307,
      "learning_rate": 1.542912085857037e-05,
      "loss": 2.1595,
      "num_input_tokens_seen": 5970928,
      "step": 2990,
      "train_runtime": 12191.1076,
      "train_tokens_per_second": 489.777
    },
    {
      "epoch": 1.879058823529412,
      "grad_norm": 0.8920947313308716,
      "learning_rate": 1.5353308565097142e-05,
      "loss": 2.1453,
      "num_input_tokens_seen": 5980672,
      "step": 2995,
      "train_runtime": 12198.5309,
      "train_tokens_per_second": 490.278
    },
    {
      "epoch": 1.8821960784313725,
      "grad_norm": 0.953890860080719,
      "learning_rate": 1.527760035913097e-05,
      "loss": 2.1954,
      "num_input_tokens_seen": 5990232,
      "step": 3000,
      "train_runtime": 12206.0106,
      "train_tokens_per_second": 490.761
    },
    {
      "epoch": 1.8821960784313725,
      "eval_loss": 2.317979097366333,
      "eval_runtime": 79.0582,
      "eval_samples_per_second": 17.923,
      "eval_steps_per_second": 4.49,
      "num_input_tokens_seen": 5990232,
      "step": 3000
    },
    {
      "epoch": 1.8853333333333333,
      "grad_norm": 0.8416032195091248,
      "learning_rate": 1.5201997057561096e-05,
      "loss": 2.1763,
      "num_input_tokens_seen": 5999904,
      "step": 3005,
      "train_runtime": 12292.8004,
      "train_tokens_per_second": 488.083
    },
    {
      "epoch": 1.8884705882352941,
      "grad_norm": 1.065488338470459,
      "learning_rate": 1.512649947614485e-05,
      "loss": 2.1241,
      "num_input_tokens_seen": 6009224,
      "step": 3010,
      "train_runtime": 12300.1303,
      "train_tokens_per_second": 488.55
    },
    {
      "epoch": 1.891607843137255,
      "grad_norm": 0.8617655634880066,
      "learning_rate": 1.5051108429498834e-05,
      "loss": 2.2239,
      "num_input_tokens_seen": 6018960,
      "step": 3015,
      "train_runtime": 12307.8718,
      "train_tokens_per_second": 489.033
    },
    {
      "epoch": 1.8947450980392158,
      "grad_norm": 0.8782935738563538,
      "learning_rate": 1.4975824731090143e-05,
      "loss": 2.1844,
      "num_input_tokens_seen": 6029600,
      "step": 3020,
      "train_runtime": 12315.9163,
      "train_tokens_per_second": 489.578
    },
    {
      "epoch": 1.8978823529411764,
      "grad_norm": 0.9012007117271423,
      "learning_rate": 1.49006491932276e-05,
      "loss": 2.0725,
      "num_input_tokens_seen": 6038960,
      "step": 3025,
      "train_runtime": 12323.1287,
      "train_tokens_per_second": 490.051
    },
    {
      "epoch": 1.9010196078431374,
      "grad_norm": 0.8288286924362183,
      "learning_rate": 1.4825582627052975e-05,
      "loss": 2.155,
      "num_input_tokens_seen": 6049392,
      "step": 3030,
      "train_runtime": 12330.9285,
      "train_tokens_per_second": 490.587
    },
    {
      "epoch": 1.904156862745098,
      "grad_norm": 0.9097158908843994,
      "learning_rate": 1.4750625842532211e-05,
      "loss": 2.1114,
      "num_input_tokens_seen": 6058832,
      "step": 3035,
      "train_runtime": 12338.4185,
      "train_tokens_per_second": 491.054
    },
    {
      "epoch": 1.9072941176470588,
      "grad_norm": 0.8902126550674438,
      "learning_rate": 1.4675779648446764e-05,
      "loss": 2.161,
      "num_input_tokens_seen": 6068448,
      "step": 3040,
      "train_runtime": 12345.7626,
      "train_tokens_per_second": 491.541
    },
    {
      "epoch": 1.9104313725490196,
      "grad_norm": 0.8606270551681519,
      "learning_rate": 1.4601044852384754e-05,
      "loss": 2.1987,
      "num_input_tokens_seen": 6078576,
      "step": 3045,
      "train_runtime": 12353.4103,
      "train_tokens_per_second": 492.057
    },
    {
      "epoch": 1.9135686274509804,
      "grad_norm": 0.9184975624084473,
      "learning_rate": 1.4526422260732395e-05,
      "loss": 2.1064,
      "num_input_tokens_seen": 6088168,
      "step": 3050,
      "train_runtime": 12360.8392,
      "train_tokens_per_second": 492.537
    },
    {
      "epoch": 1.9167058823529413,
      "grad_norm": 0.9246497750282288,
      "learning_rate": 1.4451912678665162e-05,
      "loss": 2.1736,
      "num_input_tokens_seen": 6097936,
      "step": 3055,
      "train_runtime": 12368.2532,
      "train_tokens_per_second": 493.031
    },
    {
      "epoch": 1.9198431372549019,
      "grad_norm": 0.933928370475769,
      "learning_rate": 1.4377516910139158e-05,
      "loss": 2.0535,
      "num_input_tokens_seen": 6107760,
      "step": 3060,
      "train_runtime": 12375.682,
      "train_tokens_per_second": 493.529
    },
    {
      "epoch": 1.922980392156863,
      "grad_norm": 0.9408664107322693,
      "learning_rate": 1.4303235757882499e-05,
      "loss": 2.0873,
      "num_input_tokens_seen": 6117592,
      "step": 3065,
      "train_runtime": 12383.3228,
      "train_tokens_per_second": 494.019
    },
    {
      "epoch": 1.9261176470588235,
      "grad_norm": 0.9857436418533325,
      "learning_rate": 1.4229070023386546e-05,
      "loss": 2.1966,
      "num_input_tokens_seen": 6127552,
      "step": 3070,
      "train_runtime": 12390.8838,
      "train_tokens_per_second": 494.521
    },
    {
      "epoch": 1.9292549019607843,
      "grad_norm": 0.8937442302703857,
      "learning_rate": 1.4155020506897298e-05,
      "loss": 2.1628,
      "num_input_tokens_seen": 6137872,
      "step": 3075,
      "train_runtime": 12398.6453,
      "train_tokens_per_second": 495.044
    },
    {
      "epoch": 1.9323921568627451,
      "grad_norm": 0.9128642082214355,
      "learning_rate": 1.40810880074068e-05,
      "loss": 2.0758,
      "num_input_tokens_seen": 6147544,
      "step": 3080,
      "train_runtime": 12406.2068,
      "train_tokens_per_second": 495.522
    },
    {
      "epoch": 1.9355294117647057,
      "grad_norm": 0.8955064415931702,
      "learning_rate": 1.4007273322644485e-05,
      "loss": 2.056,
      "num_input_tokens_seen": 6157160,
      "step": 3085,
      "train_runtime": 12413.4646,
      "train_tokens_per_second": 496.007
    },
    {
      "epoch": 1.9386666666666668,
      "grad_norm": 1.0124841928482056,
      "learning_rate": 1.393357724906853e-05,
      "loss": 2.1623,
      "num_input_tokens_seen": 6167168,
      "step": 3090,
      "train_runtime": 12421.1648,
      "train_tokens_per_second": 496.505
    },
    {
      "epoch": 1.9418039215686274,
      "grad_norm": 0.9727040529251099,
      "learning_rate": 1.3860000581857336e-05,
      "loss": 2.1493,
      "num_input_tokens_seen": 6177224,
      "step": 3095,
      "train_runtime": 12429.0456,
      "train_tokens_per_second": 496.999
    },
    {
      "epoch": 1.9449411764705884,
      "grad_norm": 0.9508171081542969,
      "learning_rate": 1.3786544114900918e-05,
      "loss": 2.1791,
      "num_input_tokens_seen": 6186856,
      "step": 3100,
      "train_runtime": 12436.3147,
      "train_tokens_per_second": 497.483
    },
    {
      "epoch": 1.9449411764705884,
      "eval_loss": 2.312633514404297,
      "eval_runtime": 79.0917,
      "eval_samples_per_second": 17.916,
      "eval_steps_per_second": 4.488,
      "num_input_tokens_seen": 6186856,
      "step": 3100
    },
    {
      "epoch": 1.948078431372549,
      "grad_norm": 0.9472862482070923,
      "learning_rate": 1.3713208640792296e-05,
      "loss": 2.1975,
      "num_input_tokens_seen": 6196720,
      "step": 3105,
      "train_runtime": 12523.4615,
      "train_tokens_per_second": 494.809
    },
    {
      "epoch": 1.9512156862745098,
      "grad_norm": 1.042567253112793,
      "learning_rate": 1.3639994950819024e-05,
      "loss": 2.1677,
      "num_input_tokens_seen": 6206936,
      "step": 3110,
      "train_runtime": 12531.3893,
      "train_tokens_per_second": 495.311
    },
    {
      "epoch": 1.9543529411764706,
      "grad_norm": 0.961277425289154,
      "learning_rate": 1.3566903834954573e-05,
      "loss": 2.1678,
      "num_input_tokens_seen": 6217312,
      "step": 3115,
      "train_runtime": 12539.3474,
      "train_tokens_per_second": 495.824
    },
    {
      "epoch": 1.9574901960784312,
      "grad_norm": 0.8776216506958008,
      "learning_rate": 1.3493936081849868e-05,
      "loss": 2.1553,
      "num_input_tokens_seen": 6226856,
      "step": 3120,
      "train_runtime": 12546.7449,
      "train_tokens_per_second": 496.293
    },
    {
      "epoch": 1.9606274509803923,
      "grad_norm": 0.9196212291717529,
      "learning_rate": 1.3421092478824748e-05,
      "loss": 2.0542,
      "num_input_tokens_seen": 6236256,
      "step": 3125,
      "train_runtime": 12554.2107,
      "train_tokens_per_second": 496.746
    },
    {
      "epoch": 1.9637647058823529,
      "grad_norm": 0.9000542163848877,
      "learning_rate": 1.334837381185947e-05,
      "loss": 2.1767,
      "num_input_tokens_seen": 6247104,
      "step": 3130,
      "train_runtime": 12562.4967,
      "train_tokens_per_second": 497.282
    },
    {
      "epoch": 1.9669019607843137,
      "grad_norm": 0.9576144814491272,
      "learning_rate": 1.3275780865586221e-05,
      "loss": 2.1152,
      "num_input_tokens_seen": 6256816,
      "step": 3135,
      "train_runtime": 12569.9645,
      "train_tokens_per_second": 497.759
    },
    {
      "epoch": 1.9700392156862745,
      "grad_norm": 0.8914889097213745,
      "learning_rate": 1.3203314423280717e-05,
      "loss": 2.1482,
      "num_input_tokens_seen": 6266376,
      "step": 3140,
      "train_runtime": 12577.549,
      "train_tokens_per_second": 498.219
    },
    {
      "epoch": 1.9731764705882353,
      "grad_norm": 0.9446030259132385,
      "learning_rate": 1.3130975266853646e-05,
      "loss": 2.1704,
      "num_input_tokens_seen": 6276656,
      "step": 3145,
      "train_runtime": 12585.2682,
      "train_tokens_per_second": 498.73
    },
    {
      "epoch": 1.9763137254901961,
      "grad_norm": 0.9509105682373047,
      "learning_rate": 1.3058764176842291e-05,
      "loss": 2.1196,
      "num_input_tokens_seen": 6286064,
      "step": 3150,
      "train_runtime": 12592.2963,
      "train_tokens_per_second": 499.199
    },
    {
      "epoch": 1.9794509803921567,
      "grad_norm": 0.911766767501831,
      "learning_rate": 1.2986681932402139e-05,
      "loss": 2.1591,
      "num_input_tokens_seen": 6295992,
      "step": 3155,
      "train_runtime": 12600.0033,
      "train_tokens_per_second": 499.682
    },
    {
      "epoch": 1.9825882352941178,
      "grad_norm": 0.9145702123641968,
      "learning_rate": 1.291472931129841e-05,
      "loss": 2.1979,
      "num_input_tokens_seen": 6305824,
      "step": 3160,
      "train_runtime": 12607.5391,
      "train_tokens_per_second": 500.163
    },
    {
      "epoch": 1.9857254901960784,
      "grad_norm": 0.9669908881187439,
      "learning_rate": 1.2842907089897681e-05,
      "loss": 2.2289,
      "num_input_tokens_seen": 6316152,
      "step": 3165,
      "train_runtime": 12615.4749,
      "train_tokens_per_second": 500.667
    },
    {
      "epoch": 1.9888627450980392,
      "grad_norm": 0.99930739402771,
      "learning_rate": 1.277121604315955e-05,
      "loss": 2.2164,
      "num_input_tokens_seen": 6326360,
      "step": 3170,
      "train_runtime": 12623.3074,
      "train_tokens_per_second": 501.165
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.8922613859176636,
      "learning_rate": 1.2699656944628239e-05,
      "loss": 2.0813,
      "num_input_tokens_seen": 6336176,
      "step": 3175,
      "train_runtime": 12630.9068,
      "train_tokens_per_second": 501.641
    },
    {
      "epoch": 1.9951372549019608,
      "grad_norm": 0.9633583426475525,
      "learning_rate": 1.2628230566424218e-05,
      "loss": 2.1193,
      "num_input_tokens_seen": 6346216,
      "step": 3180,
      "train_runtime": 12638.73,
      "train_tokens_per_second": 502.125
    },
    {
      "epoch": 1.9982745098039216,
      "grad_norm": 0.9421302080154419,
      "learning_rate": 1.2556937679235959e-05,
      "loss": 2.195,
      "num_input_tokens_seen": 6356432,
      "step": 3185,
      "train_runtime": 12646.4363,
      "train_tokens_per_second": 502.626
    },
    {
      "epoch": 2.001254901960784,
      "grad_norm": 0.868507981300354,
      "learning_rate": 1.2485779052311522e-05,
      "loss": 2.1189,
      "num_input_tokens_seen": 6365952,
      "step": 3190,
      "train_runtime": 12653.7423,
      "train_tokens_per_second": 503.088
    },
    {
      "epoch": 2.004392156862745,
      "grad_norm": 0.8830588459968567,
      "learning_rate": 1.241475545345034e-05,
      "loss": 1.9023,
      "num_input_tokens_seen": 6375800,
      "step": 3195,
      "train_runtime": 12661.2821,
      "train_tokens_per_second": 503.567
    },
    {
      "epoch": 2.007529411764706,
      "grad_norm": 0.9384870529174805,
      "learning_rate": 1.2343867648994898e-05,
      "loss": 2.0229,
      "num_input_tokens_seen": 6385648,
      "step": 3200,
      "train_runtime": 12668.8002,
      "train_tokens_per_second": 504.045
    },
    {
      "epoch": 2.007529411764706,
      "eval_loss": 2.3206655979156494,
      "eval_runtime": 79.0824,
      "eval_samples_per_second": 17.918,
      "eval_steps_per_second": 4.489,
      "num_input_tokens_seen": 6385648,
      "step": 3200
    },
    {
      "epoch": 2.010666666666667,
      "grad_norm": 0.9707516431808472,
      "learning_rate": 1.2273116403822419e-05,
      "loss": 1.927,
      "num_input_tokens_seen": 6394400,
      "step": 3205,
      "train_runtime": 12755.1768,
      "train_tokens_per_second": 501.318
    },
    {
      "epoch": 2.0138039215686274,
      "grad_norm": 0.922635555267334,
      "learning_rate": 1.22025024813367e-05,
      "loss": 1.9713,
      "num_input_tokens_seen": 6404568,
      "step": 3210,
      "train_runtime": 12762.6098,
      "train_tokens_per_second": 501.823
    },
    {
      "epoch": 2.016941176470588,
      "grad_norm": 0.9510405659675598,
      "learning_rate": 1.2132026643459826e-05,
      "loss": 1.8845,
      "num_input_tokens_seen": 6413984,
      "step": 3215,
      "train_runtime": 12769.7782,
      "train_tokens_per_second": 502.278
    },
    {
      "epoch": 2.020078431372549,
      "grad_norm": 0.930938184261322,
      "learning_rate": 1.2061689650623937e-05,
      "loss": 1.9581,
      "num_input_tokens_seen": 6424256,
      "step": 3220,
      "train_runtime": 12777.5891,
      "train_tokens_per_second": 502.775
    },
    {
      "epoch": 2.0232156862745097,
      "grad_norm": 1.0258123874664307,
      "learning_rate": 1.1991492261763029e-05,
      "loss": 1.8208,
      "num_input_tokens_seen": 6433856,
      "step": 3225,
      "train_runtime": 12784.8501,
      "train_tokens_per_second": 503.241
    },
    {
      "epoch": 2.0263529411764707,
      "grad_norm": 0.9255180954933167,
      "learning_rate": 1.1921435234304807e-05,
      "loss": 1.9392,
      "num_input_tokens_seen": 6443776,
      "step": 3230,
      "train_runtime": 12792.4953,
      "train_tokens_per_second": 503.715
    },
    {
      "epoch": 2.0294901960784313,
      "grad_norm": 0.9032781720161438,
      "learning_rate": 1.1851519324162474e-05,
      "loss": 1.9398,
      "num_input_tokens_seen": 6453840,
      "step": 3235,
      "train_runtime": 12800.0149,
      "train_tokens_per_second": 504.206
    },
    {
      "epoch": 2.0326274509803923,
      "grad_norm": 0.8642469644546509,
      "learning_rate": 1.1781745285726554e-05,
      "loss": 1.982,
      "num_input_tokens_seen": 6463624,
      "step": 3240,
      "train_runtime": 12807.6328,
      "train_tokens_per_second": 504.67
    },
    {
      "epoch": 2.035764705882353,
      "grad_norm": 0.9948097467422485,
      "learning_rate": 1.1712113871856806e-05,
      "loss": 1.9762,
      "num_input_tokens_seen": 6472552,
      "step": 3245,
      "train_runtime": 12814.2859,
      "train_tokens_per_second": 505.104
    },
    {
      "epoch": 2.0389019607843135,
      "grad_norm": 1.0495301485061646,
      "learning_rate": 1.1642625833874076e-05,
      "loss": 1.9652,
      "num_input_tokens_seen": 6482312,
      "step": 3250,
      "train_runtime": 12821.6557,
      "train_tokens_per_second": 505.575
    },
    {
      "epoch": 2.0420392156862746,
      "grad_norm": 1.3096449375152588,
      "learning_rate": 1.1573281921552168e-05,
      "loss": 1.9658,
      "num_input_tokens_seen": 6492256,
      "step": 3255,
      "train_runtime": 12829.4125,
      "train_tokens_per_second": 506.045
    },
    {
      "epoch": 2.045176470588235,
      "grad_norm": 0.9780811071395874,
      "learning_rate": 1.1504082883109796e-05,
      "loss": 1.9992,
      "num_input_tokens_seen": 6502752,
      "step": 3260,
      "train_runtime": 12837.5275,
      "train_tokens_per_second": 506.542
    },
    {
      "epoch": 2.048313725490196,
      "grad_norm": 0.8934101462364197,
      "learning_rate": 1.1435029465202457e-05,
      "loss": 1.9137,
      "num_input_tokens_seen": 6512856,
      "step": 3265,
      "train_runtime": 12845.3575,
      "train_tokens_per_second": 507.02
    },
    {
      "epoch": 2.051450980392157,
      "grad_norm": 0.9572241306304932,
      "learning_rate": 1.1366122412914462e-05,
      "loss": 1.9667,
      "num_input_tokens_seen": 6522232,
      "step": 3270,
      "train_runtime": 12852.5864,
      "train_tokens_per_second": 507.465
    },
    {
      "epoch": 2.054588235294118,
      "grad_norm": 0.9933390021324158,
      "learning_rate": 1.1297362469750794e-05,
      "loss": 2.026,
      "num_input_tokens_seen": 6532312,
      "step": 3275,
      "train_runtime": 12860.226,
      "train_tokens_per_second": 507.947
    },
    {
      "epoch": 2.0577254901960784,
      "grad_norm": 1.016929268836975,
      "learning_rate": 1.1228750377629136e-05,
      "loss": 1.9486,
      "num_input_tokens_seen": 6542576,
      "step": 3280,
      "train_runtime": 12868.0854,
      "train_tokens_per_second": 508.434
    },
    {
      "epoch": 2.060862745098039,
      "grad_norm": 0.9347136616706848,
      "learning_rate": 1.116028687687188e-05,
      "loss": 2.0128,
      "num_input_tokens_seen": 6553208,
      "step": 3285,
      "train_runtime": 12876.22,
      "train_tokens_per_second": 508.939
    },
    {
      "epoch": 2.064,
      "grad_norm": 1.0708332061767578,
      "learning_rate": 1.1091972706198134e-05,
      "loss": 1.9551,
      "num_input_tokens_seen": 6562192,
      "step": 3290,
      "train_runtime": 12883.1088,
      "train_tokens_per_second": 509.364
    },
    {
      "epoch": 2.0671372549019607,
      "grad_norm": 0.9767328500747681,
      "learning_rate": 1.1023808602715697e-05,
      "loss": 2.0523,
      "num_input_tokens_seen": 6572248,
      "step": 3295,
      "train_runtime": 12890.6209,
      "train_tokens_per_second": 509.847
    },
    {
      "epoch": 2.0702745098039217,
      "grad_norm": 1.0249778032302856,
      "learning_rate": 1.095579530191318e-05,
      "loss": 1.8715,
      "num_input_tokens_seen": 6582104,
      "step": 3300,
      "train_runtime": 12898.3844,
      "train_tokens_per_second": 510.305
    },
    {
      "epoch": 2.0702745098039217,
      "eval_loss": 2.336243152618408,
      "eval_runtime": 79.0284,
      "eval_samples_per_second": 17.93,
      "eval_steps_per_second": 4.492,
      "num_input_tokens_seen": 6582104,
      "step": 3300
    },
    {
      "epoch": 2.0734117647058823,
      "grad_norm": 0.9110947847366333,
      "learning_rate": 1.0887933537652042e-05,
      "loss": 1.881,
      "num_input_tokens_seen": 6592848,
      "step": 3305,
      "train_runtime": 12985.9621,
      "train_tokens_per_second": 507.69
    },
    {
      "epoch": 2.0765490196078433,
      "grad_norm": 0.9100784659385681,
      "learning_rate": 1.0820224042158633e-05,
      "loss": 2.015,
      "num_input_tokens_seen": 6603104,
      "step": 3310,
      "train_runtime": 12993.8959,
      "train_tokens_per_second": 508.17
    },
    {
      "epoch": 2.079686274509804,
      "grad_norm": 0.9087257385253906,
      "learning_rate": 1.0752667546016368e-05,
      "loss": 2.0358,
      "num_input_tokens_seen": 6613800,
      "step": 3315,
      "train_runtime": 13002.0927,
      "train_tokens_per_second": 508.672
    },
    {
      "epoch": 2.0828235294117645,
      "grad_norm": 0.9628056287765503,
      "learning_rate": 1.068526477815777e-05,
      "loss": 1.9193,
      "num_input_tokens_seen": 6623136,
      "step": 3320,
      "train_runtime": 13009.1839,
      "train_tokens_per_second": 509.112
    },
    {
      "epoch": 2.0859607843137256,
      "grad_norm": 0.9519386887550354,
      "learning_rate": 1.0618016465856657e-05,
      "loss": 1.8997,
      "num_input_tokens_seen": 6632784,
      "step": 3325,
      "train_runtime": 13016.696,
      "train_tokens_per_second": 509.56
    },
    {
      "epoch": 2.089098039215686,
      "grad_norm": 0.9490132331848145,
      "learning_rate": 1.0550923334720284e-05,
      "loss": 2.007,
      "num_input_tokens_seen": 6642352,
      "step": 3330,
      "train_runtime": 13023.9978,
      "train_tokens_per_second": 510.009
    },
    {
      "epoch": 2.092235294117647,
      "grad_norm": 0.9775065779685974,
      "learning_rate": 1.0483986108681476e-05,
      "loss": 2.0245,
      "num_input_tokens_seen": 6652808,
      "step": 3335,
      "train_runtime": 13032.0443,
      "train_tokens_per_second": 510.496
    },
    {
      "epoch": 2.095372549019608,
      "grad_norm": 0.9804427623748779,
      "learning_rate": 1.0417205509990876e-05,
      "loss": 2.0101,
      "num_input_tokens_seen": 6662848,
      "step": 3340,
      "train_runtime": 13039.6426,
      "train_tokens_per_second": 510.969
    },
    {
      "epoch": 2.098509803921569,
      "grad_norm": 1.0015817880630493,
      "learning_rate": 1.035058225920912e-05,
      "loss": 1.9843,
      "num_input_tokens_seen": 6672840,
      "step": 3345,
      "train_runtime": 13047.649,
      "train_tokens_per_second": 511.421
    },
    {
      "epoch": 2.1016470588235294,
      "grad_norm": 1.0687811374664307,
      "learning_rate": 1.0284117075199048e-05,
      "loss": 1.9021,
      "num_input_tokens_seen": 6682576,
      "step": 3350,
      "train_runtime": 13055.368,
      "train_tokens_per_second": 511.864
    },
    {
      "epoch": 2.10478431372549,
      "grad_norm": 1.0540052652359009,
      "learning_rate": 1.0217810675117964e-05,
      "loss": 1.9225,
      "num_input_tokens_seen": 6692120,
      "step": 3355,
      "train_runtime": 13062.8135,
      "train_tokens_per_second": 512.303
    },
    {
      "epoch": 2.107921568627451,
      "grad_norm": 1.030554175376892,
      "learning_rate": 1.0151663774409916e-05,
      "loss": 1.9415,
      "num_input_tokens_seen": 6701560,
      "step": 3360,
      "train_runtime": 13070.3341,
      "train_tokens_per_second": 512.731
    },
    {
      "epoch": 2.1110588235294117,
      "grad_norm": 0.9645469188690186,
      "learning_rate": 1.008567708679796e-05,
      "loss": 1.9892,
      "num_input_tokens_seen": 6711936,
      "step": 3365,
      "train_runtime": 13078.1994,
      "train_tokens_per_second": 513.216
    },
    {
      "epoch": 2.1141960784313727,
      "grad_norm": 0.9859107732772827,
      "learning_rate": 1.0019851324276428e-05,
      "loss": 2.0568,
      "num_input_tokens_seen": 6722696,
      "step": 3370,
      "train_runtime": 13086.4364,
      "train_tokens_per_second": 513.715
    },
    {
      "epoch": 2.1173333333333333,
      "grad_norm": 0.8977940678596497,
      "learning_rate": 9.954187197103305e-06,
      "loss": 1.8858,
      "num_input_tokens_seen": 6732328,
      "step": 3375,
      "train_runtime": 13093.7797,
      "train_tokens_per_second": 514.162
    },
    {
      "epoch": 2.1204705882352943,
      "grad_norm": 1.0158593654632568,
      "learning_rate": 9.888685413792532e-06,
      "loss": 1.9797,
      "num_input_tokens_seen": 6742272,
      "step": 3380,
      "train_runtime": 13101.3704,
      "train_tokens_per_second": 514.623
    },
    {
      "epoch": 2.123607843137255,
      "grad_norm": 0.9541149735450745,
      "learning_rate": 9.82334668110634e-06,
      "loss": 2.0318,
      "num_input_tokens_seen": 6752928,
      "step": 3385,
      "train_runtime": 13109.1409,
      "train_tokens_per_second": 515.131
    },
    {
      "epoch": 2.1267450980392155,
      "grad_norm": 1.0281118154525757,
      "learning_rate": 9.758171704047689e-06,
      "loss": 1.9823,
      "num_input_tokens_seen": 6763440,
      "step": 3390,
      "train_runtime": 13116.8695,
      "train_tokens_per_second": 515.629
    },
    {
      "epoch": 2.1298823529411766,
      "grad_norm": 1.0679363012313843,
      "learning_rate": 9.693161185852575e-06,
      "loss": 1.8607,
      "num_input_tokens_seen": 6773272,
      "step": 3395,
      "train_runtime": 13124.2193,
      "train_tokens_per_second": 516.09
    },
    {
      "epoch": 2.133019607843137,
      "grad_norm": 1.0920649766921997,
      "learning_rate": 9.628315827982526e-06,
      "loss": 1.9619,
      "num_input_tokens_seen": 6783096,
      "step": 3400,
      "train_runtime": 13131.8858,
      "train_tokens_per_second": 516.536
    },
    {
      "epoch": 2.133019607843137,
      "eval_loss": 2.3384511470794678,
      "eval_runtime": 79.0136,
      "eval_samples_per_second": 17.934,
      "eval_steps_per_second": 4.493,
      "num_input_tokens_seen": 6783096,
      "step": 3400
    },
    {
      "epoch": 2.136156862745098,
      "grad_norm": 1.0861481428146362,
      "learning_rate": 9.563636330116983e-06,
      "loss": 1.9466,
      "num_input_tokens_seen": 6792592,
      "step": 3405,
      "train_runtime": 13218.5179,
      "train_tokens_per_second": 513.869
    },
    {
      "epoch": 2.139294117647059,
      "grad_norm": 0.974730908870697,
      "learning_rate": 9.499123390145747e-06,
      "loss": 1.9027,
      "num_input_tokens_seen": 6802000,
      "step": 3410,
      "train_runtime": 13225.7528,
      "train_tokens_per_second": 514.3
    },
    {
      "epoch": 2.1424313725490194,
      "grad_norm": 1.0081896781921387,
      "learning_rate": 9.434777704161485e-06,
      "loss": 1.9344,
      "num_input_tokens_seen": 6812000,
      "step": 3415,
      "train_runtime": 13233.3926,
      "train_tokens_per_second": 514.758
    },
    {
      "epoch": 2.1455686274509804,
      "grad_norm": 1.041668176651001,
      "learning_rate": 9.370599966452196e-06,
      "loss": 2.0261,
      "num_input_tokens_seen": 6821976,
      "step": 3420,
      "train_runtime": 13240.8468,
      "train_tokens_per_second": 515.222
    },
    {
      "epoch": 2.148705882352941,
      "grad_norm": 0.9339218735694885,
      "learning_rate": 9.306590869493714e-06,
      "loss": 1.937,
      "num_input_tokens_seen": 6831936,
      "step": 3425,
      "train_runtime": 13248.804,
      "train_tokens_per_second": 515.664
    },
    {
      "epoch": 2.151843137254902,
      "grad_norm": 0.9570894837379456,
      "learning_rate": 9.242751103942235e-06,
      "loss": 1.9585,
      "num_input_tokens_seen": 6841704,
      "step": 3430,
      "train_runtime": 13256.1986,
      "train_tokens_per_second": 516.114
    },
    {
      "epoch": 2.1549803921568627,
      "grad_norm": 0.957072377204895,
      "learning_rate": 9.179081358626899e-06,
      "loss": 1.8324,
      "num_input_tokens_seen": 6851544,
      "step": 3435,
      "train_runtime": 13263.859,
      "train_tokens_per_second": 516.557
    },
    {
      "epoch": 2.1581176470588237,
      "grad_norm": 0.9503855109214783,
      "learning_rate": 9.115582320542323e-06,
      "loss": 1.9631,
      "num_input_tokens_seen": 6861080,
      "step": 3440,
      "train_runtime": 13271.2839,
      "train_tokens_per_second": 516.987
    },
    {
      "epoch": 2.1612549019607843,
      "grad_norm": 1.0338808298110962,
      "learning_rate": 9.052254674841187e-06,
      "loss": 1.9545,
      "num_input_tokens_seen": 6871616,
      "step": 3445,
      "train_runtime": 13279.4684,
      "train_tokens_per_second": 517.462
    },
    {
      "epoch": 2.1643921568627453,
      "grad_norm": 0.9876133799552917,
      "learning_rate": 8.989099104826865e-06,
      "loss": 2.0026,
      "num_input_tokens_seen": 6881424,
      "step": 3450,
      "train_runtime": 13287.0677,
      "train_tokens_per_second": 517.904
    },
    {
      "epoch": 2.167529411764706,
      "grad_norm": 0.9603973031044006,
      "learning_rate": 8.926116291946044e-06,
      "loss": 1.9234,
      "num_input_tokens_seen": 6891304,
      "step": 3455,
      "train_runtime": 13294.5513,
      "train_tokens_per_second": 518.356
    },
    {
      "epoch": 2.1706666666666665,
      "grad_norm": 0.9627978205680847,
      "learning_rate": 8.863306915781341e-06,
      "loss": 1.943,
      "num_input_tokens_seen": 6901808,
      "step": 3460,
      "train_runtime": 13302.5089,
      "train_tokens_per_second": 518.835
    },
    {
      "epoch": 2.1738039215686276,
      "grad_norm": 0.9646387696266174,
      "learning_rate": 8.800671654044035e-06,
      "loss": 1.9768,
      "num_input_tokens_seen": 6912240,
      "step": 3465,
      "train_runtime": 13310.4068,
      "train_tokens_per_second": 519.311
    },
    {
      "epoch": 2.176941176470588,
      "grad_norm": 1.0205413103103638,
      "learning_rate": 8.738211182566675e-06,
      "loss": 1.9355,
      "num_input_tokens_seen": 6922168,
      "step": 3470,
      "train_runtime": 13318.0934,
      "train_tokens_per_second": 519.757
    },
    {
      "epoch": 2.180078431372549,
      "grad_norm": 1.0744869709014893,
      "learning_rate": 8.675926175295854e-06,
      "loss": 1.8933,
      "num_input_tokens_seen": 6932000,
      "step": 3475,
      "train_runtime": 13325.7847,
      "train_tokens_per_second": 520.195
    },
    {
      "epoch": 2.18321568627451,
      "grad_norm": 0.9627507925033569,
      "learning_rate": 8.613817304284916e-06,
      "loss": 1.9807,
      "num_input_tokens_seen": 6942352,
      "step": 3480,
      "train_runtime": 13333.6405,
      "train_tokens_per_second": 520.664
    },
    {
      "epoch": 2.1863529411764704,
      "grad_norm": 0.9914817214012146,
      "learning_rate": 8.551885239686672e-06,
      "loss": 1.9334,
      "num_input_tokens_seen": 6951672,
      "step": 3485,
      "train_runtime": 13340.9821,
      "train_tokens_per_second": 521.076
    },
    {
      "epoch": 2.1894901960784314,
      "grad_norm": 1.0262198448181152,
      "learning_rate": 8.490130649746222e-06,
      "loss": 1.9956,
      "num_input_tokens_seen": 6962304,
      "step": 3490,
      "train_runtime": 13349.3748,
      "train_tokens_per_second": 521.545
    },
    {
      "epoch": 2.192627450980392,
      "grad_norm": 0.9031357765197754,
      "learning_rate": 8.428554200793722e-06,
      "loss": 2.0463,
      "num_input_tokens_seen": 6972736,
      "step": 3495,
      "train_runtime": 13357.3662,
      "train_tokens_per_second": 522.014
    },
    {
      "epoch": 2.195764705882353,
      "grad_norm": 1.0080958604812622,
      "learning_rate": 8.367156557237168e-06,
      "loss": 1.9003,
      "num_input_tokens_seen": 6982640,
      "step": 3500,
      "train_runtime": 13364.7292,
      "train_tokens_per_second": 522.468
    },
    {
      "epoch": 2.195764705882353,
      "eval_loss": 2.3385143280029297,
      "eval_runtime": 78.9997,
      "eval_samples_per_second": 17.937,
      "eval_steps_per_second": 4.494,
      "num_input_tokens_seen": 6982640,
      "step": 3500
    },
    {
      "epoch": 2.1989019607843137,
      "grad_norm": 0.9727723598480225,
      "learning_rate": 8.30593838155527e-06,
      "loss": 1.9903,
      "num_input_tokens_seen": 6993400,
      "step": 3505,
      "train_runtime": 13452.1508,
      "train_tokens_per_second": 519.872
    },
    {
      "epoch": 2.2020392156862747,
      "grad_norm": 0.9260678887367249,
      "learning_rate": 8.244900334290292e-06,
      "loss": 1.9776,
      "num_input_tokens_seen": 7004120,
      "step": 3510,
      "train_runtime": 13460.0868,
      "train_tokens_per_second": 520.362
    },
    {
      "epoch": 2.2051764705882353,
      "grad_norm": 0.9508397579193115,
      "learning_rate": 8.184043074040889e-06,
      "loss": 2.0064,
      "num_input_tokens_seen": 7013888,
      "step": 3515,
      "train_runtime": 13467.8408,
      "train_tokens_per_second": 520.788
    },
    {
      "epoch": 2.208313725490196,
      "grad_norm": 1.0142667293548584,
      "learning_rate": 8.123367257455067e-06,
      "loss": 2.0073,
      "num_input_tokens_seen": 7023888,
      "step": 3520,
      "train_runtime": 13475.4849,
      "train_tokens_per_second": 521.235
    },
    {
      "epoch": 2.211450980392157,
      "grad_norm": 0.9970652461051941,
      "learning_rate": 8.062873539223017e-06,
      "loss": 1.9568,
      "num_input_tokens_seen": 7033744,
      "step": 3525,
      "train_runtime": 13483.1852,
      "train_tokens_per_second": 521.668
    },
    {
      "epoch": 2.2145882352941175,
      "grad_norm": 0.9432055354118347,
      "learning_rate": 8.002562572070135e-06,
      "loss": 1.8915,
      "num_input_tokens_seen": 7043816,
      "step": 3530,
      "train_runtime": 13490.9031,
      "train_tokens_per_second": 522.116
    },
    {
      "epoch": 2.2177254901960786,
      "grad_norm": 1.0621750354766846,
      "learning_rate": 7.942435006749924e-06,
      "loss": 1.9597,
      "num_input_tokens_seen": 7053696,
      "step": 3535,
      "train_runtime": 13498.4388,
      "train_tokens_per_second": 522.556
    },
    {
      "epoch": 2.220862745098039,
      "grad_norm": 0.9569758772850037,
      "learning_rate": 7.88249149203697e-06,
      "loss": 1.9767,
      "num_input_tokens_seen": 7063736,
      "step": 3540,
      "train_runtime": 13506.2459,
      "train_tokens_per_second": 522.998
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.9866260886192322,
      "learning_rate": 7.822732674719979e-06,
      "loss": 1.9841,
      "num_input_tokens_seen": 7074568,
      "step": 3545,
      "train_runtime": 13514.2412,
      "train_tokens_per_second": 523.49
    },
    {
      "epoch": 2.227137254901961,
      "grad_norm": 0.9893195629119873,
      "learning_rate": 7.763159199594783e-06,
      "loss": 1.996,
      "num_input_tokens_seen": 7085208,
      "step": 3550,
      "train_runtime": 13522.0868,
      "train_tokens_per_second": 523.973
    },
    {
      "epoch": 2.2302745098039214,
      "grad_norm": 0.957098662853241,
      "learning_rate": 7.703771709457356e-06,
      "loss": 1.9734,
      "num_input_tokens_seen": 7094880,
      "step": 3555,
      "train_runtime": 13529.6738,
      "train_tokens_per_second": 524.394
    },
    {
      "epoch": 2.2334117647058824,
      "grad_norm": 1.0542047023773193,
      "learning_rate": 7.644570845096899e-06,
      "loss": 1.9323,
      "num_input_tokens_seen": 7104840,
      "step": 3560,
      "train_runtime": 13537.5135,
      "train_tokens_per_second": 524.826
    },
    {
      "epoch": 2.236549019607843,
      "grad_norm": 1.042404055595398,
      "learning_rate": 7.585557245288949e-06,
      "loss": 1.9568,
      "num_input_tokens_seen": 7114880,
      "step": 3565,
      "train_runtime": 13545.328,
      "train_tokens_per_second": 525.265
    },
    {
      "epoch": 2.239686274509804,
      "grad_norm": 0.9980441331863403,
      "learning_rate": 7.52673154678846e-06,
      "loss": 1.868,
      "num_input_tokens_seen": 7124864,
      "step": 3570,
      "train_runtime": 13553.271,
      "train_tokens_per_second": 525.693
    },
    {
      "epoch": 2.2428235294117647,
      "grad_norm": 0.9922900199890137,
      "learning_rate": 7.468094384322913e-06,
      "loss": 1.8382,
      "num_input_tokens_seen": 7134568,
      "step": 3575,
      "train_runtime": 13560.7896,
      "train_tokens_per_second": 526.117
    },
    {
      "epoch": 2.2459607843137253,
      "grad_norm": 1.003666639328003,
      "learning_rate": 7.409646390585512e-06,
      "loss": 2.0222,
      "num_input_tokens_seen": 7144928,
      "step": 3580,
      "train_runtime": 13568.6292,
      "train_tokens_per_second": 526.577
    },
    {
      "epoch": 2.2490980392156863,
      "grad_norm": 1.070788860321045,
      "learning_rate": 7.351388196228343e-06,
      "loss": 1.9444,
      "num_input_tokens_seen": 7154640,
      "step": 3585,
      "train_runtime": 13576.059,
      "train_tokens_per_second": 527.004
    },
    {
      "epoch": 2.252235294117647,
      "grad_norm": 1.0346739292144775,
      "learning_rate": 7.29332042985553e-06,
      "loss": 1.9797,
      "num_input_tokens_seen": 7165280,
      "step": 3590,
      "train_runtime": 13584.3585,
      "train_tokens_per_second": 527.465
    },
    {
      "epoch": 2.255372549019608,
      "grad_norm": 1.0853843688964844,
      "learning_rate": 7.235443718016524e-06,
      "loss": 1.9209,
      "num_input_tokens_seen": 7174816,
      "step": 3595,
      "train_runtime": 13591.6737,
      "train_tokens_per_second": 527.883
    },
    {
      "epoch": 2.2585098039215685,
      "grad_norm": 1.0914225578308105,
      "learning_rate": 7.1777586851992705e-06,
      "loss": 1.9304,
      "num_input_tokens_seen": 7184768,
      "step": 3600,
      "train_runtime": 13599.4179,
      "train_tokens_per_second": 528.314
    },
    {
      "epoch": 2.2585098039215685,
      "eval_loss": 2.337280511856079,
      "eval_runtime": 79.0088,
      "eval_samples_per_second": 17.935,
      "eval_steps_per_second": 4.493,
      "num_input_tokens_seen": 7184768,
      "step": 3600
    },
    {
      "epoch": 2.2616470588235296,
      "grad_norm": 0.9870879054069519,
      "learning_rate": 7.120265953823521e-06,
      "loss": 1.9874,
      "num_input_tokens_seen": 7194784,
      "step": 3605,
      "train_runtime": 13686.3539,
      "train_tokens_per_second": 525.69
    },
    {
      "epoch": 2.26478431372549,
      "grad_norm": 1.0883089303970337,
      "learning_rate": 7.062966144234112e-06,
      "loss": 1.9507,
      "num_input_tokens_seen": 7204808,
      "step": 3610,
      "train_runtime": 13693.8886,
      "train_tokens_per_second": 526.133
    },
    {
      "epoch": 2.267921568627451,
      "grad_norm": 0.9969112873077393,
      "learning_rate": 7.005859874694226e-06,
      "loss": 2.001,
      "num_input_tokens_seen": 7214688,
      "step": 3615,
      "train_runtime": 13701.4585,
      "train_tokens_per_second": 526.564
    },
    {
      "epoch": 2.271058823529412,
      "grad_norm": 0.9662429690361023,
      "learning_rate": 6.9489477613787826e-06,
      "loss": 1.9241,
      "num_input_tokens_seen": 7224544,
      "step": 3620,
      "train_runtime": 13709.1007,
      "train_tokens_per_second": 526.989
    },
    {
      "epoch": 2.2741960784313724,
      "grad_norm": 1.0293540954589844,
      "learning_rate": 6.8922304183677595e-06,
      "loss": 1.9847,
      "num_input_tokens_seen": 7234840,
      "step": 3625,
      "train_runtime": 13716.8014,
      "train_tokens_per_second": 527.444
    },
    {
      "epoch": 2.2773333333333334,
      "grad_norm": 0.9885309338569641,
      "learning_rate": 6.835708457639556e-06,
      "loss": 1.9772,
      "num_input_tokens_seen": 7244776,
      "step": 3630,
      "train_runtime": 13724.5158,
      "train_tokens_per_second": 527.871
    },
    {
      "epoch": 2.280470588235294,
      "grad_norm": 1.0022207498550415,
      "learning_rate": 6.779382489064398e-06,
      "loss": 2.0034,
      "num_input_tokens_seen": 7254496,
      "step": 3635,
      "train_runtime": 13732.1209,
      "train_tokens_per_second": 528.287
    },
    {
      "epoch": 2.283607843137255,
      "grad_norm": 1.1142232418060303,
      "learning_rate": 6.723253120397783e-06,
      "loss": 1.982,
      "num_input_tokens_seen": 7264056,
      "step": 3640,
      "train_runtime": 13739.6687,
      "train_tokens_per_second": 528.692
    },
    {
      "epoch": 2.2867450980392157,
      "grad_norm": 1.1010253429412842,
      "learning_rate": 6.6673209572738985e-06,
      "loss": 1.9269,
      "num_input_tokens_seen": 7273976,
      "step": 3645,
      "train_runtime": 13747.3746,
      "train_tokens_per_second": 529.117
    },
    {
      "epoch": 2.2898823529411763,
      "grad_norm": 0.9498499035835266,
      "learning_rate": 6.611586603199066e-06,
      "loss": 2.041,
      "num_input_tokens_seen": 7284328,
      "step": 3650,
      "train_runtime": 13755.2104,
      "train_tokens_per_second": 529.569
    },
    {
      "epoch": 2.2930196078431373,
      "grad_norm": 1.0078034400939941,
      "learning_rate": 6.556050659545279e-06,
      "loss": 1.9176,
      "num_input_tokens_seen": 7294776,
      "step": 3655,
      "train_runtime": 13763.1325,
      "train_tokens_per_second": 530.023
    },
    {
      "epoch": 2.296156862745098,
      "grad_norm": 0.9737325310707092,
      "learning_rate": 6.500713725543689e-06,
      "loss": 1.9413,
      "num_input_tokens_seen": 7305080,
      "step": 3660,
      "train_runtime": 13770.8198,
      "train_tokens_per_second": 530.475
    },
    {
      "epoch": 2.299294117647059,
      "grad_norm": 0.9268617033958435,
      "learning_rate": 6.445576398278111e-06,
      "loss": 1.9407,
      "num_input_tokens_seen": 7315728,
      "step": 3665,
      "train_runtime": 13778.7041,
      "train_tokens_per_second": 530.945
    },
    {
      "epoch": 2.3024313725490195,
      "grad_norm": 0.9860630035400391,
      "learning_rate": 6.390639272678645e-06,
      "loss": 1.9522,
      "num_input_tokens_seen": 7325000,
      "step": 3670,
      "train_runtime": 13785.8178,
      "train_tokens_per_second": 531.343
    },
    {
      "epoch": 2.3055686274509806,
      "grad_norm": 1.0396488904953003,
      "learning_rate": 6.33590294151519e-06,
      "loss": 1.9865,
      "num_input_tokens_seen": 7335168,
      "step": 3675,
      "train_runtime": 13793.4516,
      "train_tokens_per_second": 531.786
    },
    {
      "epoch": 2.308705882352941,
      "grad_norm": 1.0882924795150757,
      "learning_rate": 6.281367995391102e-06,
      "loss": 1.9057,
      "num_input_tokens_seen": 7344656,
      "step": 3680,
      "train_runtime": 13800.9444,
      "train_tokens_per_second": 532.185
    },
    {
      "epoch": 2.311843137254902,
      "grad_norm": 0.9920068383216858,
      "learning_rate": 6.227035022736799e-06,
      "loss": 1.9118,
      "num_input_tokens_seen": 7354464,
      "step": 3685,
      "train_runtime": 13808.449,
      "train_tokens_per_second": 532.606
    },
    {
      "epoch": 2.314980392156863,
      "grad_norm": 0.9284849762916565,
      "learning_rate": 6.172904609803384e-06,
      "loss": 2.0059,
      "num_input_tokens_seen": 7365568,
      "step": 3690,
      "train_runtime": 13816.6525,
      "train_tokens_per_second": 533.094
    },
    {
      "epoch": 2.3181176470588234,
      "grad_norm": 1.1403988599777222,
      "learning_rate": 6.118977340656376e-06,
      "loss": 1.9731,
      "num_input_tokens_seen": 7374832,
      "step": 3695,
      "train_runtime": 13824.0187,
      "train_tokens_per_second": 533.48
    },
    {
      "epoch": 2.3212549019607844,
      "grad_norm": 0.9274898767471313,
      "learning_rate": 6.065253797169374e-06,
      "loss": 1.9757,
      "num_input_tokens_seen": 7385312,
      "step": 3700,
      "train_runtime": 13831.9666,
      "train_tokens_per_second": 533.931
    },
    {
      "epoch": 2.3212549019607844,
      "eval_loss": 2.337301015853882,
      "eval_runtime": 78.9744,
      "eval_samples_per_second": 17.943,
      "eval_steps_per_second": 4.495,
      "num_input_tokens_seen": 7385312,
      "step": 3700
    },
    {
      "epoch": 2.324392156862745,
      "grad_norm": 0.9264175891876221,
      "learning_rate": 6.011734559017765e-06,
      "loss": 1.967,
      "num_input_tokens_seen": 7395368,
      "step": 3705,
      "train_runtime": 13919.1192,
      "train_tokens_per_second": 531.31
    },
    {
      "epoch": 2.327529411764706,
      "grad_norm": 0.974405825138092,
      "learning_rate": 5.9584202036725045e-06,
      "loss": 1.9423,
      "num_input_tokens_seen": 7404856,
      "step": 3710,
      "train_runtime": 13926.6879,
      "train_tokens_per_second": 531.703
    },
    {
      "epoch": 2.3306666666666667,
      "grad_norm": 0.9459729790687561,
      "learning_rate": 5.905311306393874e-06,
      "loss": 2.0306,
      "num_input_tokens_seen": 7414976,
      "step": 3715,
      "train_runtime": 13934.3786,
      "train_tokens_per_second": 532.135
    },
    {
      "epoch": 2.3338039215686273,
      "grad_norm": 0.9479930996894836,
      "learning_rate": 5.852408440225243e-06,
      "loss": 1.9712,
      "num_input_tokens_seen": 7425064,
      "step": 3720,
      "train_runtime": 13942.0471,
      "train_tokens_per_second": 532.566
    },
    {
      "epoch": 2.3369411764705883,
      "grad_norm": 0.9232656955718994,
      "learning_rate": 5.799712175986946e-06,
      "loss": 2.0218,
      "num_input_tokens_seen": 7435320,
      "step": 3725,
      "train_runtime": 13949.9747,
      "train_tokens_per_second": 532.999
    },
    {
      "epoch": 2.340078431372549,
      "grad_norm": 0.9677202105522156,
      "learning_rate": 5.7472230822700505e-06,
      "loss": 1.9627,
      "num_input_tokens_seen": 7444712,
      "step": 3730,
      "train_runtime": 13957.3454,
      "train_tokens_per_second": 533.39
    },
    {
      "epoch": 2.34321568627451,
      "grad_norm": 0.9296000599861145,
      "learning_rate": 5.694941725430292e-06,
      "loss": 1.8544,
      "num_input_tokens_seen": 7454320,
      "step": 3735,
      "train_runtime": 13964.9295,
      "train_tokens_per_second": 533.789
    },
    {
      "epoch": 2.3463529411764705,
      "grad_norm": 1.2053438425064087,
      "learning_rate": 5.642868669581927e-06,
      "loss": 2.0192,
      "num_input_tokens_seen": 7464560,
      "step": 3740,
      "train_runtime": 13972.8643,
      "train_tokens_per_second": 534.218
    },
    {
      "epoch": 2.349490196078431,
      "grad_norm": 1.0328155755996704,
      "learning_rate": 5.591004476591627e-06,
      "loss": 2.012,
      "num_input_tokens_seen": 7474432,
      "step": 3745,
      "train_runtime": 13980.2788,
      "train_tokens_per_second": 534.641
    },
    {
      "epoch": 2.352627450980392,
      "grad_norm": 0.9434788823127747,
      "learning_rate": 5.539349706072466e-06,
      "loss": 1.9749,
      "num_input_tokens_seen": 7484384,
      "step": 3750,
      "train_runtime": 13987.9405,
      "train_tokens_per_second": 535.06
    },
    {
      "epoch": 2.3557647058823528,
      "grad_norm": 0.8181129693984985,
      "learning_rate": 5.4879049153778535e-06,
      "loss": 1.9755,
      "num_input_tokens_seen": 7494720,
      "step": 3755,
      "train_runtime": 13995.8271,
      "train_tokens_per_second": 535.497
    },
    {
      "epoch": 2.358901960784314,
      "grad_norm": 0.9019477367401123,
      "learning_rate": 5.436670659595505e-06,
      "loss": 1.9968,
      "num_input_tokens_seen": 7505520,
      "step": 3760,
      "train_runtime": 14003.9197,
      "train_tokens_per_second": 535.959
    },
    {
      "epoch": 2.3620392156862744,
      "grad_norm": 0.9805848598480225,
      "learning_rate": 5.385647491541476e-06,
      "loss": 2.0475,
      "num_input_tokens_seen": 7515752,
      "step": 3765,
      "train_runtime": 14011.5559,
      "train_tokens_per_second": 536.397
    },
    {
      "epoch": 2.3651764705882354,
      "grad_norm": 0.9995049238204956,
      "learning_rate": 5.334835961754206e-06,
      "loss": 1.9769,
      "num_input_tokens_seen": 7525976,
      "step": 3770,
      "train_runtime": 14019.2716,
      "train_tokens_per_second": 536.831
    },
    {
      "epoch": 2.368313725490196,
      "grad_norm": 0.9112699627876282,
      "learning_rate": 5.284236618488564e-06,
      "loss": 1.9706,
      "num_input_tokens_seen": 7535992,
      "step": 3775,
      "train_runtime": 14026.9827,
      "train_tokens_per_second": 537.25
    },
    {
      "epoch": 2.371450980392157,
      "grad_norm": 1.0153084993362427,
      "learning_rate": 5.233850007709904e-06,
      "loss": 1.9108,
      "num_input_tokens_seen": 7545984,
      "step": 3780,
      "train_runtime": 14034.6104,
      "train_tokens_per_second": 537.67
    },
    {
      "epoch": 2.3745882352941177,
      "grad_norm": 0.9953562617301941,
      "learning_rate": 5.183676673088237e-06,
      "loss": 2.0375,
      "num_input_tokens_seen": 7555768,
      "step": 3785,
      "train_runtime": 14042.1124,
      "train_tokens_per_second": 538.079
    },
    {
      "epoch": 2.3777254901960783,
      "grad_norm": 1.0081944465637207,
      "learning_rate": 5.133717155992318e-06,
      "loss": 1.9316,
      "num_input_tokens_seen": 7566224,
      "step": 3790,
      "train_runtime": 14050.1167,
      "train_tokens_per_second": 538.517
    },
    {
      "epoch": 2.3808627450980393,
      "grad_norm": 1.0086973905563354,
      "learning_rate": 5.0839719954838075e-06,
      "loss": 1.9539,
      "num_input_tokens_seen": 7576408,
      "step": 3795,
      "train_runtime": 14057.9994,
      "train_tokens_per_second": 538.939
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.9090444445610046,
      "learning_rate": 5.034441728311484e-06,
      "loss": 1.9528,
      "num_input_tokens_seen": 7586920,
      "step": 3800,
      "train_runtime": 14065.9565,
      "train_tokens_per_second": 539.382
    },
    {
      "epoch": 2.384,
      "eval_loss": 2.3363547325134277,
      "eval_runtime": 79.0218,
      "eval_samples_per_second": 17.932,
      "eval_steps_per_second": 4.492,
      "num_input_tokens_seen": 7586920,
      "step": 3800
    },
    {
      "epoch": 2.387137254901961,
      "grad_norm": 1.0254722833633423,
      "learning_rate": 4.985126888905411e-06,
      "loss": 1.8213,
      "num_input_tokens_seen": 7596224,
      "step": 3805,
      "train_runtime": 14152.5994,
      "train_tokens_per_second": 536.737
    },
    {
      "epoch": 2.3902745098039215,
      "grad_norm": 1.1361297369003296,
      "learning_rate": 4.936028009371213e-06,
      "loss": 1.9098,
      "num_input_tokens_seen": 7606096,
      "step": 3810,
      "train_runtime": 14160.0553,
      "train_tokens_per_second": 537.152
    },
    {
      "epoch": 2.393411764705882,
      "grad_norm": 1.0163651704788208,
      "learning_rate": 4.887145619484312e-06,
      "loss": 1.8965,
      "num_input_tokens_seen": 7615912,
      "step": 3815,
      "train_runtime": 14167.4889,
      "train_tokens_per_second": 537.563
    },
    {
      "epoch": 2.396549019607843,
      "grad_norm": 0.942882239818573,
      "learning_rate": 4.8384802466841935e-06,
      "loss": 2.0326,
      "num_input_tokens_seen": 7626000,
      "step": 3820,
      "train_runtime": 14175.4961,
      "train_tokens_per_second": 537.971
    },
    {
      "epoch": 2.3996862745098038,
      "grad_norm": 1.0937609672546387,
      "learning_rate": 4.790032416068757e-06,
      "loss": 1.9537,
      "num_input_tokens_seen": 7635960,
      "step": 3825,
      "train_runtime": 14182.8039,
      "train_tokens_per_second": 538.396
    },
    {
      "epoch": 2.402823529411765,
      "grad_norm": 0.9690919518470764,
      "learning_rate": 4.741802650388624e-06,
      "loss": 2.0065,
      "num_input_tokens_seen": 7646544,
      "step": 3830,
      "train_runtime": 14190.7591,
      "train_tokens_per_second": 538.84
    },
    {
      "epoch": 2.4059607843137254,
      "grad_norm": 1.1089063882827759,
      "learning_rate": 4.6937914700414975e-06,
      "loss": 1.9521,
      "num_input_tokens_seen": 7656488,
      "step": 3835,
      "train_runtime": 14198.4021,
      "train_tokens_per_second": 539.25
    },
    {
      "epoch": 2.4090980392156864,
      "grad_norm": 0.9684144258499146,
      "learning_rate": 4.6459993930665445e-06,
      "loss": 2.061,
      "num_input_tokens_seen": 7666344,
      "step": 3840,
      "train_runtime": 14206.0444,
      "train_tokens_per_second": 539.654
    },
    {
      "epoch": 2.412235294117647,
      "grad_norm": 0.9824334383010864,
      "learning_rate": 4.598426935138822e-06,
      "loss": 1.9094,
      "num_input_tokens_seen": 7675960,
      "step": 3845,
      "train_runtime": 14213.3821,
      "train_tokens_per_second": 540.052
    },
    {
      "epoch": 2.415372549019608,
      "grad_norm": 0.9662536382675171,
      "learning_rate": 4.551074609563718e-06,
      "loss": 1.9806,
      "num_input_tokens_seen": 7686016,
      "step": 3850,
      "train_runtime": 14221.083,
      "train_tokens_per_second": 540.466
    },
    {
      "epoch": 2.4185098039215687,
      "grad_norm": 1.009110450744629,
      "learning_rate": 4.5039429272713705e-06,
      "loss": 2.0367,
      "num_input_tokens_seen": 7696304,
      "step": 3855,
      "train_runtime": 14228.8768,
      "train_tokens_per_second": 540.893
    },
    {
      "epoch": 2.4216470588235293,
      "grad_norm": 1.0449669361114502,
      "learning_rate": 4.4570323968111976e-06,
      "loss": 1.97,
      "num_input_tokens_seen": 7706368,
      "step": 3860,
      "train_runtime": 14236.7789,
      "train_tokens_per_second": 541.3
    },
    {
      "epoch": 2.4247843137254903,
      "grad_norm": 1.045681118965149,
      "learning_rate": 4.410343524346411e-06,
      "loss": 1.9969,
      "num_input_tokens_seen": 7715928,
      "step": 3865,
      "train_runtime": 14244.1749,
      "train_tokens_per_second": 541.69
    },
    {
      "epoch": 2.427921568627451,
      "grad_norm": 0.9532310366630554,
      "learning_rate": 4.363876813648504e-06,
      "loss": 1.829,
      "num_input_tokens_seen": 7725680,
      "step": 3870,
      "train_runtime": 14252.0302,
      "train_tokens_per_second": 542.076
    },
    {
      "epoch": 2.431058823529412,
      "grad_norm": 1.1040927171707153,
      "learning_rate": 4.317632766091887e-06,
      "loss": 2.0059,
      "num_input_tokens_seen": 7735328,
      "step": 3875,
      "train_runtime": 14259.8082,
      "train_tokens_per_second": 542.457
    },
    {
      "epoch": 2.4341960784313725,
      "grad_norm": 1.0545533895492554,
      "learning_rate": 4.27161188064841e-06,
      "loss": 1.8342,
      "num_input_tokens_seen": 7744600,
      "step": 3880,
      "train_runtime": 14267.0587,
      "train_tokens_per_second": 542.831
    },
    {
      "epoch": 2.437333333333333,
      "grad_norm": 1.0217572450637817,
      "learning_rate": 4.225814653882037e-06,
      "loss": 1.98,
      "num_input_tokens_seen": 7754672,
      "step": 3885,
      "train_runtime": 14274.6459,
      "train_tokens_per_second": 543.248
    },
    {
      "epoch": 2.440470588235294,
      "grad_norm": 1.042575716972351,
      "learning_rate": 4.180241579943459e-06,
      "loss": 2.0094,
      "num_input_tokens_seen": 7764472,
      "step": 3890,
      "train_runtime": 14282.1693,
      "train_tokens_per_second": 543.648
    },
    {
      "epoch": 2.4436078431372548,
      "grad_norm": 1.0059179067611694,
      "learning_rate": 4.134893150564742e-06,
      "loss": 2.0242,
      "num_input_tokens_seen": 7774400,
      "step": 3895,
      "train_runtime": 14289.8195,
      "train_tokens_per_second": 544.052
    },
    {
      "epoch": 2.446745098039216,
      "grad_norm": 1.0874412059783936,
      "learning_rate": 4.0897698550540625e-06,
      "loss": 1.9512,
      "num_input_tokens_seen": 7784384,
      "step": 3900,
      "train_runtime": 14297.5268,
      "train_tokens_per_second": 544.457
    },
    {
      "epoch": 2.446745098039216,
      "eval_loss": 2.3356685638427734,
      "eval_runtime": 79.0603,
      "eval_samples_per_second": 17.923,
      "eval_steps_per_second": 4.49,
      "num_input_tokens_seen": 7784384,
      "step": 3900
    },
    {
      "epoch": 2.4498823529411764,
      "grad_norm": 0.9047106504440308,
      "learning_rate": 4.044872180290418e-06,
      "loss": 1.9375,
      "num_input_tokens_seen": 7793840,
      "step": 3905,
      "train_runtime": 14384.2161,
      "train_tokens_per_second": 541.833
    },
    {
      "epoch": 2.4530196078431374,
      "grad_norm": 1.0985033512115479,
      "learning_rate": 4.000200610718341e-06,
      "loss": 1.9374,
      "num_input_tokens_seen": 7803792,
      "step": 3910,
      "train_runtime": 14391.7485,
      "train_tokens_per_second": 542.241
    },
    {
      "epoch": 2.456156862745098,
      "grad_norm": 0.9323257803916931,
      "learning_rate": 3.955755628342703e-06,
      "loss": 1.9651,
      "num_input_tokens_seen": 7814040,
      "step": 3915,
      "train_runtime": 14399.4572,
      "train_tokens_per_second": 542.662
    },
    {
      "epoch": 2.4592941176470586,
      "grad_norm": 0.9816303849220276,
      "learning_rate": 3.911537712723529e-06,
      "loss": 1.8957,
      "num_input_tokens_seen": 7824080,
      "step": 3920,
      "train_runtime": 14407.1623,
      "train_tokens_per_second": 543.069
    },
    {
      "epoch": 2.4624313725490197,
      "grad_norm": 0.9307457208633423,
      "learning_rate": 3.8675473409707675e-06,
      "loss": 1.9496,
      "num_input_tokens_seen": 7834480,
      "step": 3925,
      "train_runtime": 14414.9304,
      "train_tokens_per_second": 543.498
    },
    {
      "epoch": 2.4655686274509803,
      "grad_norm": 1.0379492044448853,
      "learning_rate": 3.823784987739204e-06,
      "loss": 2.0309,
      "num_input_tokens_seen": 7844120,
      "step": 3930,
      "train_runtime": 14422.4971,
      "train_tokens_per_second": 543.881
    },
    {
      "epoch": 2.4687058823529413,
      "grad_norm": 0.9605423212051392,
      "learning_rate": 3.780251125223286e-06,
      "loss": 1.9875,
      "num_input_tokens_seen": 7854080,
      "step": 3935,
      "train_runtime": 14429.9788,
      "train_tokens_per_second": 544.289
    },
    {
      "epoch": 2.471843137254902,
      "grad_norm": 0.9588079452514648,
      "learning_rate": 3.7369462231520685e-06,
      "loss": 1.9283,
      "num_input_tokens_seen": 7864248,
      "step": 3940,
      "train_runtime": 14437.8907,
      "train_tokens_per_second": 544.695
    },
    {
      "epoch": 2.474980392156863,
      "grad_norm": 1.0399370193481445,
      "learning_rate": 3.6938707487841396e-06,
      "loss": 1.9887,
      "num_input_tokens_seen": 7874184,
      "step": 3945,
      "train_runtime": 14445.4487,
      "train_tokens_per_second": 545.098
    },
    {
      "epoch": 2.4781176470588235,
      "grad_norm": 1.0366917848587036,
      "learning_rate": 3.6510251669025385e-06,
      "loss": 2.0107,
      "num_input_tokens_seen": 7884120,
      "step": 3950,
      "train_runtime": 14453.0982,
      "train_tokens_per_second": 545.497
    },
    {
      "epoch": 2.481254901960784,
      "grad_norm": 0.9934322237968445,
      "learning_rate": 3.608409939809801e-06,
      "loss": 2.0184,
      "num_input_tokens_seen": 7894176,
      "step": 3955,
      "train_runtime": 14460.9179,
      "train_tokens_per_second": 545.897
    },
    {
      "epoch": 2.484392156862745,
      "grad_norm": 1.1565409898757935,
      "learning_rate": 3.566025527322933e-06,
      "loss": 2.0084,
      "num_input_tokens_seen": 7904072,
      "step": 3960,
      "train_runtime": 14468.5246,
      "train_tokens_per_second": 546.294
    },
    {
      "epoch": 2.4875294117647058,
      "grad_norm": 1.0101945400238037,
      "learning_rate": 3.5238723867684535e-06,
      "loss": 1.9749,
      "num_input_tokens_seen": 7913312,
      "step": 3965,
      "train_runtime": 14475.5997,
      "train_tokens_per_second": 546.666
    },
    {
      "epoch": 2.490666666666667,
      "grad_norm": 1.0919300317764282,
      "learning_rate": 3.4819509729774573e-06,
      "loss": 1.9312,
      "num_input_tokens_seen": 7923304,
      "step": 3970,
      "train_runtime": 14483.4338,
      "train_tokens_per_second": 547.06
    },
    {
      "epoch": 2.4938039215686274,
      "grad_norm": 1.034128189086914,
      "learning_rate": 3.4402617382807286e-06,
      "loss": 2.0053,
      "num_input_tokens_seen": 7933016,
      "step": 3975,
      "train_runtime": 14490.9102,
      "train_tokens_per_second": 547.448
    },
    {
      "epoch": 2.496941176470588,
      "grad_norm": 0.9942259192466736,
      "learning_rate": 3.3988051325038516e-06,
      "loss": 2.0243,
      "num_input_tokens_seen": 7942952,
      "step": 3980,
      "train_runtime": 14498.4144,
      "train_tokens_per_second": 547.85
    },
    {
      "epoch": 2.500078431372549,
      "grad_norm": 1.0737779140472412,
      "learning_rate": 3.357581602962326e-06,
      "loss": 1.9095,
      "num_input_tokens_seen": 7952952,
      "step": 3985,
      "train_runtime": 14506.4706,
      "train_tokens_per_second": 548.235
    },
    {
      "epoch": 2.50321568627451,
      "grad_norm": 1.0605007410049438,
      "learning_rate": 3.316591594456786e-06,
      "loss": 2.0932,
      "num_input_tokens_seen": 7963096,
      "step": 3990,
      "train_runtime": 14514.1938,
      "train_tokens_per_second": 548.642
    },
    {
      "epoch": 2.5063529411764707,
      "grad_norm": 1.0074018239974976,
      "learning_rate": 3.2758355492681886e-06,
      "loss": 1.9156,
      "num_input_tokens_seen": 7973328,
      "step": 3995,
      "train_runtime": 14522.1495,
      "train_tokens_per_second": 549.046
    },
    {
      "epoch": 2.5094901960784313,
      "grad_norm": 0.9962837100028992,
      "learning_rate": 3.2353139071530007e-06,
      "loss": 1.9831,
      "num_input_tokens_seen": 7983488,
      "step": 4000,
      "train_runtime": 14530.0287,
      "train_tokens_per_second": 549.448
    },
    {
      "epoch": 2.5094901960784313,
      "eval_loss": 2.33475399017334,
      "eval_runtime": 79.0869,
      "eval_samples_per_second": 17.917,
      "eval_steps_per_second": 4.489,
      "num_input_tokens_seen": 7983488,
      "step": 4000
    },
    {
      "epoch": 2.5126274509803923,
      "grad_norm": 0.928313136100769,
      "learning_rate": 3.195027105338527e-06,
      "loss": 1.9141,
      "num_input_tokens_seen": 7993232,
      "step": 4005,
      "train_runtime": 14616.9638,
      "train_tokens_per_second": 546.846
    },
    {
      "epoch": 2.515764705882353,
      "grad_norm": 1.0840917825698853,
      "learning_rate": 3.1549755785181186e-06,
      "loss": 1.9656,
      "num_input_tokens_seen": 8003296,
      "step": 4010,
      "train_runtime": 14624.8398,
      "train_tokens_per_second": 547.24
    },
    {
      "epoch": 2.518901960784314,
      "grad_norm": 1.0922969579696655,
      "learning_rate": 3.115159758846534e-06,
      "loss": 1.9378,
      "num_input_tokens_seen": 8012736,
      "step": 4015,
      "train_runtime": 14632.0311,
      "train_tokens_per_second": 547.616
    },
    {
      "epoch": 2.5220392156862745,
      "grad_norm": 1.0747944116592407,
      "learning_rate": 3.0755800759352663e-06,
      "loss": 1.9465,
      "num_input_tokens_seen": 8022344,
      "step": 4020,
      "train_runtime": 14639.3621,
      "train_tokens_per_second": 547.998
    },
    {
      "epoch": 2.525176470588235,
      "grad_norm": 1.027400255203247,
      "learning_rate": 3.0362369568478766e-06,
      "loss": 2.0709,
      "num_input_tokens_seen": 8032544,
      "step": 4025,
      "train_runtime": 14647.0813,
      "train_tokens_per_second": 548.406
    },
    {
      "epoch": 2.528313725490196,
      "grad_norm": 1.0595641136169434,
      "learning_rate": 2.997130826095429e-06,
      "loss": 1.9595,
      "num_input_tokens_seen": 8041944,
      "step": 4030,
      "train_runtime": 14654.458,
      "train_tokens_per_second": 548.771
    },
    {
      "epoch": 2.5314509803921568,
      "grad_norm": 0.9666947722434998,
      "learning_rate": 2.9582621056318897e-06,
      "loss": 1.9516,
      "num_input_tokens_seen": 8052272,
      "step": 4035,
      "train_runtime": 14662.2745,
      "train_tokens_per_second": 549.183
    },
    {
      "epoch": 2.534588235294118,
      "grad_norm": 1.1428322792053223,
      "learning_rate": 2.9196312148495638e-06,
      "loss": 1.9746,
      "num_input_tokens_seen": 8061776,
      "step": 4040,
      "train_runtime": 14669.7758,
      "train_tokens_per_second": 549.55
    },
    {
      "epoch": 2.5377254901960784,
      "grad_norm": 1.0183403491973877,
      "learning_rate": 2.8812385705745793e-06,
      "loss": 2.0141,
      "num_input_tokens_seen": 8072072,
      "step": 4045,
      "train_runtime": 14677.6938,
      "train_tokens_per_second": 549.955
    },
    {
      "epoch": 2.540862745098039,
      "grad_norm": 0.9712976813316345,
      "learning_rate": 2.8430845870624166e-06,
      "loss": 1.9706,
      "num_input_tokens_seen": 8082424,
      "step": 4050,
      "train_runtime": 14685.5152,
      "train_tokens_per_second": 550.367
    },
    {
      "epoch": 2.544,
      "grad_norm": 1.0472962856292725,
      "learning_rate": 2.805169675993388e-06,
      "loss": 1.9668,
      "num_input_tokens_seen": 8092888,
      "step": 4055,
      "train_runtime": 14693.6484,
      "train_tokens_per_second": 550.775
    },
    {
      "epoch": 2.5471372549019606,
      "grad_norm": 1.0674092769622803,
      "learning_rate": 2.7674942464682274e-06,
      "loss": 1.959,
      "num_input_tokens_seen": 8103072,
      "step": 4060,
      "train_runtime": 14701.5347,
      "train_tokens_per_second": 551.172
    },
    {
      "epoch": 2.5502745098039217,
      "grad_norm": 1.0039976835250854,
      "learning_rate": 2.730058705003674e-06,
      "loss": 1.9682,
      "num_input_tokens_seen": 8112672,
      "step": 4065,
      "train_runtime": 14708.9002,
      "train_tokens_per_second": 551.549
    },
    {
      "epoch": 2.5534117647058823,
      "grad_norm": 0.9258204102516174,
      "learning_rate": 2.6928634555280913e-06,
      "loss": 1.9995,
      "num_input_tokens_seen": 8122656,
      "step": 4070,
      "train_runtime": 14716.5177,
      "train_tokens_per_second": 551.941
    },
    {
      "epoch": 2.556549019607843,
      "grad_norm": 1.0299997329711914,
      "learning_rate": 2.655908899377074e-06,
      "loss": 2.0022,
      "num_input_tokens_seen": 8132376,
      "step": 4075,
      "train_runtime": 14723.8522,
      "train_tokens_per_second": 552.327
    },
    {
      "epoch": 2.559686274509804,
      "grad_norm": 1.0138344764709473,
      "learning_rate": 2.6191954352891736e-06,
      "loss": 1.9066,
      "num_input_tokens_seen": 8141976,
      "step": 4080,
      "train_runtime": 14731.2244,
      "train_tokens_per_second": 552.702
    },
    {
      "epoch": 2.562823529411765,
      "grad_norm": 1.055203914642334,
      "learning_rate": 2.582723459401537e-06,
      "loss": 2.0127,
      "num_input_tokens_seen": 8151696,
      "step": 4085,
      "train_runtime": 14738.9279,
      "train_tokens_per_second": 553.073
    },
    {
      "epoch": 2.5659607843137255,
      "grad_norm": 1.0254861116409302,
      "learning_rate": 2.5464933652456807e-06,
      "loss": 1.9342,
      "num_input_tokens_seen": 8161448,
      "step": 4090,
      "train_runtime": 14746.7128,
      "train_tokens_per_second": 553.442
    },
    {
      "epoch": 2.569098039215686,
      "grad_norm": 0.8963825702667236,
      "learning_rate": 2.5105055437432217e-06,
      "loss": 1.9223,
      "num_input_tokens_seen": 8171736,
      "step": 4095,
      "train_runtime": 14754.2802,
      "train_tokens_per_second": 553.855
    },
    {
      "epoch": 2.572235294117647,
      "grad_norm": 1.0774357318878174,
      "learning_rate": 2.474760383201652e-06,
      "loss": 1.9416,
      "num_input_tokens_seen": 8181368,
      "step": 4100,
      "train_runtime": 14761.6901,
      "train_tokens_per_second": 554.23
    },
    {
      "epoch": 2.572235294117647,
      "eval_loss": 2.3340303897857666,
      "eval_runtime": 79.0921,
      "eval_samples_per_second": 17.916,
      "eval_steps_per_second": 4.488,
      "num_input_tokens_seen": 8181368,
      "step": 4100
    },
    {
      "epoch": 2.5753725490196078,
      "grad_norm": 1.0242135524749756,
      "learning_rate": 2.4392582693101684e-06,
      "loss": 1.8568,
      "num_input_tokens_seen": 8190664,
      "step": 4105,
      "train_runtime": 14848.2985,
      "train_tokens_per_second": 551.623
    },
    {
      "epoch": 2.578509803921569,
      "grad_norm": 0.9451236128807068,
      "learning_rate": 2.4039995851355078e-06,
      "loss": 1.9627,
      "num_input_tokens_seen": 8201384,
      "step": 4110,
      "train_runtime": 14856.1387,
      "train_tokens_per_second": 552.054
    },
    {
      "epoch": 2.5816470588235294,
      "grad_norm": 0.9994097948074341,
      "learning_rate": 2.3689847111177916e-06,
      "loss": 1.9285,
      "num_input_tokens_seen": 8210936,
      "step": 4115,
      "train_runtime": 14863.5813,
      "train_tokens_per_second": 552.42
    },
    {
      "epoch": 2.58478431372549,
      "grad_norm": 1.0644510984420776,
      "learning_rate": 2.3342140250664336e-06,
      "loss": 1.9165,
      "num_input_tokens_seen": 8221056,
      "step": 4120,
      "train_runtime": 14871.1137,
      "train_tokens_per_second": 552.82
    },
    {
      "epoch": 2.587921568627451,
      "grad_norm": 0.9687952995300293,
      "learning_rate": 2.299687902156103e-06,
      "loss": 1.9579,
      "num_input_tokens_seen": 8231024,
      "step": 4125,
      "train_runtime": 14878.6578,
      "train_tokens_per_second": 553.21
    },
    {
      "epoch": 2.5910588235294116,
      "grad_norm": 1.0008533000946045,
      "learning_rate": 2.265406714922602e-06,
      "loss": 1.9954,
      "num_input_tokens_seen": 8240984,
      "step": 4130,
      "train_runtime": 14886.5842,
      "train_tokens_per_second": 553.585
    },
    {
      "epoch": 2.5941960784313727,
      "grad_norm": 0.9985437989234924,
      "learning_rate": 2.2313708332588947e-06,
      "loss": 2.0366,
      "num_input_tokens_seen": 8250960,
      "step": 4135,
      "train_runtime": 14894.1485,
      "train_tokens_per_second": 553.973
    },
    {
      "epoch": 2.5973333333333333,
      "grad_norm": 1.0145344734191895,
      "learning_rate": 2.1975806244111137e-06,
      "loss": 1.9702,
      "num_input_tokens_seen": 8260872,
      "step": 4140,
      "train_runtime": 14901.6916,
      "train_tokens_per_second": 554.358
    },
    {
      "epoch": 2.600470588235294,
      "grad_norm": 1.0454879999160767,
      "learning_rate": 2.1640364529745826e-06,
      "loss": 2.0031,
      "num_input_tokens_seen": 8270576,
      "step": 4145,
      "train_runtime": 14909.1092,
      "train_tokens_per_second": 554.733
    },
    {
      "epoch": 2.603607843137255,
      "grad_norm": 0.9864563941955566,
      "learning_rate": 2.130738680889896e-06,
      "loss": 1.866,
      "num_input_tokens_seen": 8280480,
      "step": 4150,
      "train_runtime": 14916.4755,
      "train_tokens_per_second": 555.123
    },
    {
      "epoch": 2.606745098039216,
      "grad_norm": 0.9852878451347351,
      "learning_rate": 2.097687667438994e-06,
      "loss": 1.8429,
      "num_input_tokens_seen": 8289696,
      "step": 4155,
      "train_runtime": 14923.8965,
      "train_tokens_per_second": 555.465
    },
    {
      "epoch": 2.6098823529411765,
      "grad_norm": 1.0251113176345825,
      "learning_rate": 2.0648837692413076e-06,
      "loss": 1.8961,
      "num_input_tokens_seen": 8299072,
      "step": 4160,
      "train_runtime": 14930.9987,
      "train_tokens_per_second": 555.828
    },
    {
      "epoch": 2.613019607843137,
      "grad_norm": 1.039801001548767,
      "learning_rate": 2.0323273402499066e-06,
      "loss": 1.936,
      "num_input_tokens_seen": 8308880,
      "step": 4165,
      "train_runtime": 14938.3694,
      "train_tokens_per_second": 556.211
    },
    {
      "epoch": 2.616156862745098,
      "grad_norm": 1.0229600667953491,
      "learning_rate": 2.000018731747663e-06,
      "loss": 1.9518,
      "num_input_tokens_seen": 8318760,
      "step": 4170,
      "train_runtime": 14945.8057,
      "train_tokens_per_second": 556.595
    },
    {
      "epoch": 2.6192941176470588,
      "grad_norm": 1.0154379606246948,
      "learning_rate": 1.9679582923434773e-06,
      "loss": 2.0932,
      "num_input_tokens_seen": 8328808,
      "step": 4175,
      "train_runtime": 14953.5864,
      "train_tokens_per_second": 556.977
    },
    {
      "epoch": 2.62243137254902,
      "grad_norm": 0.9943674206733704,
      "learning_rate": 1.9361463679685192e-06,
      "loss": 1.938,
      "num_input_tokens_seen": 8339936,
      "step": 4180,
      "train_runtime": 14961.7,
      "train_tokens_per_second": 557.419
    },
    {
      "epoch": 2.6255686274509804,
      "grad_norm": 1.0092560052871704,
      "learning_rate": 1.9045833018724895e-06,
      "loss": 1.8026,
      "num_input_tokens_seen": 8349208,
      "step": 4185,
      "train_runtime": 14968.663,
      "train_tokens_per_second": 557.779
    },
    {
      "epoch": 2.628705882352941,
      "grad_norm": 1.042546033859253,
      "learning_rate": 1.873269434619898e-06,
      "loss": 1.9688,
      "num_input_tokens_seen": 8359056,
      "step": 4190,
      "train_runtime": 14976.1124,
      "train_tokens_per_second": 558.159
    },
    {
      "epoch": 2.631843137254902,
      "grad_norm": 0.9419285655021667,
      "learning_rate": 1.8422051040864308e-06,
      "loss": 1.9427,
      "num_input_tokens_seen": 8369152,
      "step": 4195,
      "train_runtime": 14983.6897,
      "train_tokens_per_second": 558.551
    },
    {
      "epoch": 2.6349803921568626,
      "grad_norm": 0.972057044506073,
      "learning_rate": 1.8113906454552688e-06,
      "loss": 1.8254,
      "num_input_tokens_seen": 8378600,
      "step": 4200,
      "train_runtime": 14991.065,
      "train_tokens_per_second": 558.906
    },
    {
      "epoch": 2.6349803921568626,
      "eval_loss": 2.3340394496917725,
      "eval_runtime": 79.0299,
      "eval_samples_per_second": 17.93,
      "eval_steps_per_second": 4.492,
      "num_input_tokens_seen": 8378600,
      "step": 4200
    },
    {
      "epoch": 2.6381176470588237,
      "grad_norm": 0.9166439771652222,
      "learning_rate": 1.7808263912134748e-06,
      "loss": 1.8798,
      "num_input_tokens_seen": 8388512,
      "step": 4205,
      "train_runtime": 15077.8895,
      "train_tokens_per_second": 556.345
    },
    {
      "epoch": 2.6412549019607843,
      "grad_norm": 0.9327230453491211,
      "learning_rate": 1.7505126711484327e-06,
      "loss": 2.0367,
      "num_input_tokens_seen": 8399208,
      "step": 4210,
      "train_runtime": 15085.8217,
      "train_tokens_per_second": 556.762
    },
    {
      "epoch": 2.644392156862745,
      "grad_norm": 1.1360487937927246,
      "learning_rate": 1.7204498123442492e-06,
      "loss": 2.0291,
      "num_input_tokens_seen": 8409176,
      "step": 4215,
      "train_runtime": 15093.5613,
      "train_tokens_per_second": 557.137
    },
    {
      "epoch": 2.647529411764706,
      "grad_norm": 1.0026369094848633,
      "learning_rate": 1.6906381391782605e-06,
      "loss": 1.8738,
      "num_input_tokens_seen": 8419600,
      "step": 4220,
      "train_runtime": 15101.514,
      "train_tokens_per_second": 557.534
    },
    {
      "epoch": 2.6506666666666665,
      "grad_norm": 1.0190510749816895,
      "learning_rate": 1.661077973317518e-06,
      "loss": 1.9471,
      "num_input_tokens_seen": 8429328,
      "step": 4225,
      "train_runtime": 15109.2929,
      "train_tokens_per_second": 557.89
    },
    {
      "epoch": 2.6538039215686275,
      "grad_norm": 1.078104853630066,
      "learning_rate": 1.631769633715305e-06,
      "loss": 1.8972,
      "num_input_tokens_seen": 8439216,
      "step": 4230,
      "train_runtime": 15116.8119,
      "train_tokens_per_second": 558.267
    },
    {
      "epoch": 2.656941176470588,
      "grad_norm": 1.0927891731262207,
      "learning_rate": 1.602713436607714e-06,
      "loss": 1.9175,
      "num_input_tokens_seen": 8449360,
      "step": 4235,
      "train_runtime": 15124.5516,
      "train_tokens_per_second": 558.652
    },
    {
      "epoch": 2.660078431372549,
      "grad_norm": 0.9895141124725342,
      "learning_rate": 1.573909695510234e-06,
      "loss": 1.9111,
      "num_input_tokens_seen": 8459056,
      "step": 4240,
      "train_runtime": 15132.0873,
      "train_tokens_per_second": 559.014
    },
    {
      "epoch": 2.6632156862745098,
      "grad_norm": 0.9821738600730896,
      "learning_rate": 1.5453587212143516e-06,
      "loss": 1.8886,
      "num_input_tokens_seen": 8469416,
      "step": 4245,
      "train_runtime": 15139.8924,
      "train_tokens_per_second": 559.411
    },
    {
      "epoch": 2.666352941176471,
      "grad_norm": 1.0910651683807373,
      "learning_rate": 1.5170608217842053e-06,
      "loss": 2.0472,
      "num_input_tokens_seen": 8479352,
      "step": 4250,
      "train_runtime": 15147.3283,
      "train_tokens_per_second": 559.792
    },
    {
      "epoch": 2.6694901960784314,
      "grad_norm": 0.9598801136016846,
      "learning_rate": 1.4890163025532782e-06,
      "loss": 1.9013,
      "num_input_tokens_seen": 8489024,
      "step": 4255,
      "train_runtime": 15154.8617,
      "train_tokens_per_second": 560.152
    },
    {
      "epoch": 2.672627450980392,
      "grad_norm": 1.1033987998962402,
      "learning_rate": 1.4612254661210771e-06,
      "loss": 2.0693,
      "num_input_tokens_seen": 8498864,
      "step": 4260,
      "train_runtime": 15162.6552,
      "train_tokens_per_second": 560.513
    },
    {
      "epoch": 2.675764705882353,
      "grad_norm": 0.9532541632652283,
      "learning_rate": 1.4336886123498732e-06,
      "loss": 1.9118,
      "num_input_tokens_seen": 8508984,
      "step": 4265,
      "train_runtime": 15170.4882,
      "train_tokens_per_second": 560.891
    },
    {
      "epoch": 2.6789019607843136,
      "grad_norm": 1.1022484302520752,
      "learning_rate": 1.4064060383614907e-06,
      "loss": 1.9745,
      "num_input_tokens_seen": 8519416,
      "step": 4270,
      "train_runtime": 15178.3639,
      "train_tokens_per_second": 561.287
    },
    {
      "epoch": 2.6820392156862747,
      "grad_norm": 1.1093010902404785,
      "learning_rate": 1.379378038534071e-06,
      "loss": 1.9443,
      "num_input_tokens_seen": 8528824,
      "step": 4275,
      "train_runtime": 15185.5839,
      "train_tokens_per_second": 561.64
    },
    {
      "epoch": 2.6851764705882353,
      "grad_norm": 1.1229043006896973,
      "learning_rate": 1.3526049044989053e-06,
      "loss": 1.9137,
      "num_input_tokens_seen": 8538976,
      "step": 4280,
      "train_runtime": 15193.3926,
      "train_tokens_per_second": 562.019
    },
    {
      "epoch": 2.688313725490196,
      "grad_norm": 1.048992395401001,
      "learning_rate": 1.3260869251373015e-06,
      "loss": 1.8939,
      "num_input_tokens_seen": 8548216,
      "step": 4285,
      "train_runtime": 15200.4901,
      "train_tokens_per_second": 562.364
    },
    {
      "epoch": 2.691450980392157,
      "grad_norm": 0.9547625780105591,
      "learning_rate": 1.2998243865774418e-06,
      "loss": 1.9148,
      "num_input_tokens_seen": 8558232,
      "step": 4290,
      "train_runtime": 15208.0504,
      "train_tokens_per_second": 562.744
    },
    {
      "epoch": 2.6945882352941175,
      "grad_norm": 1.0149579048156738,
      "learning_rate": 1.2738175721913242e-06,
      "loss": 1.8941,
      "num_input_tokens_seen": 8568720,
      "step": 4295,
      "train_runtime": 15216.0343,
      "train_tokens_per_second": 563.138
    },
    {
      "epoch": 2.6977254901960785,
      "grad_norm": 0.986682116985321,
      "learning_rate": 1.2480667625916875e-06,
      "loss": 1.9548,
      "num_input_tokens_seen": 8578968,
      "step": 4300,
      "train_runtime": 15224.0396,
      "train_tokens_per_second": 563.515
    },
    {
      "epoch": 2.6977254901960785,
      "eval_loss": 2.333183765411377,
      "eval_runtime": 79.0238,
      "eval_samples_per_second": 17.931,
      "eval_steps_per_second": 4.492,
      "num_input_tokens_seen": 8578968,
      "step": 4300
    },
    {
      "epoch": 2.700862745098039,
      "grad_norm": 1.0448570251464844,
      "learning_rate": 1.2225722356289742e-06,
      "loss": 1.9927,
      "num_input_tokens_seen": 8589176,
      "step": 4305,
      "train_runtime": 15311.5017,
      "train_tokens_per_second": 560.962
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.9950917363166809,
      "learning_rate": 1.1973342663883614e-06,
      "loss": 1.9279,
      "num_input_tokens_seen": 8598904,
      "step": 4310,
      "train_runtime": 15319.1606,
      "train_tokens_per_second": 561.317
    },
    {
      "epoch": 2.7071372549019608,
      "grad_norm": 1.0997792482376099,
      "learning_rate": 1.1723531271867704e-06,
      "loss": 1.9086,
      "num_input_tokens_seen": 8608368,
      "step": 4315,
      "train_runtime": 15326.4974,
      "train_tokens_per_second": 561.666
    },
    {
      "epoch": 2.710274509803922,
      "grad_norm": 1.0926493406295776,
      "learning_rate": 1.147629087569932e-06,
      "loss": 1.7818,
      "num_input_tokens_seen": 8617920,
      "step": 4320,
      "train_runtime": 15333.9125,
      "train_tokens_per_second": 562.017
    },
    {
      "epoch": 2.7134117647058824,
      "grad_norm": 0.9598461985588074,
      "learning_rate": 1.1231624143094727e-06,
      "loss": 1.9115,
      "num_input_tokens_seen": 8627808,
      "step": 4325,
      "train_runtime": 15341.7016,
      "train_tokens_per_second": 562.376
    },
    {
      "epoch": 2.716549019607843,
      "grad_norm": 1.0775203704833984,
      "learning_rate": 1.098953371400066e-06,
      "loss": 1.9677,
      "num_input_tokens_seen": 8638488,
      "step": 4330,
      "train_runtime": 15349.86,
      "train_tokens_per_second": 562.773
    },
    {
      "epoch": 2.719686274509804,
      "grad_norm": 1.0673311948776245,
      "learning_rate": 1.0750022200565423e-06,
      "loss": 2.0033,
      "num_input_tokens_seen": 8648832,
      "step": 4335,
      "train_runtime": 15357.8389,
      "train_tokens_per_second": 563.154
    },
    {
      "epoch": 2.7228235294117646,
      "grad_norm": 1.0802662372589111,
      "learning_rate": 1.051309218711094e-06,
      "loss": 1.9304,
      "num_input_tokens_seen": 8658576,
      "step": 4340,
      "train_runtime": 15365.5949,
      "train_tokens_per_second": 563.504
    },
    {
      "epoch": 2.7259607843137257,
      "grad_norm": 0.9659605622291565,
      "learning_rate": 1.027874623010483e-06,
      "loss": 1.923,
      "num_input_tokens_seen": 8668392,
      "step": 4345,
      "train_runtime": 15373.1174,
      "train_tokens_per_second": 563.867
    },
    {
      "epoch": 2.7290980392156863,
      "grad_norm": 0.970415472984314,
      "learning_rate": 1.0046986858132934e-06,
      "loss": 2.0024,
      "num_input_tokens_seen": 8678488,
      "step": 4350,
      "train_runtime": 15380.9157,
      "train_tokens_per_second": 564.237
    },
    {
      "epoch": 2.732235294117647,
      "grad_norm": 0.9220554232597351,
      "learning_rate": 9.817816571871696e-07,
      "loss": 1.9655,
      "num_input_tokens_seen": 8688656,
      "step": 4355,
      "train_runtime": 15388.6781,
      "train_tokens_per_second": 564.614
    },
    {
      "epoch": 2.735372549019608,
      "grad_norm": 1.1218626499176025,
      "learning_rate": 9.591237844061628e-07,
      "loss": 1.9139,
      "num_input_tokens_seen": 8698560,
      "step": 4360,
      "train_runtime": 15396.2279,
      "train_tokens_per_second": 564.98
    },
    {
      "epoch": 2.7385098039215685,
      "grad_norm": 0.951862633228302,
      "learning_rate": 9.367253119480252e-07,
      "loss": 1.934,
      "num_input_tokens_seen": 8708480,
      "step": 4365,
      "train_runtime": 15403.6918,
      "train_tokens_per_second": 565.35
    },
    {
      "epoch": 2.7416470588235295,
      "grad_norm": 1.0944479703903198,
      "learning_rate": 9.145864814916e-07,
      "loss": 2.0077,
      "num_input_tokens_seen": 8718376,
      "step": 4370,
      "train_runtime": 15411.3781,
      "train_tokens_per_second": 565.71
    },
    {
      "epoch": 2.74478431372549,
      "grad_norm": 0.993804931640625,
      "learning_rate": 8.927075319141914e-07,
      "loss": 2.0044,
      "num_input_tokens_seen": 8728240,
      "step": 4375,
      "train_runtime": 15419.0467,
      "train_tokens_per_second": 566.069
    },
    {
      "epoch": 2.7479215686274507,
      "grad_norm": 1.0045469999313354,
      "learning_rate": 8.710886992889939e-07,
      "loss": 1.9068,
      "num_input_tokens_seen": 8738232,
      "step": 4380,
      "train_runtime": 15426.8259,
      "train_tokens_per_second": 566.431
    },
    {
      "epoch": 2.751058823529412,
      "grad_norm": 1.0649381875991821,
      "learning_rate": 8.497302168825577e-07,
      "loss": 1.9445,
      "num_input_tokens_seen": 8747904,
      "step": 4385,
      "train_runtime": 15434.4034,
      "train_tokens_per_second": 566.78
    },
    {
      "epoch": 2.754196078431373,
      "grad_norm": 0.9073764085769653,
      "learning_rate": 8.286323151522613e-07,
      "loss": 1.9739,
      "num_input_tokens_seen": 8758288,
      "step": 4390,
      "train_runtime": 15442.0859,
      "train_tokens_per_second": 567.17
    },
    {
      "epoch": 2.7573333333333334,
      "grad_norm": 0.9990367889404297,
      "learning_rate": 8.07795221743815e-07,
      "loss": 1.9884,
      "num_input_tokens_seen": 8768248,
      "step": 4395,
      "train_runtime": 15449.527,
      "train_tokens_per_second": 567.542
    },
    {
      "epoch": 2.760470588235294,
      "grad_norm": 1.0004305839538574,
      "learning_rate": 7.872191614888308e-07,
      "loss": 2.089,
      "num_input_tokens_seen": 8778288,
      "step": 4400,
      "train_runtime": 15457.1687,
      "train_tokens_per_second": 567.91
    },
    {
      "epoch": 2.760470588235294,
      "eval_loss": 2.3325185775756836,
      "eval_runtime": 79.0106,
      "eval_samples_per_second": 17.934,
      "eval_steps_per_second": 4.493,
      "num_input_tokens_seen": 8778288,
      "step": 4400
    },
    {
      "epoch": 2.763607843137255,
      "grad_norm": 1.0480120182037354,
      "learning_rate": 7.669043564023676e-07,
      "loss": 1.9261,
      "num_input_tokens_seen": 8787520,
      "step": 4405,
      "train_runtime": 15543.4734,
      "train_tokens_per_second": 565.351
    },
    {
      "epoch": 2.7667450980392156,
      "grad_norm": 1.1478502750396729,
      "learning_rate": 7.468510256805561e-07,
      "loss": 1.9167,
      "num_input_tokens_seen": 8796992,
      "step": 4410,
      "train_runtime": 15551.0333,
      "train_tokens_per_second": 565.685
    },
    {
      "epoch": 2.7698823529411767,
      "grad_norm": 0.9416865706443787,
      "learning_rate": 7.270593856982255e-07,
      "loss": 1.934,
      "num_input_tokens_seen": 8806872,
      "step": 4415,
      "train_runtime": 15558.4719,
      "train_tokens_per_second": 566.05
    },
    {
      "epoch": 2.7730196078431373,
      "grad_norm": 1.0348881483078003,
      "learning_rate": 7.075296500065665e-07,
      "loss": 1.882,
      "num_input_tokens_seen": 8816872,
      "step": 4420,
      "train_runtime": 15566.2835,
      "train_tokens_per_second": 566.408
    },
    {
      "epoch": 2.776156862745098,
      "grad_norm": 1.0126005411148071,
      "learning_rate": 6.882620293308328e-07,
      "loss": 1.9265,
      "num_input_tokens_seen": 8826584,
      "step": 4425,
      "train_runtime": 15573.7398,
      "train_tokens_per_second": 566.761
    },
    {
      "epoch": 2.779294117647059,
      "grad_norm": 1.03908109664917,
      "learning_rate": 6.692567315680686e-07,
      "loss": 1.9059,
      "num_input_tokens_seen": 8836688,
      "step": 4430,
      "train_runtime": 15581.4221,
      "train_tokens_per_second": 567.13
    },
    {
      "epoch": 2.7824313725490195,
      "grad_norm": 1.0009948015213013,
      "learning_rate": 6.505139617848571e-07,
      "loss": 1.9328,
      "num_input_tokens_seen": 8846504,
      "step": 4435,
      "train_runtime": 15589.2729,
      "train_tokens_per_second": 567.474
    },
    {
      "epoch": 2.7855686274509806,
      "grad_norm": 1.0345443487167358,
      "learning_rate": 6.320339222151112e-07,
      "loss": 1.9238,
      "num_input_tokens_seen": 8856808,
      "step": 4440,
      "train_runtime": 15597.0262,
      "train_tokens_per_second": 567.852
    },
    {
      "epoch": 2.788705882352941,
      "grad_norm": 1.0422593355178833,
      "learning_rate": 6.138168122579002e-07,
      "loss": 1.9115,
      "num_input_tokens_seen": 8866264,
      "step": 4445,
      "train_runtime": 15604.3119,
      "train_tokens_per_second": 568.193
    },
    {
      "epoch": 2.7918431372549017,
      "grad_norm": 0.9942763447761536,
      "learning_rate": 5.958628284752826e-07,
      "loss": 1.8485,
      "num_input_tokens_seen": 8876520,
      "step": 4450,
      "train_runtime": 15612.2917,
      "train_tokens_per_second": 568.56
    },
    {
      "epoch": 2.794980392156863,
      "grad_norm": 1.1111564636230469,
      "learning_rate": 5.781721645901961e-07,
      "loss": 1.9202,
      "num_input_tokens_seen": 8885672,
      "step": 4455,
      "train_runtime": 15619.4873,
      "train_tokens_per_second": 568.884
    },
    {
      "epoch": 2.7981176470588234,
      "grad_norm": 1.0045828819274902,
      "learning_rate": 5.607450114843704e-07,
      "loss": 2.0223,
      "num_input_tokens_seen": 8895808,
      "step": 4460,
      "train_runtime": 15627.1867,
      "train_tokens_per_second": 569.252
    },
    {
      "epoch": 2.8012549019607844,
      "grad_norm": 1.0197105407714844,
      "learning_rate": 5.435815571962543e-07,
      "loss": 1.8567,
      "num_input_tokens_seen": 8906024,
      "step": 4465,
      "train_runtime": 15634.908,
      "train_tokens_per_second": 569.624
    },
    {
      "epoch": 2.804392156862745,
      "grad_norm": 1.006085753440857,
      "learning_rate": 5.266819869189977e-07,
      "loss": 1.8956,
      "num_input_tokens_seen": 8916808,
      "step": 4470,
      "train_runtime": 15643.073,
      "train_tokens_per_second": 570.016
    },
    {
      "epoch": 2.8075294117647056,
      "grad_norm": 1.0668957233428955,
      "learning_rate": 5.100464829984497e-07,
      "loss": 1.9489,
      "num_input_tokens_seen": 8927032,
      "step": 4475,
      "train_runtime": 15650.7369,
      "train_tokens_per_second": 570.391
    },
    {
      "epoch": 2.8106666666666666,
      "grad_norm": 0.9689091444015503,
      "learning_rate": 4.936752249311921e-07,
      "loss": 1.9139,
      "num_input_tokens_seen": 8937736,
      "step": 4480,
      "train_runtime": 15658.9599,
      "train_tokens_per_second": 570.775
    },
    {
      "epoch": 2.8138039215686277,
      "grad_norm": 1.0117783546447754,
      "learning_rate": 4.775683893626009e-07,
      "loss": 2.0412,
      "num_input_tokens_seen": 8947968,
      "step": 4485,
      "train_runtime": 15666.5363,
      "train_tokens_per_second": 571.152
    },
    {
      "epoch": 2.8169411764705883,
      "grad_norm": 1.0100728273391724,
      "learning_rate": 4.617261500849429e-07,
      "loss": 1.9288,
      "num_input_tokens_seen": 8957936,
      "step": 4490,
      "train_runtime": 15673.9202,
      "train_tokens_per_second": 571.519
    },
    {
      "epoch": 2.820078431372549,
      "grad_norm": 1.0281033515930176,
      "learning_rate": 4.461486780354934e-07,
      "loss": 1.9796,
      "num_input_tokens_seen": 8968232,
      "step": 4495,
      "train_runtime": 15681.9146,
      "train_tokens_per_second": 571.884
    },
    {
      "epoch": 2.82321568627451,
      "grad_norm": 1.0580965280532837,
      "learning_rate": 4.3083614129470483e-07,
      "loss": 1.8978,
      "num_input_tokens_seen": 8978184,
      "step": 4500,
      "train_runtime": 15689.4309,
      "train_tokens_per_second": 572.244
    },
    {
      "epoch": 2.82321568627451,
      "eval_loss": 2.3327102661132812,
      "eval_runtime": 78.9978,
      "eval_samples_per_second": 17.937,
      "eval_steps_per_second": 4.494,
      "num_input_tokens_seen": 8978184,
      "step": 4500
    },
    {
      "epoch": 2.8263529411764705,
      "grad_norm": 1.0844718217849731,
      "learning_rate": 4.1578870508438836e-07,
      "loss": 1.9143,
      "num_input_tokens_seen": 8987352,
      "step": 4505,
      "train_runtime": 15776.3184,
      "train_tokens_per_second": 569.674
    },
    {
      "epoch": 2.8294901960784316,
      "grad_norm": 1.0594998598098755,
      "learning_rate": 4.0100653176591284e-07,
      "loss": 1.966,
      "num_input_tokens_seen": 8996888,
      "step": 4510,
      "train_runtime": 15783.5117,
      "train_tokens_per_second": 570.018
    },
    {
      "epoch": 2.832627450980392,
      "grad_norm": 0.9961757659912109,
      "learning_rate": 3.8648978083848375e-07,
      "loss": 1.868,
      "num_input_tokens_seen": 9006536,
      "step": 4515,
      "train_runtime": 15790.8018,
      "train_tokens_per_second": 570.366
    },
    {
      "epoch": 2.8357647058823527,
      "grad_norm": 1.0136014223098755,
      "learning_rate": 3.7223860893740303e-07,
      "loss": 2.0432,
      "num_input_tokens_seen": 9016600,
      "step": 4520,
      "train_runtime": 15798.7611,
      "train_tokens_per_second": 570.716
    },
    {
      "epoch": 2.838901960784314,
      "grad_norm": 1.0757652521133423,
      "learning_rate": 3.582531698323788e-07,
      "loss": 1.8992,
      "num_input_tokens_seen": 9025696,
      "step": 4525,
      "train_runtime": 15805.7542,
      "train_tokens_per_second": 571.039
    },
    {
      "epoch": 2.8420392156862744,
      "grad_norm": 1.0284515619277954,
      "learning_rate": 3.445336144258737e-07,
      "loss": 2.0153,
      "num_input_tokens_seen": 9036376,
      "step": 4530,
      "train_runtime": 15813.8372,
      "train_tokens_per_second": 571.422
    },
    {
      "epoch": 2.8451764705882354,
      "grad_norm": 1.0584794282913208,
      "learning_rate": 3.3108009075147607e-07,
      "loss": 1.8925,
      "num_input_tokens_seen": 9046584,
      "step": 4535,
      "train_runtime": 15821.5692,
      "train_tokens_per_second": 571.788
    },
    {
      "epoch": 2.848313725490196,
      "grad_norm": 0.9517064094543457,
      "learning_rate": 3.178927439722951e-07,
      "loss": 1.9234,
      "num_input_tokens_seen": 9056424,
      "step": 4540,
      "train_runtime": 15829.3486,
      "train_tokens_per_second": 572.129
    },
    {
      "epoch": 2.8514509803921566,
      "grad_norm": 1.0672237873077393,
      "learning_rate": 3.0497171637940134e-07,
      "loss": 1.9953,
      "num_input_tokens_seen": 9065696,
      "step": 4545,
      "train_runtime": 15836.2651,
      "train_tokens_per_second": 572.464
    },
    {
      "epoch": 2.8545882352941176,
      "grad_norm": 1.0451688766479492,
      "learning_rate": 2.9231714739028916e-07,
      "loss": 1.8621,
      "num_input_tokens_seen": 9075528,
      "step": 4550,
      "train_runtime": 15843.8957,
      "train_tokens_per_second": 572.809
    },
    {
      "epoch": 2.8577254901960787,
      "grad_norm": 1.0461840629577637,
      "learning_rate": 2.7992917354737467e-07,
      "loss": 2.0071,
      "num_input_tokens_seen": 9087024,
      "step": 4555,
      "train_runtime": 15852.5402,
      "train_tokens_per_second": 573.222
    },
    {
      "epoch": 2.8608627450980393,
      "grad_norm": 0.925479531288147,
      "learning_rate": 2.6780792851651414e-07,
      "loss": 1.92,
      "num_input_tokens_seen": 9096592,
      "step": 4560,
      "train_runtime": 15859.9471,
      "train_tokens_per_second": 573.558
    },
    {
      "epoch": 2.864,
      "grad_norm": 1.0652633905410767,
      "learning_rate": 2.5595354308557696e-07,
      "loss": 1.9473,
      "num_input_tokens_seen": 9106616,
      "step": 4565,
      "train_runtime": 15867.6012,
      "train_tokens_per_second": 573.913
    },
    {
      "epoch": 2.867137254901961,
      "grad_norm": 1.0371108055114746,
      "learning_rate": 2.443661451630219e-07,
      "loss": 1.9277,
      "num_input_tokens_seen": 9116584,
      "step": 4570,
      "train_runtime": 15875.2201,
      "train_tokens_per_second": 574.265
    },
    {
      "epoch": 2.8702745098039215,
      "grad_norm": 1.0702797174453735,
      "learning_rate": 2.3304585977651504e-07,
      "loss": 1.9872,
      "num_input_tokens_seen": 9126568,
      "step": 4575,
      "train_runtime": 15882.762,
      "train_tokens_per_second": 574.621
    },
    {
      "epoch": 2.8734117647058826,
      "grad_norm": 1.0426385402679443,
      "learning_rate": 2.2199280907159725e-07,
      "loss": 1.9963,
      "num_input_tokens_seen": 9136776,
      "step": 4580,
      "train_runtime": 15890.5843,
      "train_tokens_per_second": 574.98
    },
    {
      "epoch": 2.876549019607843,
      "grad_norm": 1.054022192955017,
      "learning_rate": 2.1120711231034374e-07,
      "loss": 1.9189,
      "num_input_tokens_seen": 9147192,
      "step": 4585,
      "train_runtime": 15898.5739,
      "train_tokens_per_second": 575.347
    },
    {
      "epoch": 2.8796862745098037,
      "grad_norm": 1.0181488990783691,
      "learning_rate": 2.0068888587009838e-07,
      "loss": 1.9612,
      "num_input_tokens_seen": 9156968,
      "step": 4590,
      "train_runtime": 15905.8309,
      "train_tokens_per_second": 575.699
    },
    {
      "epoch": 2.882823529411765,
      "grad_norm": 1.101747989654541,
      "learning_rate": 1.904382432422025e-07,
      "loss": 1.998,
      "num_input_tokens_seen": 9166944,
      "step": 4595,
      "train_runtime": 15913.5648,
      "train_tokens_per_second": 576.046
    },
    {
      "epoch": 2.8859607843137254,
      "grad_norm": 0.991381049156189,
      "learning_rate": 1.804552950307792e-07,
      "loss": 1.9115,
      "num_input_tokens_seen": 9177120,
      "step": 4600,
      "train_runtime": 15921.2222,
      "train_tokens_per_second": 576.408
    },
    {
      "epoch": 2.8859607843137254,
      "eval_loss": 2.3322653770446777,
      "eval_runtime": 79.0584,
      "eval_samples_per_second": 17.923,
      "eval_steps_per_second": 4.49,
      "num_input_tokens_seen": 9177120,
      "step": 4600
    },
    {
      "epoch": 2.8890980392156864,
      "grad_norm": 1.0916013717651367,
      "learning_rate": 1.7074014895153422e-07,
      "loss": 1.9776,
      "num_input_tokens_seen": 9186616,
      "step": 4605,
      "train_runtime": 16007.976,
      "train_tokens_per_second": 573.877
    },
    {
      "epoch": 2.892235294117647,
      "grad_norm": 0.9777578115463257,
      "learning_rate": 1.6129290983060152e-07,
      "loss": 1.9455,
      "num_input_tokens_seen": 9196776,
      "step": 4610,
      "train_runtime": 16015.8257,
      "train_tokens_per_second": 574.231
    },
    {
      "epoch": 2.8953725490196076,
      "grad_norm": 1.072670578956604,
      "learning_rate": 1.5211367960339952e-07,
      "loss": 2.0433,
      "num_input_tokens_seen": 9207056,
      "step": 4615,
      "train_runtime": 16023.581,
      "train_tokens_per_second": 574.594
    },
    {
      "epoch": 2.8985098039215687,
      "grad_norm": 0.9775785803794861,
      "learning_rate": 1.4320255731354592e-07,
      "loss": 1.8553,
      "num_input_tokens_seen": 9217016,
      "step": 4620,
      "train_runtime": 16031.0984,
      "train_tokens_per_second": 574.946
    },
    {
      "epoch": 2.9016470588235292,
      "grad_norm": 1.0749626159667969,
      "learning_rate": 1.3455963911177817e-07,
      "loss": 1.9705,
      "num_input_tokens_seen": 9226696,
      "step": 4625,
      "train_runtime": 16038.6567,
      "train_tokens_per_second": 575.279
    },
    {
      "epoch": 2.9047843137254903,
      "grad_norm": 0.967142641544342,
      "learning_rate": 1.2618501825492068e-07,
      "loss": 2.0862,
      "num_input_tokens_seen": 9237048,
      "step": 4630,
      "train_runtime": 16046.7183,
      "train_tokens_per_second": 575.635
    },
    {
      "epoch": 2.907921568627451,
      "grad_norm": 1.0091696977615356,
      "learning_rate": 1.1807878510487758e-07,
      "loss": 2.1178,
      "num_input_tokens_seen": 9247808,
      "step": 4635,
      "train_runtime": 16054.5538,
      "train_tokens_per_second": 576.024
    },
    {
      "epoch": 2.911058823529412,
      "grad_norm": 1.0309849977493286,
      "learning_rate": 1.1024102712765827e-07,
      "loss": 1.9615,
      "num_input_tokens_seen": 9257216,
      "step": 4640,
      "train_runtime": 16061.7819,
      "train_tokens_per_second": 576.35
    },
    {
      "epoch": 2.9141960784313725,
      "grad_norm": 1.0205427408218384,
      "learning_rate": 1.0267182889243388e-07,
      "loss": 1.9656,
      "num_input_tokens_seen": 9268104,
      "step": 4645,
      "train_runtime": 16070.077,
      "train_tokens_per_second": 576.731
    },
    {
      "epoch": 2.9173333333333336,
      "grad_norm": 1.0209507942199707,
      "learning_rate": 9.537127207062125e-08,
      "loss": 1.8773,
      "num_input_tokens_seen": 9277696,
      "step": 4650,
      "train_runtime": 16077.4107,
      "train_tokens_per_second": 577.064
    },
    {
      "epoch": 2.920470588235294,
      "grad_norm": 1.0245203971862793,
      "learning_rate": 8.833943543500867e-08,
      "loss": 1.9711,
      "num_input_tokens_seen": 9286944,
      "step": 4655,
      "train_runtime": 16084.6376,
      "train_tokens_per_second": 577.38
    },
    {
      "epoch": 2.9236078431372547,
      "grad_norm": 1.0382853746414185,
      "learning_rate": 8.157639485889546e-08,
      "loss": 1.9639,
      "num_input_tokens_seen": 9296736,
      "step": 4660,
      "train_runtime": 16092.2194,
      "train_tokens_per_second": 577.716
    },
    {
      "epoch": 2.926745098039216,
      "grad_norm": 1.0193493366241455,
      "learning_rate": 7.508222331528702e-08,
      "loss": 1.9466,
      "num_input_tokens_seen": 9307072,
      "step": 4665,
      "train_runtime": 16100.0526,
      "train_tokens_per_second": 578.077
    },
    {
      "epoch": 2.9298823529411764,
      "grad_norm": 0.9860593676567078,
      "learning_rate": 6.885699087609554e-08,
      "loss": 1.9921,
      "num_input_tokens_seen": 9317672,
      "step": 4670,
      "train_runtime": 16107.9918,
      "train_tokens_per_second": 578.45
    },
    {
      "epoch": 2.9330196078431374,
      "grad_norm": 1.0482842922210693,
      "learning_rate": 6.29007647113905e-08,
      "loss": 1.9365,
      "num_input_tokens_seen": 9327880,
      "step": 4675,
      "train_runtime": 16115.9013,
      "train_tokens_per_second": 578.8
    },
    {
      "epoch": 2.936156862745098,
      "grad_norm": 0.9967072606086731,
      "learning_rate": 5.7213609088668795e-08,
      "loss": 2.0253,
      "num_input_tokens_seen": 9338152,
      "step": 4680,
      "train_runtime": 16123.9594,
      "train_tokens_per_second": 579.148
    },
    {
      "epoch": 2.9392941176470586,
      "grad_norm": 1.024847388267517,
      "learning_rate": 5.179558537216911e-08,
      "loss": 1.9286,
      "num_input_tokens_seen": 9348400,
      "step": 4685,
      "train_runtime": 16131.5584,
      "train_tokens_per_second": 579.51
    },
    {
      "epoch": 2.9424313725490197,
      "grad_norm": 0.9413645267486572,
      "learning_rate": 4.664675202220026e-08,
      "loss": 2.0582,
      "num_input_tokens_seen": 9359280,
      "step": 4690,
      "train_runtime": 16139.6567,
      "train_tokens_per_second": 579.893
    },
    {
      "epoch": 2.9455686274509802,
      "grad_norm": 1.003071665763855,
      "learning_rate": 4.176716459451946e-08,
      "loss": 1.9219,
      "num_input_tokens_seen": 9369352,
      "step": 4695,
      "train_runtime": 16147.3061,
      "train_tokens_per_second": 580.242
    },
    {
      "epoch": 2.9487058823529413,
      "grad_norm": 0.9939294457435608,
      "learning_rate": 3.7156875739724484e-08,
      "loss": 1.9293,
      "num_input_tokens_seen": 9379520,
      "step": 4700,
      "train_runtime": 16155.3315,
      "train_tokens_per_second": 580.584
    },
    {
      "epoch": 2.9487058823529413,
      "eval_loss": 2.3321502208709717,
      "eval_runtime": 79.0243,
      "eval_samples_per_second": 17.931,
      "eval_steps_per_second": 4.492,
      "num_input_tokens_seen": 9379520,
      "step": 4700
    },
    {
      "epoch": 2.951843137254902,
      "grad_norm": 0.9834991097450256,
      "learning_rate": 3.281593520269577e-08,
      "loss": 1.9224,
      "num_input_tokens_seen": 9389464,
      "step": 4705,
      "train_runtime": 16242.6726,
      "train_tokens_per_second": 578.074
    },
    {
      "epoch": 2.9549803921568625,
      "grad_norm": 1.0679936408996582,
      "learning_rate": 2.8744389822044083e-08,
      "loss": 1.9254,
      "num_input_tokens_seen": 9399832,
      "step": 4710,
      "train_runtime": 16250.4665,
      "train_tokens_per_second": 578.435
    },
    {
      "epoch": 2.9581176470588235,
      "grad_norm": 1.0240744352340698,
      "learning_rate": 2.49422835296248e-08,
      "loss": 1.8851,
      "num_input_tokens_seen": 9409584,
      "step": 4715,
      "train_runtime": 16257.8282,
      "train_tokens_per_second": 578.773
    },
    {
      "epoch": 2.9612549019607846,
      "grad_norm": 0.957299530506134,
      "learning_rate": 2.140965735004663e-08,
      "loss": 1.9546,
      "num_input_tokens_seen": 9420280,
      "step": 4720,
      "train_runtime": 16266.1578,
      "train_tokens_per_second": 579.134
    },
    {
      "epoch": 2.964392156862745,
      "grad_norm": 1.0427632331848145,
      "learning_rate": 1.8146549400238634e-08,
      "loss": 1.8207,
      "num_input_tokens_seen": 9430176,
      "step": 4725,
      "train_runtime": 16274.032,
      "train_tokens_per_second": 579.462
    },
    {
      "epoch": 2.9675294117647057,
      "grad_norm": 0.9525232315063477,
      "learning_rate": 1.515299488903943e-08,
      "loss": 1.9129,
      "num_input_tokens_seen": 9440096,
      "step": 4730,
      "train_runtime": 16281.4669,
      "train_tokens_per_second": 579.806
    },
    {
      "epoch": 2.970666666666667,
      "grad_norm": 0.991701602935791,
      "learning_rate": 1.2429026116805853e-08,
      "loss": 1.9296,
      "num_input_tokens_seen": 9449888,
      "step": 4735,
      "train_runtime": 16288.863,
      "train_tokens_per_second": 580.144
    },
    {
      "epoch": 2.9738039215686274,
      "grad_norm": 1.0127079486846924,
      "learning_rate": 9.974672475082658e-09,
      "loss": 1.9188,
      "num_input_tokens_seen": 9459216,
      "step": 4740,
      "train_runtime": 16296.0429,
      "train_tokens_per_second": 580.461
    },
    {
      "epoch": 2.9769411764705884,
      "grad_norm": 1.0218732357025146,
      "learning_rate": 7.789960446266675e-09,
      "loss": 1.9758,
      "num_input_tokens_seen": 9468784,
      "step": 4745,
      "train_runtime": 16303.3215,
      "train_tokens_per_second": 580.789
    },
    {
      "epoch": 2.980078431372549,
      "grad_norm": 0.9528163075447083,
      "learning_rate": 5.87491360334036e-09,
      "loss": 1.9569,
      "num_input_tokens_seen": 9479456,
      "step": 4750,
      "train_runtime": 16311.2836,
      "train_tokens_per_second": 581.159
    },
    {
      "epoch": 2.9832156862745096,
      "grad_norm": 1.0290969610214233,
      "learning_rate": 4.229552609594234e-09,
      "loss": 1.9209,
      "num_input_tokens_seen": 9489448,
      "step": 4755,
      "train_runtime": 16318.7471,
      "train_tokens_per_second": 581.506
    },
    {
      "epoch": 2.9863529411764707,
      "grad_norm": 1.097937822341919,
      "learning_rate": 2.8538952184270495e-09,
      "loss": 1.9649,
      "num_input_tokens_seen": 9499432,
      "step": 4760,
      "train_runtime": 16326.5668,
      "train_tokens_per_second": 581.839
    },
    {
      "epoch": 2.9894901960784313,
      "grad_norm": 0.9954330325126648,
      "learning_rate": 1.7479562731403943e-09,
      "loss": 1.9003,
      "num_input_tokens_seen": 9509688,
      "step": 4765,
      "train_runtime": 16334.501,
      "train_tokens_per_second": 582.184
    },
    {
      "epoch": 2.9926274509803923,
      "grad_norm": 1.0623457431793213,
      "learning_rate": 9.117477067777103e-10,
      "loss": 1.9043,
      "num_input_tokens_seen": 9519680,
      "step": 4770,
      "train_runtime": 16342.2754,
      "train_tokens_per_second": 582.519
    },
    {
      "epoch": 2.995764705882353,
      "grad_norm": 1.0498653650283813,
      "learning_rate": 3.452785420104965e-10,
      "loss": 1.9385,
      "num_input_tokens_seen": 9529176,
      "step": 4775,
      "train_runtime": 16349.6779,
      "train_tokens_per_second": 582.836
    },
    {
      "epoch": 2.9989019607843135,
      "grad_norm": 1.0348795652389526,
      "learning_rate": 4.855489101895927e-11,
      "loss": 1.9618,
      "num_input_tokens_seen": 9538920,
      "step": 4780,
      "train_runtime": 16357.1925,
      "train_tokens_per_second": 583.164
    }
  ],
  "logging_steps": 5,
  "max_steps": 4782,
  "num_input_tokens_seen": 9542808,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.054192323611853e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
